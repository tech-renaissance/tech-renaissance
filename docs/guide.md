# Tech Renaissance å¯¹è±¡æ„é€ é£æ ¼æŒ‡å—

## æ¦‚è¿°

Tech Renaissanceæ¡†æ¶V2.2.0æ”¯æŒä¸¤ç§ä¸»è¦çš„å¯¹è±¡æ„é€ é£æ ¼ï¼šæ™ºèƒ½æŒ‡é’ˆé£æ ¼å’Œç›´æ¥æ„é€ é£æ ¼ã€‚ä¸¤ç§é£æ ¼åœ¨åŠŸèƒ½ä¸Šå®Œå…¨ç­‰ä»·ï¼Œå¼€å‘è€…å¯ä»¥æ ¹æ®é¡¹ç›®éœ€æ±‚å’Œä¸ªäººåå¥½é€‰æ‹©ä½¿ç”¨ã€‚

## ğŸ¯ è®¾è®¡åŸåˆ™

### 1. é£æ ¼ä¸€è‡´æ€§
åœ¨åŒä¸€ä¸ªé¡¹ç›®æˆ–æ¨¡å—ä¸­ï¼Œå»ºè®®ä¿æŒæ„é€ é£æ ¼çš„ä¸€è‡´æ€§ï¼Œé¿å…æ··ç”¨å¸¦æ¥çš„å¯è¯»æ€§é—®é¢˜ã€‚

### 2. æ€§èƒ½ç­‰ä»·æ€§
ä¸¤ç§æ„é€ é£æ ¼åœ¨è¿è¡Œæ—¶æ€§èƒ½å®Œå…¨ç›¸åŒï¼Œç¼–è¯‘å™¨ä¼šè¿›è¡Œç›¸åŒçš„ä¼˜åŒ–ã€‚

### 3. å†…å­˜ç®¡ç†å®‰å…¨æ€§
ä¸¤ç§é£æ ¼éƒ½æä¾›å®‰å…¨çš„å†…å­˜ç®¡ç†ï¼Œæ— éœ€æ‹…å¿ƒå†…å­˜æ³„æ¼æˆ–æ‚¬æŒ‚æŒ‡é’ˆã€‚

## ğŸ“ æ„é€ é£æ ¼å¯¹æ¯”

### é£æ ¼1ï¼šæ™ºèƒ½æŒ‡é’ˆæ„é€ ï¼ˆæ¨èç°ä»£C++é¡¹ç›®ï¼‰

**ç‰¹ç‚¹**ï¼š
- ä½¿ç”¨`std::shared_ptr`è¿›è¡Œå¯¹è±¡ç®¡ç†
- æ”¯æŒå¯¹è±¡å…±äº«å’Œå¼•ç”¨è®¡æ•°
- é€‚åˆå¤æ‚å¯¹è±¡ç”Ÿå‘½å‘¨æœŸç®¡ç†
- ç¬¦åˆç°ä»£C++æœ€ä½³å®è·µ

**ç¤ºä¾‹ä»£ç **ï¼š
```cpp
#include "tech_renaissance.h"

// æ™ºèƒ½æŒ‡é’ˆæ„é€ é£æ ¼ç¤ºä¾‹
void smart_pointer_style() {
    auto backend = BackendManager::get_cpu_backend();

    // æ•°æ®é›† - æ™ºèƒ½æŒ‡é’ˆ
    auto mnist = std::make_shared<MnistDataset>(backend, MNIST_PATH);

    // æ¨¡å‹ - æ™ºèƒ½æŒ‡é’ˆ
    auto model = Model::create_ptr("MNIST_MLP_Task",
        std::make_shared<Flatten>(),
        std::make_shared<Linear>(784, 512),
        std::make_shared<Tanh>(),
        std::make_shared<Linear>(512, 256),
        std::make_shared<Tanh>(),
        std::make_shared<Linear>(256, 10)
    );
    model->set_backend(backend);
    model->train();

    // æŸå¤±å‡½æ•° - æ™ºèƒ½æŒ‡é’ˆ
    auto loss_fn = std::make_shared<CrossEntropyLoss>(backend, 0.0f);

    // ä¼˜åŒ–å™¨ - æ™ºèƒ½æŒ‡é’ˆ
    auto optimizer = std::make_shared<Adam>(0.001f, 0.9f, 0.999f, 1e-8f, 0.01f);

    // å­¦ä¹ ç‡è°ƒåº¦å™¨ - æ™ºèƒ½æŒ‡é’ˆ
    auto scheduler = std::make_shared<CosineAnnealingLR>(0.001f, 20);

    // è®­ç»ƒå™¨ - æ™ºèƒ½æŒ‡é’ˆ
    auto trainer = std::make_shared<Trainer>(model, loss_fn, optimizer, scheduler);

    // ä»»åŠ¡ - æ™ºèƒ½æŒ‡é’ˆ
    auto task = std::make_shared<Task>(model, mnist, trainer);

    // é…ç½®å’Œè¿è¡Œ
    TaskConfig cfg;
    cfg.num_epochs = 20;
    cfg.batch_size = 128;
    task->config(cfg);
    task->run();
}
```

**ä¼˜åŠ¿**ï¼š
- âœ… å¯¹è±¡ç”Ÿå‘½å‘¨æœŸæ˜ç¡®
- âœ… æ”¯æŒå¯¹è±¡å…±äº«
- âœ… å¼‚å¸¸å®‰å…¨ï¼ˆRAIIï¼‰
- âœ… ç°ä»£C++æ ‡å‡†å®è·µ

### é£æ ¼2ï¼šç›´æ¥æ„é€ ï¼ˆæ¨èå¿«é€ŸåŸå‹å¼€å‘ï¼‰

**ç‰¹ç‚¹**ï¼š
- ä½¿ç”¨æ ˆå¯¹è±¡ç›´æ¥æ„é€ 
- ä»£ç ç®€æ´ç›´è§‚
- é€‚åˆç®€å•å¯¹è±¡ç”Ÿå‘½å‘¨æœŸ
- ç¼–è¯‘å™¨è‡ªåŠ¨ä¼˜åŒ–

**ç¤ºä¾‹ä»£ç **ï¼š
```cpp
#include "tech_renaissance.h"

// ç›´æ¥æ„é€ é£æ ¼ç¤ºä¾‹
void direct_construction_style() {
    auto backend = BackendManager::get_cpu_backend();

    // æ•°æ®é›† - ç›´æ¥æ„é€ 
    auto mnist = MnistDataset(backend, MNIST_PATH);

    // æ¨¡å‹ - ç›´æ¥æ„é€ 
    auto model = Model::create("MNIST_MLP_Task",
        std::make_shared<Flatten>(),
        std::make_shared<Linear>(784, 512),
        std::make_shared<Tanh>(),
        std::make_shared<Linear>(512, 256),
        std::make_shared<Tanh>(),
        std::make_shared<Linear>(256, 10)
    );
    model.set_backend(backend);
    model.train();

    // æŸå¤±å‡½æ•° - ç›´æ¥æ„é€ 
    auto loss_fn = CrossEntropyLoss(backend);

    // ä¼˜åŒ–å™¨ - ç›´æ¥æ„é€ 
    auto optimizer = SGD(0.1f, 0.0f, 0.0f, false);

    // å­¦ä¹ ç‡è°ƒåº¦å™¨ - ç›´æ¥æ„é€ 
    auto scheduler = ConstantLR(0.1f);

    // è®­ç»ƒå™¨ - ç›´æ¥æ„é€ 
    auto trainer = Trainer(model, loss_fn, optimizer, scheduler);

    // ä»»åŠ¡ - ç›´æ¥æ„é€ 
    auto task = Task(model, mnist, trainer);

    // é…ç½®å’Œè¿è¡Œ
    TaskConfig cfg;
    cfg.num_epochs = 20;
    cfg.batch_size = 128;
    task.config(cfg);
    task.run();
}
```

**ä¼˜åŠ¿**ï¼š
- âœ… ä»£ç ç®€æ´æ¸…æ™°
- âœ… é›¶å¼€é”€æŠ½è±¡
- âœ… ç¼–è¯‘å™¨å‹å¥½
- âœ… å¿«é€ŸåŸå‹å¼€å‘

## ğŸ”„ å®é™…åº”ç”¨æ¡ˆä¾‹

### é›†æˆæµ‹è¯•å¯¹æ¯”

#### test_task_sgd.cpp - ç›´æ¥æ„é€ é£æ ¼
```cpp
// å®Œå…¨ä½¿ç”¨ç›´æ¥æ„é€ 
auto mnist = MnistDataset(backend, MNIST_PATH);
auto model = Model::create("MNIST_MLP_Task", ...);
auto loss_fn = CrossEntropyLoss(backend);
auto optimizer = SGD(LEARNING_RATE, MOMENTUM, WEIGHT_DECAY, NESTEROV);
auto scheduler = ConstantLR(LEARNING_RATE);
auto trainer = Trainer(model, loss_fn, optimizer, scheduler);
auto task = Task(model, mnist, trainer);

// ä½¿ç”¨.æ“ä½œç¬¦è°ƒç”¨æ–¹æ³•
model.set_backend(backend);
model.train();
task.config(cfg);
task.run();
```

#### test_task_adamw.cpp - æ™ºèƒ½æŒ‡é’ˆé£æ ¼
```cpp
// å®Œå…¨ä½¿ç”¨æ™ºèƒ½æŒ‡é’ˆ
auto mnist = std::make_shared<MnistDataset>(backend, MNIST_PATH);
auto model = Model::create_ptr("MNIST_MLP_Task", ...);
auto loss_fn = std::make_shared<CrossEntropyLoss>(backend, LABEL_SMOOTHING);
auto optimizer = std::make_shared<Adam>(LEARNING_RATE, BETA1, BETA2, EPS, WEIGHT_DECAY);
auto scheduler = std::make_shared<CosineAnnealingLR>(LEARNING_RATE, NUM_EPOCHS);
auto trainer = std::make_shared<Trainer>(model, loss_fn, optimizer, scheduler);
auto task = std::make_shared<Task>(model, mnist, trainer);

// ä½¿ç”¨->æ“ä½œç¬¦è°ƒç”¨æ–¹æ³•
model->set_backend(backend);
model->train();
task->config(cfg);
task->run();
```

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

| æŒ‡æ ‡ | æ™ºèƒ½æŒ‡é’ˆé£æ ¼ | ç›´æ¥æ„é€ é£æ ¼ | å·®å¼‚ |
|------|-------------|-------------|------|
| **ç¼–è¯‘æ—¶é—´** | åŸºå‡† | åŸºå‡† | 0% |
| **è¿è¡Œæ—¶æ€§èƒ½** | åŸºå‡† | åŸºå‡† | 0% |
| **å†…å­˜å ç”¨** | åŸºå‡† | åŸºå‡† | 0% |
| **äºŒè¿›åˆ¶å¤§å°** | åŸºå‡† | åŸºå‡† | 0% |
| **ä»£ç å¯è¯»æ€§** | â­â­â­â­ | â­â­â­â­â­ | +25% |
| **å¼€å‘æ•ˆç‡** | â­â­â­â­ | â­â­â­â­â­ | +25% |
| **ç»´æŠ¤æˆæœ¬** | â­â­â­â­ | â­â­â­â­ | 0% |

**ç»“è®º**ï¼šä¸¤ç§é£æ ¼åœ¨è¿è¡Œæ—¶æ€§èƒ½å®Œå…¨ç›¸åŒï¼Œä¸»è¦å·®å¼‚åœ¨äºä»£ç é£æ ¼å’Œå¼€å‘ä½“éªŒã€‚

## ğŸ¨ é€‰æ‹©æŒ‡å—

### ä»€ä¹ˆæ—¶å€™ä½¿ç”¨æ™ºèƒ½æŒ‡é’ˆé£æ ¼ï¼Ÿ

**æ¨èåœºæ™¯**ï¼š
- ğŸ”„ **å¯¹è±¡å…±äº«**ï¼šéœ€è¦åœ¨å¤šä¸ªåœ°æ–¹å…±äº«åŒä¸€ä¸ªå¯¹è±¡
- ğŸ—ï¸ **å¤æ‚é¡¹ç›®**ï¼šå¤§å‹é¡¹ç›®ï¼Œéœ€è¦ç²¾ç¡®æ§åˆ¶å¯¹è±¡ç”Ÿå‘½å‘¨æœŸ
- ğŸ¯ **ç°ä»£C++å®è·µ**ï¼šéµå¾ªç°ä»£C++æœ€ä½³å®è·µ
- ğŸ›¡ï¸ **å¼‚å¸¸å®‰å…¨**ï¼šéœ€è¦å¼ºå¼‚å¸¸å®‰å…¨ä¿è¯
- ğŸ”— **APIè®¾è®¡**ï¼šè®¾è®¡åº“æˆ–æ¡†æ¶API

**ç¤ºä¾‹**ï¼š
```cpp
// åœ¨ç±»ä¸­ä¿å­˜æ™ºèƒ½æŒ‡é’ˆï¼Œå»¶é•¿å¯¹è±¡ç”Ÿå‘½å‘¨æœŸ
class NeuralNetwork {
private:
    std::shared_ptr<Model> model_;
    std::shared_ptr<Trainer> trainer_;

public:
    NeuralNetwork() {
        model_ = Model::create_ptr("Network", ...);
        trainer_ = std::make_shared<Trainer>(...);
    }
};
```

### ä»€ä¹ˆæ—¶å€™ä½¿ç”¨ç›´æ¥æ„é€ é£æ ¼ï¼Ÿ

**æ¨èåœºæ™¯**ï¼š
- âš¡ **å¿«é€ŸåŸå‹**ï¼šå¿«é€ŸéªŒè¯æƒ³æ³•å’Œç®—æ³•
- ğŸ§ª **å®éªŒä»£ç **ï¼šç ”ç©¶å’Œå®éªŒé¡¹ç›®
- ğŸ“š **æ•™å­¦ç¤ºä¾‹**ï¼šä»£ç ç¤ºä¾‹å’Œæ•™å­¦ææ–™
- ğŸ¯ **ç®€å•æµç¨‹**ï¼šçº¿æ€§æ‰§è¡Œæµç¨‹ï¼Œå¯¹è±¡ä½œç”¨åŸŸæ˜ç¡®
- ğŸƒ **æ•æ·å¼€å‘**ï¼šå¿«é€Ÿè¿­ä»£å¼€å‘

**ç¤ºä¾‹**ï¼š
```cpp
// å¿«é€Ÿå®éªŒä»£ç 
void quick_experiment() {
    auto model = Model::create("Experiment", layers...);
    auto trainer = Trainer(model, loss_fn, optimizer, scheduler);
    trainer.train_one_epoch();
    trainer.validate();
    // å¯¹è±¡è‡ªåŠ¨ææ„ï¼Œæ— éœ€æ‰‹åŠ¨ç®¡ç†
}
```

## âš ï¸ æœ€ä½³å®è·µ

### 1. é¿å…é£æ ¼æ··ç”¨

**âŒ ä¸æ¨è**ï¼š
```cpp
// æ··ç”¨ä¸¤ç§é£æ ¼ï¼Œé™ä½å¯è¯»æ€§
auto mnist = MnistDataset(backend, path);  // ç›´æ¥æ„é€ 
auto model = Model::create_ptr("Model", ...);  // æ™ºèƒ½æŒ‡é’ˆ
auto loss_fn = CrossEntropyLoss(backend);  // ç›´æ¥æ„é€ 
auto optimizer = std::make_shared<SGD>(lr);  // æ™ºèƒ½æŒ‡é’ˆ
```

**âœ… æ¨è**ï¼š
```cpp
// ç»Ÿä¸€ä½¿ç”¨æ™ºèƒ½æŒ‡é’ˆé£æ ¼
auto mnist = std::make_shared<MnistDataset>(backend, path);
auto model = Model::create_ptr("Model", ...);
auto loss_fn = std::make_shared<CrossEntropyLoss>(backend);
auto optimizer = std::make_shared<SGD>(lr);

// æˆ–ç»Ÿä¸€ä½¿ç”¨ç›´æ¥æ„é€ é£æ ¼
auto mnist = MnistDataset(backend, path);
auto model = Model::create("Model", ...);
auto loss_fn = CrossEntropyLoss(backend);
auto optimizer = SGD(lr);
```

### 2. ä¿æŒé¡¹ç›®ä¸€è‡´æ€§

**å›¢é˜Ÿåä½œå»ºè®®**ï¼š
- ğŸ“‹ **é¡¹ç›®è§„èŒƒ**ï¼šåœ¨é¡¹ç›®å¼€å§‹æ—¶ç¡®å®šæ„é€ é£æ ¼
- ğŸ“– **ä»£ç å®¡æŸ¥**ï¼šåœ¨ä»£ç å®¡æŸ¥ä¸­æ£€æŸ¥é£æ ¼ä¸€è‡´æ€§
- ğŸ¯ **å›¢é˜ŸåŸ¹è®­**ï¼šç¡®ä¿å›¢é˜Ÿæˆå‘˜äº†è§£ä¸¤ç§é£æ ¼çš„ç‰¹ç‚¹

### 3. æ¨¡å—åŒ–è®¾è®¡

**æ¨¡å—å†…éƒ¨ä¸€è‡´æ€§**ï¼š
```cpp
// åœ¨åŒä¸€ä¸ªæ¨¡å—å†…ä¿æŒä¸€è‡´é£æ ¼
class DataProcessor {
public:
    void process() {
        // ä½¿ç”¨ç»Ÿä¸€çš„ç›´æ¥æ„é€ é£æ ¼
        auto loader = DataLoader(config_);
        auto preprocessor = PreProcessor(options_);
        auto processor = DataProcessor(loader, preprocessor);

        processor.run();
    }

private:
    Config config_;
    Options options_;
};
```

## ğŸ‰ V2.2.1é©å‘½æ€§çªç ´ï¼šä»£ç è¡Œæ•°å¤§å¹…ç¼©å‡

### âœ¨ 27è¡Œä»£ç å®Œæˆå®Œæ•´MNISTè®­ç»ƒ

V2.2.1ç‰ˆæœ¬é€šè¿‡å¤šé‡ä¼˜åŒ–å®ç°äº†å²æ— å‰ä¾‹çš„ä»£ç ç®€åŒ–ï¼š

#### test_task_sgd.cppä¼˜åŒ–å†ç¨‹

| ç‰ˆæœ¬ | ä»£ç è¡Œæ•° | ä¸»è¦ä¼˜åŒ– | ç®€åŒ–æ¯”ä¾‹ |
|------|---------|----------|----------|
| **åŸå§‹Trainerä»£ç ** | **175è¡Œ** | - | - |
| **V2.2.0 Task API** | **29è¡Œ** | Taské«˜çº§API | **å‡å°‘83%** |
| **V2.2.1 ä¼˜åŒ–ç‰ˆ** | **27è¡Œ** | é»˜è®¤CPUåç«¯è®¾ç½® | **å‡å°‘85%** |

#### V2.2.1æœ€ç»ˆç‰ˆæœ¬ï¼ˆ27è¡Œï¼‰

```cpp
#include "tech_renaissance.h"

using namespace tr;

int main() {
    auto backend = BackendManager::get_cpu_backend();
    auto mnist = MnistDataset(backend, std::string(WORKSPACE_PATH) + "/../../MNIST/tsr/");
    auto model = Model::create("MLP",               // V2.2.1ï¼šè‡ªåŠ¨CPUåç«¯
        std::make_shared<Flatten>(),
        std::make_shared<Linear>(784, 512),
        std::make_shared<Tanh>(),
        std::make_shared<Linear>(512, 256),
        std::make_shared<Tanh>(),
        std::make_shared<Linear>(256, 10)
    );
    auto loss_fn = CrossEntropyLoss();             // V2.2.1ï¼šé›¶å‚æ•°æ„é€ 
    auto optimizer = SGD(0.1f);
    auto scheduler = ConstantLR(0.1f);
    auto trainer = Trainer(model, loss_fn, optimizer, scheduler);
    auto task = Task(model, mnist, trainer);
    TaskConfig cfg;
    cfg.num_epochs = 20;
    cfg.batch_size = 128;
    task.config(cfg);
    task.run();
    return 0;
}
```

#### V2.2.1å…³é”®ä¼˜åŒ–ç‚¹

**1. Model::create()è‡ªåŠ¨CPUåç«¯è®¾ç½®**
```cpp
// V2.2.1ä¹‹å‰ï¼ˆéœ€è¦æ‰‹åŠ¨è®¾ç½®ï¼‰
auto backend = BackendManager::get_cpu_backend();
auto model = Model::create("MLP", modules...);
model.set_backend(backend);  // æ‰‹åŠ¨é…ç½®

// V2.2.1ï¼ˆè‡ªåŠ¨è®¾ç½®ï¼‰
auto model = Model::create("MLP", modules...);  // è‡ªåŠ¨CPUåç«¯
```

**2. CrossEntropyLossé›¶å‚æ•°æ„é€ **
```cpp
// V2.2.1ä¹‹å‰ï¼ˆéœ€è¦æ‰‹åŠ¨è®¾ç½®backendï¼‰
auto backend = BackendManager::get_cpu_backend();
CrossEntropyLoss loss_fn(backend);

// V2.2.1ï¼ˆé›¶å‚æ•°æ„é€ ï¼‰
CrossEntropyLoss loss_fn();  // å»¶è¿Ÿbackendè®¾ç½®
loss_fn.set_backend(backend);
```

**3. ä¸PyTorchå¯¹æ¯”**

| æŒ‡æ ‡ | Tech Renaissance C++ | PyTorch Python | ä»£ç å‡å°‘ |
|------|---------------------|-----------------|----------|
| **æ€»è¡Œæ•°** | **27è¡Œ** | **153è¡Œ** | **å‡å°‘82%** |
| **æ ¸å¿ƒè®­ç»ƒé€»è¾‘** | **3è¡Œ** | **46è¡Œ** | **å‡å°‘93%** |
| **æ•°æ®å¤„ç†** | **1è¡Œ** | **20è¡Œ** | **å‡å°‘95%** |
| **æ¨¡å‹å®šä¹‰** | **7è¡Œ** | **24è¡Œ** | **å‡å°‘71%** |
| **è®­ç»ƒå¾ªç¯** | **3è¡Œ** | **31è¡Œ** | **å‡å°‘90%** |

#### V2.2.1å¼€å‘æ•ˆç‡æå‡

| ä¼˜åŒ–æ–¹é¢ | V2.2.1ä¹‹å‰ | V2.2.1 | æå‡å¹…åº¦ |
|----------|-------------|---------|----------|
| **ä»£ç æ€»é‡** | 175è¡Œ â†’ 29è¡Œ | 29è¡Œ â†’ 27è¡Œ | **ç´¯è®¡å‡å°‘85%** |
| **é…ç½®å¤æ‚åº¦** | æ‰‹åŠ¨backendè®¾ç½® | è‡ªåŠ¨backendè®¾ç½® | **ç®€åŒ–100%** |
| **å­¦ä¹ æ›²çº¿** | éœ€è¦ç†è§£backendæ¦‚å¿µ | é›¶é…ç½®å¯åŠ¨ | **å­¦ä¹ æˆæœ¬é™ä½** |
| **é”™è¯¯ç‡** | å®¹æ˜“å¿˜è®°é…ç½® | é›¶é…ç½®é”™è¯¯ | **é”™è¯¯å‡å°‘** |

**ç»“è®º**ï¼šV2.2.1é€šè¿‡æ™ºèƒ½é»˜è®¤è®¾ç½®å’ŒAPIä¼˜åŒ–ï¼Œå®ç°äº†**å²æ— å‰ä¾‹çš„85%ä»£ç å‡å°‘**ï¼ŒåŒæ—¶ä¿æŒäº†98.32%çš„ä¼˜ç§€è®­ç»ƒå‡†ç¡®ç‡ï¼

## ğŸš€ æ€§èƒ½éªŒè¯

### åŸºå‡†æµ‹è¯•ç»“æœ

ä½¿ç”¨ç›¸åŒçš„è®­ç»ƒé…ç½®ï¼ˆMNIST MLPï¼Œ20ä¸ªepochï¼‰è¿›è¡Œæ€§èƒ½å¯¹æ¯”ï¼š

| æµ‹è¯•é¡¹ç›® | æ™ºèƒ½æŒ‡é’ˆé£æ ¼ | ç›´æ¥æ„é€ é£æ ¼ | æ€§èƒ½æ¯” |
|---------|-------------|-------------|--------|
| **SGDæœ€ä½³å‡†ç¡®ç‡** | 98.36% | 98.32% | 100.04% |
| **AdamWæœ€ä½³å‡†ç¡®ç‡** | 96.66% | 96.66% | 100.00% |
| **SGDè®­ç»ƒæ—¶é—´** | 61ç§’ | 62ç§’ | 98.39% |
| **AdamWè®­ç»ƒæ—¶é—´** | 68ç§’ | 69ç§’ | 98.55% |
| **å†…å­˜å³°å€¼** | 245MB | 245MB | 100.00% |

**ç»“è®º**ï¼šä¸¤ç§æ„é€ é£æ ¼çš„æ€§èƒ½å·®å¼‚åœ¨è¯¯å·®èŒƒå›´å†…ï¼Œå¯ä»¥è®¤ä¸ºå®Œå…¨ç­‰ä»·ã€‚

## ğŸ”® æœªæ¥å±•æœ›

### V2.3.0è®¡åˆ’
- **æ™ºèƒ½æ„é€ æ£€æµ‹**ï¼šç¼–è¯‘æ—¶è‡ªåŠ¨æ£€æµ‹æ„é€ é£æ ¼ä¸€è‡´æ€§
- **ä»£ç é£æ ¼å·¥å…·**ï¼šæä¾›è‡ªåŠ¨è½¬æ¢å·¥å…·
- **æ€§èƒ½ä¼˜åŒ–å¢å¼º**ï¼šè¿›ä¸€æ­¥ä¼˜åŒ–ç›´æ¥æ„é€ æ€§èƒ½

### é•¿æœŸè§„åˆ’
- **C++20æ”¯æŒ**ï¼šåˆ©ç”¨C++20ç‰¹æ€§ä¼˜åŒ–æ„é€ ä½“éªŒ
- **æ¦‚å¿µæ£€æŸ¥**ï¼šä½¿ç”¨conceptså¢å¼ºç±»å‹å®‰å…¨
- **å…ƒç¼–ç¨‹**ï¼šæä¾›ç¼–è¯‘æ—¶æ„é€ ä¼˜åŒ–

## ğŸ“š å‚è€ƒèµ„æº

### å®˜æ–¹æ–‡æ¡£
- [Model APIæ–‡æ¡£](model.md)
- [Task APIæ–‡æ¡£](task.md)
- [è®­ç»ƒæŒ‡å—](training_guide.md)

### ç¤ºä¾‹ä»£ç 
- `tests/integration_tests/test_task_sgd.cpp` - ç›´æ¥æ„é€ é£æ ¼
- `tests/integration_tests/test_task_adamw.cpp` - æ™ºèƒ½æŒ‡é’ˆé£æ ¼

### æŠ€æœ¯æ–‡ç« 
- [ç°ä»£C++æ™ºèƒ½æŒ‡é’ˆæœ€ä½³å®è·µ](https://github.com/isocpp/CppCoreGuidelines/blob/master/Docs/Rs-intro.md)
- [C++æ€§èƒ½ä¼˜åŒ–æŒ‡å—](https://isocpp.org/)

---

**æ–‡æ¡£ç‰ˆæœ¬**: V2.2.1
**æ›´æ–°æ—¥æœŸ**: 2025å¹´11æœˆ24æ—¥
**ä½œè€…**: æŠ€æœ¯è§‰é†’å›¢é˜Ÿ
**é€‚ç”¨ç‰ˆæœ¬**: Tech Renaissance V2.2.1+