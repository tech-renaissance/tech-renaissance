# Linearå±‚æŠ€æœ¯æ–‡æ¡£

**ç‰ˆæœ¬**: V1.59.0
**æ—¥æœŸ**: 2025å¹´11æœˆ21æ—¥
**ä½œè€…**: æŠ€æœ¯è§‰é†’å›¢é˜Ÿ
**æ‰€å±ç³»åˆ—**: model

## æ¦‚è¿°

Linearå±‚ï¼ˆå…¨è¿æ¥å±‚ï¼‰æ˜¯æ·±åº¦å­¦ä¹ ä¸­æœ€åŸºç¡€å’Œé‡è¦çš„å±‚ä¹‹ä¸€ã€‚å®ƒå®ç°äº†å¯¹è¾“å…¥æ•°æ®çš„çº¿æ€§å˜æ¢ï¼š`output = input @ weight^T + bias`ã€‚è¯¥å±‚å·²å®Œå…¨å®ç°çœŸå®çš„çŸ©é˜µä¹˜æ³•è¿ç®—ï¼Œå¹¶ä¸PyTorchè¾“å‡ºå®Œå…¨ä¸€è‡´ï¼Œæ”¯æŒå®Œæ•´çš„æ¢¯åº¦è®¡ç®—ã€å†…å­˜ä¼˜åŒ–çš„intoå‹æ–¹æ³•ã€é«˜æ•ˆçš„å‚æ•°ç®¡ç†ï¼Œä»¥åŠæƒé‡è½¬ç½®ç¼“å­˜ä¼˜åŒ–ã€‚**V1.59.0ç‰ˆæœ¬å®ç°äº†TIPS3.mdæœ€ç»ˆæ–¹æ¡ˆçš„å…³é”®ä¼˜åŒ–ï¼Œé€šè¿‡MNISTè®­ç»ƒéªŒè¯äº†98.04%çš„æµ‹è¯•å‡†ç¡®ç‡ï¼Œåœ¨æ€§èƒ½å’Œå†…å­˜ä¼˜åŒ–æ–¹é¢è¾¾åˆ°ç”Ÿäº§çº§æ°´å‡†**ã€‚

## V1.59.0å…³é”®ç‰¹æ€§

### âœ… **P0çº§å…³é”®ä¼˜åŒ– - å·²å®Œæˆ**

#### 1. æƒé‡è½¬ç½®ç¼“å­˜å¤±æ•ˆæ—¶æœºä¼˜åŒ– ğŸ¯
**é—®é¢˜**: æ¯æ¬¡backwardéƒ½å¤±æ•ˆæƒé‡è½¬ç½®ç¼“å­˜ï¼Œä½†æƒé‡å®é™…åœ¨Optimizer::step()ä¸­æ›´æ–°ï¼Œå¯¼è‡´ä¸‹æ¬¡forwardé‡å¤è®¡ç®—è½¬ç½®
**è§£å†³**: å®ç°weight_dirty_æœºåˆ¶ï¼Œé¿å…ä¸å¿…è¦çš„è½¬ç½®è®¡ç®—

```cpp
class Linear : public Module {
private:
    mutable bool weight_dirty_ = false;     // âœ… æ–°å¢ï¼šæƒé‡è„æ ‡è®°

    void forward_into(const Tensor& input, Tensor& output) override {
        // âœ… åªåœ¨æƒé‡è¢«ä¿®æ”¹åæ‰é‡æ–°è½¬ç½®
        if (weight_dirty_) {
            invalidate_weight_cache();
            weight_dirty_ = false;
        }
        // ... æ­£å¸¸forwardé€»è¾‘
    }

    void backward_into(const Tensor& grad_output, Tensor& grad_input) override {
        // ... æ¢¯åº¦è®¡ç®—é€»è¾‘ ...
        weight_dirty_ = true;  // âœ… æ ‡è®°æƒé‡å°†è¢«æ›´æ–°ï¼Œè€Œéç«‹å³å¤±æ•ˆç¼“å­˜
    }
};
```

**é¢„æœŸæ”¶ç›Š**: è®­ç»ƒæ€§èƒ½æå‡15-20%

#### 2. æ¢¯åº¦åˆå§‹åŒ–æœºåˆ¶ä¼˜åŒ– ğŸ¯
**é—®é¢˜**: å‚æ•°æ³¨å†Œæ—¶æœªåˆå§‹åŒ–æ¢¯åº¦å¼ é‡ï¼Œå¯¼è‡´`has_grad()`è¿”å›false
**è§£å†³**: åœ¨`set_backend`ä¸­ä¸ºå‚æ•°åˆ›å»ºé›¶æ¢¯åº¦å¼ é‡

```cpp
void set_backend(std::shared_ptr<Backend> backend) override {
    // ... æƒé‡åˆ›å»ºå’Œåˆå§‹åŒ– ...

    // âœ… å¯ç”¨æ¢¯åº¦ï¼šä¸ºæƒé‡å‚æ•°åˆ›å»ºæ¢¯åº¦å¼ é‡
    Tensor weight_grad = backend->zeros(weight.shape(), DType::FP32);
    weight.set_grad(weight_grad);

    if (use_bias_ && !has_parameter("bias")) {
        // ... åç½®åˆ›å»ºå’Œåˆå§‹åŒ– ...
        Tensor bias_grad = backend->zeros(bias.shape(), DType::FP32);
        bias.set_grad(bias_grad);
    }
}
```

**é¢„æœŸæ•ˆæœ**: ç¡®ä¿æ‰€æœ‰å‚æ•°éƒ½æœ‰æ­£ç¡®çš„æ¢¯åº¦çŠ¶æ€

### ğŸ”§ æŠ€æœ¯å®ç°ç»†èŠ‚

#### æ ¸å¿ƒç®—æ³•å®ç°
```cpp
// å‰å‘ä¼ æ’­ï¼šä½¿ç”¨ç¼“å­˜çš„è½¬ç½®æƒé‡é¿å…è¿è¡Œæ—¶è½¬ç½®
void forward_into(const Tensor& input, Tensor& output) override {
    cache_input(input);

    if (weight_dirty_) {
        invalidate_weight_cache();
        weight_dirty_ = false;
    }

    // ä½¿ç”¨ç¼“å­˜çš„è½¬ç½®æƒé‡è¿›è¡ŒçŸ©é˜µä¹˜æ³•
    backend->mm_into(input, weight_transposed_, output);

    if (use_bias_ && has_parameter("bias")) {
        const Tensor& bias = get_parameter("bias");
        backend->add_broadcast_into(output, bias, output);
    }
}

// åå‘ä¼ æ’­ï¼šä½¿ç”¨mm_into_transposedé¿å…ä¸´æ—¶è½¬ç½®å¼ é‡
void backward_into(const Tensor& grad_output, Tensor& grad_input) override {
    // è¾“å…¥æ¢¯åº¦ï¼šgrad_input = grad_output @ weight
    backend->mm_into(grad_output, weight, grad_input);

    // æƒé‡æ¢¯åº¦ï¼šgrad_weight = grad_output^T @ input (ä½¿ç”¨è½¬ç½®ä¼˜åŒ–)
    if (weight.has_grad()) {
        Shape grad_weight_shape(weight.shape());
        Tensor grad_weight = backend->zeros(grad_weight_shape, DType::FP32);
        backend->mm_into_transposed(grad_output, cached_input_, grad_weight, true, false);

        // æ¢¯åº¦ç´¯ç§¯ï¼šnew_grad += old_grad
        Tensor& existing_grad = weight.grad();
        backend->add_into(grad_weight, existing_grad, existing_grad);
    }

    weight_dirty_ = true;  // æ ‡è®°æƒé‡å°†è¢«æ›´æ–°
}
```

#### ç¼“å­˜ç®¡ç†ä¼˜åŒ–
```cpp
// æƒé‡è½¬ç½®ç¼“å­˜å¤±æ•ˆæ—¶æœº
void invalidate_weight_cache() const {
    auto backend = get_backend();
    if (backend && has_parameter("weight")) {
        const Tensor& weight = get_parameter("weight");
        weight_transposed_ = backend->zeros(Shape(in_features_, out_features_), weight.dtype());
    }
    weight_transposed_valid_ = false;
    weight_dirty_ = false;  // é‡ç½®è„æ ‡è®°
}
```

#### å†…å­˜å¸ƒå±€ä¼˜åŒ–
- **æƒé‡å­˜å‚¨**: `(out_features, in_features)` - PyTorchæ ‡å‡†æ ¼å¼
- **è½¬ç½®ç¼“å­˜**: `(in_features, out_features)` - ä¼˜åŒ–çš„çŸ©é˜µä¹˜æ³•æ ¼å¼
- **è¾“å…¥ç¼“å­˜**: ç¼“å­˜è®­ç»ƒæ—¶çš„è¾“å…¥å¼ é‡ï¼Œç”¨äºè®¡ç®—æƒé‡æ¢¯åº¦
- **æ¢¯åº¦åˆ†é…**: ä»…åœ¨æœ‰éœ€æ±‚çš„å‚æ•°ä¸Šåˆ†é…æ¢¯åº¦ï¼ŒèŠ‚çœå†…å­˜

## ä½¿ç”¨ç¤ºä¾‹

### åŸºæœ¬ç”¨æ³•
```cpp
// åˆ›å»ºLinearå±‚
Linear layer(784, 512, "Linear1", true);

// è®¾ç½®åç«¯ï¼ˆCPUåç«¯ï¼‰
layer.set_backend(BackendManager::instance().get_backend(tr::CPU));

// å‰å‘ä¼ æ’­
Tensor input = backend->randn(Shape(100, 784), DType::FP32);
Tensor output = layer.forward(input);

// åå‘ä¼ æ’­
Tensor grad_output = backend->ones_like(output);
Tensor grad_input = layer.backward(grad_output);
```

### æ¨¡å‹é›†æˆ
```cpp
Model model;
model.add_module(std::make_shared<Linear>(784, 512, "linear1", true));
model.add_module(std::make_shared<Linear>(512, 256, "linear2", true));
model.add_module(std::make_shared<Linear>(256, 10, "linear3", false));

// è®¾ç½®åç«¯å¹¶åˆå§‹åŒ–
model.set_backend(BackendManager::instance().get_backend(tr::CPU));
model.initialize(Shape(100, 784));
```

## æ€§èƒ½ä¼˜åŒ–ç‰¹æ€§

### 1. æƒé‡è½¬ç½®ç¼“å­˜ ğŸš€
- **é¿å…è¿è¡Œæ—¶è½¬ç½®**: ç¼“å­˜æƒé‡è½¬ç½®ï¼Œæå‡å‰å‘ä¼ æ’­æ€§èƒ½
- **æ™ºèƒ½å¤±æ•ˆæœºåˆ¶**: åªåœ¨æƒé‡çœŸæ­£æ›´æ–°æ—¶æ‰é‡æ–°è®¡ç®—è½¬ç½®
- **å†…å­˜é¢„åˆ†é…**: è½¬ç½®ç¼“å­˜é¢„åˆ†é…ï¼Œé¿å…è¿è¡Œæ—¶åˆ†é…å¼€é”€

### 2. çŸ©é˜µä¹˜æ³•ä¼˜åŒ– ğŸš€
- **mm_into**: intoå‹æ–¹æ³•ï¼Œé¿å…è¾“å‡ºå¼ é‡åˆ›å»º
- **mm_into_transposed**: è½¬ç½®ä¼˜åŒ–ç‰ˆæœ¬ï¼Œé¿å…ä¸´æ—¶è½¬ç½®å¼ é‡
- **å¹¿æ’­åŠ æ³•**: add_broadcast_intoï¼Œé¿å…åç½®å¼ é‡æ‰©å±•

### 3. æ¢¯åº¦è®¡ç®—ä¼˜åŒ– ğŸš€
- **å»¶è¿Ÿæ¢¯åº¦åˆ†é…**: ä»…åœ¨å‚æ•°éœ€è¦æ—¶åˆ†é…æ¢¯åº¦å¼ é‡
- **æ¢¯åº¦ç´¯ç§¯**: æ”¯æŒmini-batchè®­ç»ƒçš„æ¢¯åº¦ç´¯åŠ 
- **é«˜æ•ˆæ±‚å’Œ**: ä½¿ç”¨sum_intoè®¡ç®—åç½®æ¢¯åº¦

## æµ‹è¯•éªŒè¯

### MNISTè®­ç»ƒæ€§èƒ½
```cpp
// æµ‹è¯•ç»“æœï¼ˆV1.59.0ï¼‰
MNIST Dataset: 60,000 è®­ç»ƒæ ·æœ¬ï¼Œ10,000 æµ‹è¯•æ ·æœ¬
Architecture: 784 -> 512 -> 256 -> 10
Optimizer: SGD (lr=0.01, momentum=0.9, weight_decay=0.0005)

Best Test Accuracy: 98.04% (Epoch 19)
Training Time: 78 seconds (20 epochs)
Convergence: Fast and stable
```

### å•å…ƒæµ‹è¯•è¦†ç›–
- åŸºç¡€å‰å‘ä¼ æ’­æµ‹è¯•
- æ¢¯åº¦è®¡ç®—å‡†ç¡®æ€§æµ‹è¯•
- å†…å­˜åˆ†é…æµ‹è¯•
- å‚æ•°ç®¡ç†æµ‹è¯•
- ç¼“å­˜å¤±æ•ˆæµ‹è¯•
- è®¾å¤‡è½¬ç§»æµ‹è¯•

## è®¾è®¡æƒè¡¡

### ä¼˜ç‚¹
- âœ… **æ€§èƒ½ä¼˜åŒ–**: æƒé‡è½¬ç½®ç¼“å­˜å’Œintoå‹æ–¹æ³•æ˜¾è‘—æå‡æ€§èƒ½
- âœ… **å†…å­˜æ•ˆç‡**: å»¶è¿Ÿåˆ†é…å’Œæ™ºèƒ½ç¼“å­˜å‡å°‘å†…å­˜ä½¿ç”¨
- âœ… **åŠŸèƒ½å®Œæ•´**: å®Œæ•´å®ç°å‰å‘/åå‘ä¼ æ’­å’Œå‚æ•°ç®¡ç†
- âœ… **PyTorchå…¼å®¹**: è¾“å…¥è¾“å‡ºæ ¼å¼ä¸PyTorchä¸€è‡´

### è®¾è®¡è€ƒè™‘
- âœ… **ä½¿ç”¨ä¾¿åˆ©**: æä¾›é«˜çº§æ¥å£å’Œintoå‹æ–¹æ³•
- âœ… **æ€§èƒ½ä¼˜åŒ–**: ç¼“å­˜æœºåˆ¶å’Œå†…å­˜ä¼˜åŒ–
- âœ… **å¯æ‰©å±•æ€§**: æ˜“äºæ‰©å±•å’Œè‡ªå®šä¹‰
- âœ… **å†…å­˜å®‰å…¨**: RAIIç®¡ç†å†…å­˜ç”Ÿå‘½å‘¨æœŸ

## æœªæ¥è§„åˆ’

### V1.60.0è§„åˆ’
- **è‡ªåŠ¨ç²¾åº¦æ”¯æŒ**: æ”¯æŒåŠç²¾åº¦(FP16)è®¡ç®—
- **æ›´å¤šä¼˜åŒ–**: æ·»åŠ æ›´å¤šçŸ©é˜µè¿ç®—ä¼˜åŒ–
- **é‡åŒ–æ”¯æŒ**: æ”¯æŒé‡åŒ–å’Œåé‡åŒ–
- **æ‰¹å¤„ç†ä¼˜åŒ–**: è¿›ä¸€æ­¥ä¼˜åŒ–æ‰¹å¤„ç†æ€§èƒ½

âœ… **V1.53.0å®Œæˆ - PyTorchè®­ç»ƒå®Œå…¨å¯¹é½**:
- **åç½®å½¢çŠ¶å…¼å®¹**: ä¿®æ”¹åç½®é»˜è®¤ä¸º2Då½¢çŠ¶`(1, out_features)`ï¼Œå®Œå…¨å…¼å®¹PyTorch 1Dåç½®
- **æ¢¯åº¦è®¡ç®—éªŒè¯**: æ‰€æœ‰æƒé‡å’Œåç½®æ¢¯åº¦è®¡ç®—ä¸PyTorchæ•°å€¼å®Œå…¨ä¸€è‡´ï¼Œé€šè¿‡ä¸¥æ ¼æµ‹è¯•éªŒè¯
- **æƒé‡æ›´æ–°éªŒè¯**: SGDä¼˜åŒ–å™¨æ›´æ–°åçš„æƒé‡ä¸PyTorchå®Œå…¨ä¸€è‡´ï¼Œç¡®ä¿è®­ç»ƒæ”¶æ•›æ€§
- **å¹¿æ’­ä¼˜åŒ–**: è§£å†³äº†`(1,5)`å’Œ`(5)`å½¢çŠ¶å¹¿æ’­ä¸å…¼å®¹é—®é¢˜ï¼Œæå‡è®­ç»ƒç¨³å®šæ€§

âœ… **V1.50.0å®Œæˆ - æƒé‡è½¬ç½®ç¼“å­˜ä¼˜åŒ–**:
- **æ™ºèƒ½ç¼“å­˜æœºåˆ¶**ï¼šLinearå±‚æ™ºèƒ½ç¼“å­˜è½¬ç½®æƒé‡ï¼Œé¿å…é‡å¤è®¡ç®—ï¼Œå®ç°3.75å€æ€§èƒ½æå‡
- **mutableç¼“å­˜è®¾è®¡**ï¼šä½¿ç”¨mutableå…³é”®å­—å®ç°çº¿ç¨‹å®‰å…¨çš„ç¼“å­˜ç®¡ç†
- **è‡ªåŠ¨å¤±æ•ˆæœºåˆ¶**ï¼šæƒé‡æ›´æ–°ã€è®¾å¤‡è½¬ç§»æ—¶è‡ªåŠ¨ä½¿ç¼“å­˜å¤±æ•ˆå¹¶é‡æ–°è®¡ç®—
- **å†…å­˜é«˜æ•ˆ**ï¼šä»…å­˜å‚¨ä¸€ä¸ªè½¬ç½®æƒé‡å‰¯æœ¬ï¼Œç©ºé—´å¤æ‚åº¦O(1)
- **é¢„åˆ†é…ç­–ç•¥**ï¼šåœ¨set_backendæ—¶é¢„åˆ†é…è½¬ç½®ç¼“å­˜ï¼Œå‡å°‘è¿è¡Œæ—¶åˆ†é…å¼€é”€

âœ… **V1.47.0å®Œæˆ - å½¢çŠ¶æ¨æ–­æ¥å£å®ç°**:
- **infer_output_shapeæ–¹æ³•**ï¼šæ™ºèƒ½è®¡ç®—batch_sizeå’Œè¾“å‡ºå½¢çŠ¶
- **é™æ€å›¾åˆ†ææ”¯æŒ**ï¼šåŸºäºå½¢çŠ¶æ•°å­¦è®¡ç®—ï¼Œé›¶å†…å­˜åˆ†é…
- **ç¼–è¯‘æ—¶å¼ºåˆ¶å®ç°**ï¼šç¡®ä¿æ‰€æœ‰Linearå±‚éƒ½èƒ½è¿›è¡Œå†…å­˜åˆ†æ

âœ… **V1.46.1é‡è¦æ›´æ–° - PyTorchæƒé‡æ ¼å¼å®Œå…¨å…¼å®¹**:
- æƒé‡å­˜å‚¨æ ¼å¼ä»è½¬ç½®æ ¼å¼ `(in_features, out_features)` æ”¹ä¸ºPyTorchæ ‡å‡†æ ¼å¼ `(out_features, in_features)`
- ä¸PyTorchæ¨¡å‹æƒé‡å¯ç›´æ¥äº¤æ¢ï¼Œæ— éœ€è½¬ç½®æ“ä½œ
- åºåˆ—åŒ–æ ¼å¼ä¸PyTorch `state_dict()` å®Œå…¨ä¸€è‡´

## æ•°å­¦è¿ç®—

### å‰å‘ä¼ æ’­

å¯¹äºè¾“å…¥å¼ é‡ $X \in \mathbb{R}^{B \times D_{in}}$ï¼š

$$Y = X \cdot W^T + b$$

å…¶ä¸­ï¼š
- $W \in \mathbb{R}^{D_{out} \times D_{in}}$ æ˜¯æƒé‡çŸ©é˜µ
- $b \in \mathbb{R}^{D_{out}}$ æ˜¯åç½®å‘é‡ï¼ˆé»˜è®¤ä¸ä½¿ç”¨ï¼‰
- $Y \in \mathbb{R}^{B \times D_{out}}$ æ˜¯è¾“å‡º

**æ³¨æ„**ï¼šLinearå±‚é»˜è®¤ä¸ä½¿ç”¨åç½®ï¼ˆ`use_bias = false`ï¼‰ï¼Œå¯ä»¥é€šè¿‡æ„é€ å‡½æ•°å‚æ•°å¯ç”¨ã€‚

### åå‘ä¼ æ’­

ç»™å®šæ¢¯åº¦ $\frac{\partial L}{\partial Y} \in \mathbb{R}^{B \times D_{out}}$ï¼š

$$\frac{\partial L}{\partial W} = \left(\frac{\partial L}{\partial Y}\right)^T \cdot X$$

$$\frac{\partial L}{\partial b} = \sum_{i=1}^{B} \left(\frac{\partial L}{\partial Y}\right)_i$$

$$\frac{\partial L}{\partial X} = \frac{\partial L}{\partial Y} \cdot W$$

## ç±»å®šä¹‰

```cpp
namespace tr {
class Linear : public Module {
public:
    Linear(int in_features, int out_features, const std::string& name = "Linear");

    // æ ¸å¿ƒè®¡ç®—æ–¹æ³•
    Tensor forward(const Tensor& input) override;
    void forward_into(const Tensor& input, Tensor& output) override;
    Tensor backward(const Tensor& grad_output) override;
    void backward_into(const Tensor& grad_output, Tensor& grad_input) override;

    // è®¿é—®å™¨æ–¹æ³•
    int in_features() const;
    int out_features() const;

    // è°ƒè¯•æ–¹æ³•
    void print_parameters() const;
};
}
```

## æ„é€ å‡½æ•°

### Linear(int in_features, int out_features, const std::string& name = "Linear")

åˆ›å»ºä¸€ä¸ªLinearå±‚å®ä¾‹ã€‚

**å‚æ•°**:
- `in_features`: è¾“å…¥ç‰¹å¾æ•°é‡
- `out_features`: è¾“å‡ºç‰¹å¾æ•°é‡
- `name`: å±‚çš„åç§°ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¸º"Linear"ï¼‰

**ç¤ºä¾‹**:
```cpp
// åˆ›å»ºä¸€ä¸ªè¾“å…¥784ç»´ï¼Œè¾“å‡º256ç»´çš„Linearå±‚
Linear layer(784, 256, "fc1");
```

### åç«¯é…ç½®

```cpp
void set_backend(Backend* backend) override;
```

ä½¿ç”¨æŒ‡å®šåç«¯é…ç½®å±‚ï¼Œå¹¶ä½¿ç”¨Xavieråˆå§‹åŒ–åˆå§‹åŒ–å‚æ•°ã€‚

### æ ¸å¿ƒæ“ä½œ

```cpp
// å‰å‘ä¼ æ’­ï¼ˆè¿”å›å‹ï¼‰
Tensor forward(const Tensor& input) override;

// å‰å‘ä¼ æ’­ï¼ˆintoå‹ï¼‰
void forward_into(const Tensor& input, Tensor& output) override;

// åå‘ä¼ æ’­ï¼ˆè¿”å›å‹ï¼‰
Tensor backward(const Tensor& grad_output) override;

// åå‘ä¼ æ’­ï¼ˆintoå‹ï¼‰
void backward_into(const Tensor& grad_output, Tensor& grad_input) override;

// å½¢çŠ¶æ¨æ–­ï¼ˆV1.47.0æ–°å¢ï¼‰
Shape infer_output_shape(const Shape& input_shape) const override;

// å½¢çŠ¶æ¨æ–­å®ç°
Shape infer_output_shape(const Shape& input_shape) const override {
    // è¾“å…¥: (batch, in_features) æˆ–å±•å¹³åçš„å…¶ä»–å½¢çŠ¶
    // è¾“å‡º: (batch, out_features)
    // å‡è®¾è¾“å…¥çš„æœ€åä¸€ç»´æ˜¯in_featuresï¼Œå…¶ä»–ç»´åº¦å±•å¹³ä¸ºbatch
    int64_t batch_size = input_shape.numel() / in_features_;
    return Shape(batch_size, out_features_);
}
```

## V1.50.0æ€§èƒ½ä¼˜åŒ–ï¼šæƒé‡è½¬ç½®ç¼“å­˜

### ä¼˜åŒ–èƒŒæ™¯

Linearå±‚åœ¨å‰å‘ä¼ æ’­æ—¶éœ€è¦è¿›è¡ŒçŸ©é˜µä¹˜æ³•ï¼š`output = input @ weight^T`ã€‚åœ¨ä¼ ç»Ÿçš„å®ç°ä¸­ï¼Œæ¯æ¬¡å‰å‘ä¼ æ’­éƒ½éœ€è¦å®æ—¶è®¡ç®—æƒé‡è½¬ç½®ï¼Œè¿™åœ¨å¤§è§„æ¨¡è®­ç»ƒä¸­ä¼šé€ æˆæ˜¾è‘—çš„è®¡ç®—å¼€é”€ã€‚V1.50.0å¼•å…¥äº†æ™ºèƒ½çš„æƒé‡è½¬ç½®ç¼“å­˜æœºåˆ¶æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚

### æ ¸å¿ƒå®ç°

```cpp
class Linear : public Module {
private:
    // V1.50.0æ–°å¢ï¼šæƒé‡è½¬ç½®ç¼“å­˜
    mutable Tensor weight_transposed_;      // ç¼“å­˜çš„è½¬ç½®æƒé‡
    mutable bool weight_transposed_valid_ = false;

public:
    void forward_into(const Tensor& input, Tensor& output) override {
        cache_input(input);
        auto backend = get_backend();
        const Tensor& weight = get_parameter("weight");

        // â­ ç¡®ä¿è½¬ç½®æƒé‡ç¼“å­˜æœ‰æ•ˆ
        if (!weight_transposed_valid_) {
            // é¢„è®¡ç®—å¹¶ç¼“å­˜è½¬ç½®æƒé‡ï¼šweight^T (in_features, out_features)
            weight_transposed_ = backend->transpose(weight);
            weight_transposed_valid_ = true;
        }

        // â­ ä½¿ç”¨ç¼“å­˜çš„è½¬ç½®æƒé‡ï¼Œé¿å…è¿è¡Œæ—¶è½¬ç½®å¼€é”€
        backend->mm_into(input, weight_transposed_, output);

        // åç½®å¤„ç†...
        if (use_bias_ && has_parameter("bias")) {
            const Tensor& bias = get_parameter("bias");
            backend->add_broadcast_into(output, bias, output);
        }
    }

private:
    // â­ ç¼“å­˜ç®¡ç†æ–¹æ³•
    void invalidate_weight_cache() const {
        auto backend = get_backend();
        if (backend && has_parameter("weight")) {
            const Tensor& weight = get_parameter("weight");
            // é¢„åˆ†é…è½¬ç½®æƒé‡ç¼“å­˜
            weight_transposed_ = backend->zeros(Shape(in_features_, out_features_), weight.dtype());
        }
        weight_transposed_valid_ = false;
    }
};
```

### æŠ€æœ¯ç‰¹æ€§

#### 1. **æ™ºèƒ½ç¼“å­˜ç®¡ç†**
- **mutableè®¾è®¡**ï¼šä½¿ç”¨mutableå…³é”®å­—ï¼Œå…è®¸åœ¨constæ–¹æ³•ä¸­ä¿®æ”¹ç¼“å­˜
- **å»¶è¿Ÿè®¡ç®—**ï¼šåªåœ¨éœ€è¦æ—¶è®¡ç®—è½¬ç½®æƒé‡
- **è‡ªåŠ¨å¤±æ•ˆ**ï¼šæƒé‡æ›´æ–°ã€è®¾å¤‡è½¬ç§»æ—¶è‡ªåŠ¨ä½¿ç¼“å­˜å¤±æ•ˆ

#### 2. **æ€§èƒ½ä¼˜åŒ–æ•ˆæœ**
```cpp
// æ€§èƒ½æµ‹è¯•ç»“æœ
ç¬¬ä¸€æ¬¡å‰å‘ä¼ æ’­ï¼ˆæ„å»ºç¼“å­˜ï¼‰: 45 Î¼s
ç¬¬äºŒæ¬¡å‰å‘ä¼ æ’­ï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰: 12 Î¼s
æ€§èƒ½æå‡: 3.75å€
```

#### 3. **å†…å­˜æ•ˆç‡**
- **ç©ºé—´å¤æ‚åº¦**ï¼šO(1) - ä»…å­˜å‚¨ä¸€ä¸ªè½¬ç½®æƒé‡å‰¯æœ¬
- **å†…å­˜å¼€é”€**ï¼šä¸åŸå§‹æƒé‡å¤§å°ç›¸åŒ
- **é¢„åˆ†é…ç­–ç•¥**ï¼šåœ¨set_backendæ—¶é¢„åˆ†é…ï¼Œå‡å°‘è¿è¡Œæ—¶åˆ†é…

### ç¼“å­˜å¤±æ•ˆæœºåˆ¶

```cpp
void backward_into(const Tensor& grad_output, Tensor& grad_input) override {
    // ... æ¢¯åº¦è®¡ç®— ...

    // â­ æƒé‡æ›´æ–°åï¼Œè½¬ç½®ç¼“å­˜å¤±æ•ˆ
    invalidate_weight_cache();
}

void to(const Device& device) override {
    Module::to(device);
    // â­ è®¾å¤‡è½¬ç§»åï¼Œè½¬ç½®ç¼“å­˜å¤±æ•ˆ
    invalidate_weight_cache();
}
```

### ä½¿ç”¨ç¤ºä¾‹

```cpp
// åˆ›å»ºLinearå±‚
auto linear = std::make_shared<Linear>(784, 512);
linear->set_backend(backend);

// ç¬¬ä¸€æ¬¡å‰å‘ä¼ æ’­ï¼ˆæ„å»ºç¼“å­˜ï¼‰
Tensor input1 = backend->randn({32, 784});
Tensor output1 = backend->zeros({32, 512});
linear->forward_into(input1, output1);  // ç¼“å­˜æ„å»ºæ—¶é—´ï¼š45Î¼s

// åç»­å‰å‘ä¼ æ’­ï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰
Tensor input2 = backend->randn({32, 784});
Tensor output2 = backend->zeros({32, 512});
linear->forward_into(input2, output2);  // ç¼“å­˜å‘½ä¸­æ—¶é—´ï¼š12Î¼s

// æƒé‡æ›´æ–°ï¼ˆç¼“å­˜è‡ªåŠ¨å¤±æ•ˆï¼‰
Tensor& weight = linear->get_parameter("weight");
// ... æƒé‡æ›´æ–°æ“ä½œ ...
// ä¸‹æ¬¡forward_intoä¼šé‡æ–°æ„å»ºç¼“å­˜
```

### è°ƒè¯•æ”¯æŒ

```cpp
void print_parameters() const override {
    std::cout << "Linear Layer (" << instance_name() << "):" << std::endl;
    std::cout << "  Input features: " << in_features_ << std::endl;
    std::cout << "  Output features: " << out_features_ << std::endl;

    // â­ æ˜¾ç¤ºç¼“å­˜çŠ¶æ€
    std::cout << "  Weight transposed cache: "
              << (weight_transposed_valid_ ? "VALID âœ…" : "INVALID âŒ") << std::endl;

    // ... å…¶ä»–ä¿¡æ¯ ...
}
```

### æ€§èƒ½åŸºå‡†æµ‹è¯•

```cpp
=== Linear Layer Performance Test ===
ç¬¬ä¸€æ¬¡å‰å‘ä¼ æ’­ï¼ˆæ„å»ºç¼“å­˜ï¼‰: 45 Î¼s
ç¬¬äºŒæ¬¡å‰å‘ä¼ æ’­ï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰: 12 Î¼s
è¾“å‡ºä¸€è‡´æ€§éªŒè¯: PASS
[æ€§èƒ½æå‡: 3.75å€]

ç¼“å­˜çŠ¶æ€è°ƒè¯•è¾“å‡º:
Linear Layer (TestLinear):
  Input features: 256
  Output features: 512
  Weight transposed cache: VALID âœ…
  Weight shape: (512,256) (PyTorch standard: out_features, in_features)
```
```

### è®¿é—®æ–¹æ³•

```cpp
// è·å–å±‚ç»´åº¦
int in_features() const;
int out_features() const;

// è°ƒè¯•ä¿¡æ¯
void print_parameters() const;
```

## åˆå§‹åŒ–

### Xavieråˆå§‹åŒ–

æƒé‡ä½¿ç”¨Xavierï¼ˆGlorotï¼‰åˆå§‹åŒ–ï¼š

$$W_{ij} \sim \mathcal{U}\left(-\sqrt{\frac{6}{D_{in} + D_{out}}}, \sqrt{\frac{6}{D_{in} + D_{out}}}\right)$$

è¿™ç§åˆå§‹åŒ–æœ‰åŠ©äºåœ¨å±‚ä¹‹é—´ä¿æŒæ¢¯åº¦æ–¹å·®ã€‚

### åç½®åˆå§‹åŒ–

åç½®åˆå§‹åŒ–ä¸ºé›¶ï¼š

$$b_i = 0$$

## æ ¸å¿ƒæ–¹æ³•

### å‰å‘ä¼ æ’­

#### Tensor forward(const Tensor& input)
æ‰§è¡Œå‰å‘ä¼ æ’­ï¼Œè¿”å›æ–°çš„è¾“å‡ºå¼ é‡ã€‚

**å‚æ•°**:
- `input`: è¾“å…¥å¼ é‡ï¼Œå½¢çŠ¶ä¸º(batch_size, in_features)

**è¿”å›å€¼**: è¾“å‡ºå¼ é‡ï¼Œå½¢çŠ¶ä¸º(batch_size, out_features)

**å†…éƒ¨å®ç°**: è°ƒç”¨`forward_into`æ–¹æ³•

#### void forward_into(const Tensor& input, Tensor& output)
é«˜æ€§èƒ½å‰å‘ä¼ æ’­ï¼Œå°†ç»“æœå†™å…¥é¢„åˆ†é…çš„è¾“å‡ºå¼ é‡ã€‚

**å‚æ•°**:
- `input`: è¾“å…¥å¼ é‡ï¼Œå½¢çŠ¶ä¸º(batch_size, in_features)
- `output`: é¢„åˆ†é…çš„è¾“å‡ºå¼ é‡ï¼Œå½¢çŠ¶ä¸º(batch_size, out_features)

**è®¡ç®—å…¬å¼**: `output = input @ weight^T + bias`

**æ€§èƒ½ç‰¹ç‚¹**:
- ä½¿ç”¨intoå‹æ–¹æ³•é¿å…å†…å­˜åˆ†é…
- åœ¨è®­ç»ƒæ¨¡å¼ä¸‹ç¼“å­˜è¾“å…¥ç”¨äºåå‘ä¼ æ’­
- ä½¿ç”¨CpuBackendçš„é«˜æ•ˆçŸ©é˜µä¹˜æ³•

### åå‘ä¼ æ’­

#### Tensor backward(const Tensor& grad_output)
æ‰§è¡Œåå‘ä¼ æ’­ï¼Œè¿”å›è¾“å…¥æ¢¯åº¦å¼ é‡ã€‚

**å‚æ•°**:
- `grad_output`: ä¸Šå±‚ä¼ æ¥çš„æ¢¯åº¦ï¼Œå½¢çŠ¶ä¸º(batch_size, out_features)

**è¿”å›å€¼**: è¾“å…¥æ¢¯åº¦å¼ é‡ï¼Œå½¢çŠ¶ä¸º(batch_size, in_features)

**å†…éƒ¨å®ç°**: è°ƒç”¨`backward_into`æ–¹æ³•

#### void backward_into(const Tensor& grad_output, Tensor& grad_input)
é«˜æ€§èƒ½åå‘ä¼ æ’­ï¼Œå°†ç»“æœå†™å…¥é¢„åˆ†é…çš„æ¢¯åº¦å¼ é‡ã€‚

**å‚æ•°**:
- `grad_output`: ä¸Šå±‚ä¼ æ¥çš„æ¢¯åº¦ï¼Œå½¢çŠ¶ä¸º(batch_size, out_features)
- `grad_input`: é¢„åˆ†é…çš„è¾“å…¥æ¢¯åº¦å¼ é‡ï¼Œå½¢çŠ¶ä¸º(batch_size, in_features)

**è®¡ç®—å…¬å¼**:
```cpp
grad_weight = grad_output^T @ input
grad_bias = sum(grad_output, dim=0)
grad_input = grad_output @ weight
```

**æ€§èƒ½ç‰¹ç‚¹**:
- åŒæ—¶è®¡ç®—è¾“å…¥æ¢¯åº¦å’Œå‚æ•°æ¢¯åº¦
- ä½¿ç”¨é«˜æ•ˆçš„çŸ©é˜µè¿ç®—
- è‡ªåŠ¨ç®¡ç†å‚æ•°æ¢¯åº¦çš„å­˜å‚¨

### è®¿é—®å™¨æ–¹æ³•

#### int in_features() const
è¿”å›è¾“å…¥ç‰¹å¾æ•°é‡ã€‚

#### int out_features() const
è¿”å›è¾“å‡ºç‰¹å¾æ•°é‡ã€‚

### è°ƒè¯•æ–¹æ³•

#### void print_parameters() const
æ‰“å°å±‚çš„å‚æ•°ä¿¡æ¯ï¼ŒåŒ…æ‹¬æƒé‡å’Œåç½®çš„å½¢çŠ¶ã€‚

## è¾“å…¥è¾“å‡ºå½¢çŠ¶

### å‰å‘ä¼ æ’­
- **è¾“å…¥å½¢çŠ¶**: (batch_size, in_features)
- **è¾“å‡ºå½¢çŠ¶**: (batch_size, out_features)

### åå‘ä¼ æ’­
- **æ¢¯åº¦è¾“å…¥å½¢çŠ¶**: (batch_size, out_features)
- **æ¢¯åº¦è¾“å‡ºå½¢çŠ¶**: (batch_size, in_features)
- **æƒé‡æ¢¯åº¦å½¢çŠ¶**: (out_features, in_features)
- **åç½®æ¢¯åº¦å½¢çŠ¶**: (out_features,)

## å‚æ•°åˆå§‹åŒ–

Linearå±‚ä½¿ç”¨Xavieråˆå§‹åŒ–æ–¹æ³•æ¥åˆå§‹åŒ–æƒé‡ï¼š

```cpp
// æƒé‡åˆå§‹åŒ–ï¼šout_features Ã— in_features (PyTorchæ ‡å‡†æ ¼å¼)
float limit = sqrt(6.0f / (in_features_ + out_features_));
backend->uniform_inplace(weight_, -limit, limit);
backend->fill(bias_, 0.0f);
```

- **æƒé‡**: ä½¿ç”¨å‡åŒ€åˆ†å¸ƒ`U(-limit, limit)`ï¼Œå…¶ä¸­`limit = sqrt(6/(in+out))`
  - **å­˜å‚¨æ ¼å¼**: `(out_features, in_features)` - PyTorchæ ‡å‡†æ ¼å¼ï¼ˆV1.46.1æ›´æ–°ï¼‰
  - **ä¸PyTorchå…¼å®¹**: æƒé‡æ ¼å¼ä¸PyTorchå®Œå…¨ä¸€è‡´ï¼Œå¯ç›´æ¥äº¤æ¢ä½¿ç”¨
  - **å‰å‘ä¼ æ’­**: ä½¿ç”¨`input @ weight^T`è®¡ç®—ï¼Œå‰å‘æ—¶è½¬ç½®æƒé‡
- **åç½®**: åˆå§‹åŒ–ä¸º0

## å†…å­˜ç®¡ç†

### æ¢¯åº¦ç®¡ç†
- å‚æ•°æ¢¯åº¦é‡‡ç”¨å»¶è¿Ÿåˆ†é…ç­–ç•¥
- åªæœ‰åœ¨éœ€è¦æ—¶æ‰åˆ›å»ºæ¢¯åº¦å¼ é‡
- ä½¿ç”¨`zero_grad()`æ–¹æ³•å¯ä»¥æ¸…é›¶æ‰€æœ‰å‚æ•°æ¢¯åº¦

### ç¼“å­˜ç®¡ç†
- åœ¨è®­ç»ƒæ¨¡å¼ä¸‹ç¼“å­˜è¾“å…¥å¼ é‡ç”¨äºåå‘ä¼ æ’­
- åœ¨æ¨ç†æ¨¡å¼ä¸‹ä¸ç¼“å­˜è¾“å…¥ä»¥èŠ‚çœå†…å­˜
- ä½¿ç”¨`clear_cache()`æ–¹æ³•å¯ä»¥æ‰‹åŠ¨æ¸…é™¤ç¼“å­˜

## ä½¿ç”¨ç¤ºä¾‹

### åŸºæœ¬ä½¿ç”¨

```cpp
#include "tech_renaissance.h"

using namespace tr;

int main() {
    // åˆ›å»ºCPUåç«¯
    auto backend = BackendManager::get_cpu_backend();

    // åˆ›å»ºLinearå±‚
    Linear layer(784, 256, "fc1");
    layer.set_backend(backend.get());

    // åˆ›å»ºè¾“å…¥æ•°æ®
    Tensor input = backend->randn(Shape(32, 784));

    // å‰å‘ä¼ æ’­
    Tensor output = layer.forward(input);
    std::cout << "Output shape: " << output.shape().to_string() << std::endl;

    // åˆ›å»ºæ¢¯åº¦ï¼ˆæ¨¡æ‹Ÿä¸Šå±‚ä¼ æ¥çš„æ¢¯åº¦ï¼‰
    Tensor grad_output = backend->ones(output.shape());

    // åå‘ä¼ æ’­
    Tensor grad_input = layer.backward(grad_output);
    std::cout << "Input gradient shape: " << grad_input.shape().to_string() << std::endl;

    return 0;
}
```

### è®­ç»ƒå¾ªç¯

```cpp
// è®¾ç½®
Linear layer(128, 64);
layer.set_backend(BackendManager::get_cpu_backend());
layer.train();  // è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼

// è®­ç»ƒè¿­ä»£
for (int epoch = 0; epoch < epochs; ++epoch) {
    for (auto& batch : data_loader) {
        // å‰å‘ä¼ æ’­
        Tensor output = layer.forward(batch.input);

        // è®¡ç®—æŸå¤±ï¼ˆMSEç¤ºä¾‹ï¼‰
        Tensor loss = mse_loss(output, batch.target);

        // åå‘ä¼ æ’­
        Tensor grad_loss = mse_loss_backward(loss);
        Tensor grad_input = layer.backward(grad_loss);

        // å‚æ•°æ›´æ–°
        Tensor& weight = layer.get_parameter("weight");
        Tensor& bias = layer.get_parameter("bias");

        if (weight.has_grad()) {
            optimizer.update(weight, weight.grad());
        }
        if (bias.has_grad()) {
            optimizer.update(bias, bias.grad());
        }

        // ä¸ºä¸‹æ¬¡è¿­ä»£æ¸…é›¶æ¢¯åº¦
        layer.zero_grad();
    }
}
```

### é«˜æ€§èƒ½intoå‹æ–¹æ³•ä½¿ç”¨
```cpp
// é¢„åˆ†é…è¾“å‡ºå¼ é‡
Tensor output = backend->zeros(Shape(32, 256));
Tensor grad_input = backend->zeros(Shape(32, 784));

// ä½¿ç”¨intoå‹æ–¹æ³•è¿›è¡Œè®¡ç®—
layer.forward_into(input, output);
layer.backward_into(grad_output, grad_input);
```

### è®­ç»ƒå¾ªç¯ç¤ºä¾‹
```cpp
Linear layer1(784, 512, "fc1");
Linear layer2(512, 256, "fc2");
Linear layer3(256, 10, "fc3");

// è®¾ç½®åç«¯
layer1.set_backend(backend.get());
layer2.set_backend(backend.get());
layer3.set_backend(backend.get());

// è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼
layer1.train();
layer2.train();
layer3.train();

for (int epoch = 0; epoch < num_epochs; ++epoch) {
    for (int batch = 0; batch < num_batches; ++batch) {
        // å‰å‘ä¼ æ’­
        Tensor h1 = layer1.forward(input);
        Tensor h2 = layer2.forward(h1);
        Tensor output = layer3.forward(h2);

        // è®¡ç®—æŸå¤±å’Œæ¢¯åº¦
        Tensor loss_grad = compute_loss_gradient(output, target);

        // åå‘ä¼ æ’­
        Tensor grad_h2 = layer3.backward(loss_grad);
        Tensor grad_h1 = layer2.backward(grad_h2);
        Tensor grad_input = layer1.backward(grad_h1);

        // æ›´æ–°å‚æ•°
        update_parameters(layer1);
        update_parameters(layer2);
        update_parameters(layer3);

        // æ¸…é›¶æ¢¯åº¦
        layer1.zero_grad();
        layer2.zero_grad();
        layer3.zero_grad();
    }
}
```

### å†…å­˜é«˜æ•ˆä½¿ç”¨

```cpp
// ä¸ºé‡å¤æ¨ç†é¢„åˆ†é…è¾“å‡ºå¼ é‡
Linear layer(512, 256);
layer.set_backend(BackendManager::get_cpu_backend());
layer.eval();  // è®¾ç½®ä¸ºæ¨ç†æ¨¡å¼

Tensor input = backend->randn(Shape(1000, 512));
Tensor output = backend->zeros(Shape(1000, 256));  // é¢„åˆ†é…

// å¤ç”¨è¾“å‡ºå¼ é‡ï¼ˆæ— å†…å­˜åˆ†é…ï¼‰
for (int i = 0; i < 1000; ++i) {
    layer.forward_into(input, output);
    // å¤„ç†output...
}
```

## æ€§èƒ½ç‰¹ç‚¹

### å†…å­˜ä¼˜åŒ–
- **intoå‹æ–¹æ³•**: é¿å…ä¸å¿…è¦çš„å†…å­˜åˆ†é…ï¼Œå‡å°‘80%å†…å­˜åˆ†é…æ¬¡æ•°
- **å»¶è¿Ÿæ¢¯åº¦åˆ†é…**: åªåœ¨éœ€è¦æ—¶åˆ›å»ºæ¢¯åº¦å¼ é‡
- **æ™ºèƒ½ç¼“å­˜**: æ ¹æ®è®­ç»ƒ/æ¨ç†æ¨¡å¼è‡ªåŠ¨ç®¡ç†ç¼“å­˜
- **PyTorchå…¼å®¹å­˜å‚¨**: æƒé‡æ ¼å¼ä¸PyTorchä¸€è‡´ï¼Œæ— éœ€é¢å¤–è½¬æ¢å­˜å‚¨ï¼ˆV1.46.1æ›´æ–°ï¼‰

### è®¡ç®—ä¼˜åŒ–
- **é«˜æ•ˆçŸ©é˜µä¹˜æ³•**: ä½¿ç”¨CpuBackendçš„ä¼˜åŒ–å®ç°
- **å‘é‡åŒ–æ“ä½œ**: å……åˆ†åˆ©ç”¨SIMDæŒ‡ä»¤é›†
- **å†…å­˜è¿ç»­æ€§**: ä¿è¯æ•°æ®åœ¨å†…å­˜ä¸­çš„è¿ç»­å­˜å‚¨
- **æƒé‡æ ¼å¼ä¼˜åŒ–**: PyTorchæ ‡å‡†æ ¼å¼å­˜å‚¨ï¼Œå‰å‘ä¼ æ’­æ—¶è½¬ç½®ä½¿ç”¨

### è®¡ç®—å¤æ‚åº¦
- **å‰å‘ä¼ æ’­**: O(batch_size Ã— in_features Ã— out_features)
- **åå‘ä¼ æ’­**: O(batch_size Ã— in_features Ã— out_features)
- **å‚æ•°å­˜å‚¨**: O(in_features Ã— out_features + out_features)
- **æ¢¯åº¦å­˜å‚¨**: O(in_features Ã— out_features + out_features) (è®­ç»ƒæ—¶)

## æ³¨æ„äº‹é¡¹

1. **è¾“å…¥å½¢çŠ¶**: ç¡®ä¿è¾“å…¥çš„æœ€åä¸€ç»´ç­‰äº`in_features`
2. **åç«¯è®¾ç½®**: åœ¨ä½¿ç”¨å‰å¿…é¡»è°ƒç”¨`set_backend()`æ–¹æ³•
3. **æ¨¡å¼åˆ‡æ¢**: è®­ç»ƒæ—¶è°ƒç”¨`train()`ï¼Œæ¨ç†æ—¶è°ƒç”¨`eval()`
4. **æ¢¯åº¦ç®¡ç†**: è®­ç»ƒå¾ªç¯ä¸­è®°å¾—è°ƒç”¨`zero_grad()`æ¸…é›¶æ¢¯åº¦
5. **å†…å­˜ç®¡ç†**: ä½¿ç”¨intoå‹æ–¹æ³•å¯ä»¥è·å¾—æ›´å¥½çš„æ€§èƒ½

## æµ‹è¯•éªŒè¯

### å•å…ƒæµ‹è¯•ç»“æœ

Linearå±‚é€šè¿‡äº†ä»¥ä¸‹æµ‹è¯•ï¼š

1. **æ¨¡å—æ¢¯åº¦æ£€æŸ¥æµ‹è¯•** - éªŒè¯å‰å‘/åå‘ä¼ æ’­æ­£ç¡®æ€§
   ```
   Input shape: (4,3)
   Weight shape: (3,2)
   Forward pass successful, output shape: (4,2)
   Backward pass successful, grad_input shape: (4,3)
   [PASS] Basic module test PASSED!
   ```

2. **å†…å­˜åˆ†é…éªŒè¯æµ‹è¯•** - éªŒè¯å†…å­˜ä¼˜åŒ–æ•ˆæœ
   ```
   Traditional method: 5 iterations, 5 allocations
   Into method: 5 iterations, 1 allocation
   Memory savings: 80%
   ```

3. **MLPç«¯åˆ°ç«¯éªŒè¯æµ‹è¯•** - ä¸PyTorchå®Œå…¨ä¸€è‡´
   ```
   Module outputs are equal to PyTorch outputs
   my_loss_module: 0.0015
   loss: 0.0015
   Module loss matches PyTorch loss (diff: 0.0000)
   ```

### éªŒè¯æˆå°±

- **çœŸå®çŸ©é˜µä¹˜æ³•**: Linearå±‚ä½¿ç”¨`backend->mm_into()`è¿›è¡ŒçœŸå®çš„çŸ©é˜µè¿ç®—
- **æ•°å€¼æ­£ç¡®æ€§**: 3å±‚MLPç½‘ç»œè¾“å‡ºä¸PyTorchå®Œå…¨ä¸€è‡´
- **ç²¾åº¦éªŒè¯**: Lossè®¡ç®—ç»“æœå·®å€¼ä¸º0.0000ï¼Œè¾¾åˆ°é«˜ç²¾åº¦è¦æ±‚
- **ç«¯åˆ°ç«¯æµ‹è¯•**: å®Œæ•´çš„å‰å‘ä¼ æ’­é“¾æ¡æ­£å¸¸å·¥ä½œ

### æµ‹è¯•æ–‡ä»¶
- `tests/unit_tests/test_module_gradient.cpp` - æ¢¯åº¦æ£€æŸ¥æµ‹è¯•
- `tests/unit_tests/test_memory_allocation.cpp` - å†…å­˜åˆ†é…éªŒè¯æµ‹è¯•
- `tests/unit_tests/test_mlp_module.cpp` - MLPç«¯åˆ°ç«¯éªŒè¯æµ‹è¯•

## ç›¸å…³æ–‡æ¡£

- [ModuleåŸºç±»æ–‡æ¡£](module.md)
- [Tensoræ–‡æ¡£](tensor.md)
- [Backendæ–‡æ¡£](backend.md)
- [æ¢¯åº¦æ£€æŸ¥æµ‹è¯•](../tests/unit_tests/test_module_gradient.cpp)

## å†å²ç‰ˆæœ¬

- **V1.46.1** (2025-11-17): PyTorchå…¼å®¹æ€§é‡å¤§æ›´æ–°
  - æƒé‡å­˜å‚¨æ ¼å¼æ”¹ä¸ºPyTorchæ ‡å‡†æ ¼å¼`(out_features, in_features)`
  - ä¸PyTorchæ¨¡å‹æƒé‡å¯ç›´æ¥äº¤æ¢ä½¿ç”¨
  - æ›´æ–°å‰å‘ä¼ æ’­ä½¿ç”¨`input @ weight^T`è®¡ç®—
  - ç®€åŒ–åå‘ä¼ æ’­è®¡ç®—é€»è¾‘
  - æµ‹è¯•éªŒè¯ä¸PyTorchæ•°å€¼ç²¾åº¦å®Œå…¨ä¸€è‡´ï¼ˆdiff: 0.0000ï¼‰

- **V1.46.0** (2025-11-17): P0å…³é”®é—®é¢˜ä¿®å¤
  - Modelæ•°æ®æµé€»è¾‘ä¿®å¤
  - åˆå§‹åŒ–æ£€æŸ¥ä¿®å¤ï¼Œæ¿€æ´»é¢„åˆ†é…æœºåˆ¶
  - è®¾å¤‡è½¬ç§»ä¿®å¤

- **V1.45.0** (2025-11-17): åˆå§‹å®ç°ï¼ŒåŒ…å«å®Œæ•´çš„intoå‹æ–¹æ³•æ”¯æŒ
- æ”¯æŒXavieråˆå§‹åŒ–ã€é«˜æ€§èƒ½è®¡ç®—å’Œå®Œæ•´çš„æ¢¯åº¦ç®¡ç†

## å®ç°ç»†èŠ‚

### å‰å‘ä¼ æ’­å®ç°ï¼ˆV1.50.0ä¼˜åŒ–ç‰ˆï¼‰

```cpp
void forward_into(const Tensor& input, Tensor& output) override {
    cache_input(input);

    auto backend = get_backend();
    const Tensor& weight = get_parameter("weight");

    // â­ V1.50.0ï¼šç¡®ä¿è½¬ç½®æƒé‡ç¼“å­˜æœ‰æ•ˆ
    if (!weight_transposed_valid_) {
        // é¢„è®¡ç®—å¹¶ç¼“å­˜è½¬ç½®æƒé‡ï¼šweight^T (in_features, out_features)
        weight_transposed_ = backend->transpose(weight);
        weight_transposed_valid_ = true;
    }

    // â­ ä½¿ç”¨ç¼“å­˜çš„è½¬ç½®æƒé‡ï¼Œé¿å…è¿è¡Œæ—¶è½¬ç½®å¼€é”€
    // è®¡ç®—ï¼šoutput = input @ weight^T + bias
    // æƒé‡å½¢çŠ¶ï¼š(out_features, in_features) - PyTorchæ ‡å‡†æ ¼å¼
    // ç¼“å­˜è½¬ç½®æƒé‡å½¢çŠ¶ï¼š(in_features, out_features)
    // è¾“å…¥å½¢çŠ¶ï¼š(batch_size, in_features)
    // è¾“å‡ºå½¢çŠ¶ï¼š(batch_size, out_features)
    backend->mm_into(input, weight_transposed_, output);

    // å¦‚æœä½¿ç”¨åç½®ï¼Œè¿›è¡Œå¹¿æ’­åŠ æ³•
    if (use_bias_ && has_parameter("bias")) {
        const Tensor& bias = get_parameter("bias");
        backend->add_broadcast_into(output, bias, output);
    }
}
```

### åå‘ä¼ æ’­å®ç°ï¼ˆV1.50.0ç¼“å­˜ç®¡ç†ç‰ˆï¼‰

```cpp
void backward_into(const Tensor& grad_output, Tensor& grad_input) override {
    auto backend = get_backend();
    const Tensor& weight = get_parameter("weight");

    // è®¡ç®—è¾“å…¥æ¢¯åº¦ï¼šgrad_input = grad_output @ weight^T
    // ç”±äºæƒé‡å·²ç»æ˜¯PyTorchæ ¼å¼(out_features, in_features)ï¼Œç›´æ¥ä½¿ç”¨å³å¯
    // grad_output(batch, out_features) @ weight(out_features, in_features) = grad_input(batch, in_features)
    backend->mm_into(grad_output, weight, grad_input);

    // è®¡ç®—æƒé‡æ¢¯åº¦ï¼šgrad_weight = grad_output^T @ input
    if (weight.has_grad()) {
        // grad_output^T(out_features, batch) @ input(batch, in_features) = grad_weight(out_features, in_features)
        Tensor grad_output_t = backend->transpose(grad_output);
        Shape grad_weight_shape(grad_output_t.shape().dim(0), cached_input_.shape().dim(1));
        Tensor grad_weight = backend->zeros(grad_weight_shape, DType::FP32);
        backend->mm_into(grad_output_t, cached_input_, grad_weight);

        // ç´¯ç§¯æƒé‡æ¢¯åº¦
        if (!weight.grad().storage_allocated()) {
            weight.set_grad(grad_weight);
        } else {
            Tensor& existing_grad = weight.grad();
            backend->add_into(grad_weight, existing_grad, existing_grad);
        }
    }

    // è®¡ç®—åç½®æ¢¯åº¦ï¼šgrad_bias = sum(grad_output, dim=0)
    if (use_bias_ && has_parameter("bias")) {
        const Tensor& bias = get_parameter("bias");
        if (bias.has_grad()) {
            // å¯¹grad_outputçš„batchç»´åº¦æ±‚å’Œï¼šgrad_bias(out_features)
            Tensor grad_bias = backend->zeros(bias.shape(), DType::FP32);
            backend->sum_into(grad_output, grad_bias, 0, false);

            // ç´¯ç§¯åç½®æ¢¯åº¦
            if (!bias.grad().storage_allocated()) {
                bias.set_grad(grad_bias);
            } else {
                Tensor& existing_grad = bias.grad();
                backend->add_into(grad_bias, existing_grad, existing_grad);
            }
        }
    }

    clear_cache();

    // â­ V1.50.0ï¼šæƒé‡æ›´æ–°åï¼Œè½¬ç½®ç¼“å­˜å¤±æ•ˆ
    invalidate_weight_cache();
}
```

## é™åˆ¶å’Œå½“å‰çŠ¶æ€

### å½“å‰é™åˆ¶

1. **æƒé‡æ¢¯åº¦è®¡ç®—**ï¼šå½“å‰å®ç°è¾ƒä¸ºç®€åŒ–ï¼Œéœ€è¦å®Œæ•´çš„æƒé‡æ¢¯åº¦è®¡ç®—å®ç°
2. **åç½®æ¢¯åº¦**ï¼šç®€åŒ–å®ç°ï¼Œéœ€è¦å®Œæ•´çš„reduce_sumæ“ä½œ
3. **åå‘ä¼ æ’­è½¬ç½®å¼€é”€**ï¼šåå‘ä¼ æ’­æ—¶ä»éœ€è½¬ç½®æƒé‡ï¼ˆè¿™æ˜¯æ•°å­¦è¦æ±‚ï¼Œæ— æ³•é¿å…ï¼‰
4. **æ•°æ®ç±»å‹**ï¼šç›®å‰ä»…æ”¯æŒFP32
5. **è®¾å¤‡æ”¯æŒ**ï¼šCPUåç«¯å®Œå…¨æ”¯æŒï¼ŒCUDAåç«¯éœ€è¦æµ‹è¯•

### æœªæ¥å¢å¼º

1. **å®Œæ•´æƒé‡æ¢¯åº¦**ï¼šå®ç°çœŸå®çš„æƒé‡æ¢¯åº¦è®¡ç®— `grad_weight = grad_output^T @ input`
2. **å®Œæ•´åç½®æ¢¯åº¦**ï¼šå®ç°é«˜æ•ˆçš„reduce_sumæ“ä½œ
3. **åå‘ä¼ æ’­ä¼˜åŒ–**ï¼šè€ƒè™‘é¢„åˆ†é…è½¬ç½®æƒé‡ç¼“å†²åŒºä»¥å‡å°‘åå‘ä¼ æ’­å¼€é”€
4. **æ•°æ®ç±»å‹æ”¯æŒ**ï¼šæ·»åŠ FP16ã€BF16æ”¯æŒ
5. **æ‰¹å½’ä¸€åŒ–é›†æˆ**ï¼šä¸æ‰¹å½’ä¸€åŒ–ç»“åˆ
6. **æ¿€æ´»å‡½æ•°é›†æˆ**ï¼šæ·»åŠ æ¿€æ´»å‡½æ•°é›†æˆ
7. **Dropoutæ”¯æŒ**ï¼šæ·»åŠ DropoutåŠŸèƒ½

## æµ‹è¯•

### å•å…ƒæµ‹è¯•

è¯¥å±‚æµ‹è¯•åŒ…æ‹¬ï¼š

1. **æ¢¯åº¦æ£€æŸ¥**ï¼šæ•°å€¼å¾®åˆ†éªŒè¯
2. **å†…å­˜åˆ†é…**ï¼šéªŒè¯é«˜æ•ˆå†…å­˜ä½¿ç”¨
3. **å½¢çŠ¶æ¨æ–­**ï¼šæµ‹è¯•è¾“å…¥/è¾“å‡ºå½¢çŠ¶è®¡ç®—
4. **å‚æ•°è®¿é—®**ï¼šéªŒè¯å‚æ•°ç®¡ç†

### æµ‹è¯•æ–‡ä»¶

- `tests/unit_tests/test_module_gradient.cpp` - æ¢¯åº¦éªŒè¯
- `tests/unit_tests/test_memory_allocation.cpp` - å†…å­˜æ•ˆç‡æµ‹è¯•

## æ–‡ä»¶

- **å¤´æ–‡ä»¶**ï¼š`include/tech_renaissance/model/linear.h`
- **å®ç°**ï¼š`src/model/linear.cpp`
- **æµ‹è¯•**ï¼š`tests/unit_tests/test_module_gradient.cpp`

## ç›¸å…³æ–‡æ¡£

- [ModuleåŸºç±»](module.md) - åŸºç±»æ¥å£
- [Tensorç±»](tensor.md) - å¼ é‡æ“ä½œå’Œæ¢¯åº¦
- [åç«¯ç³»ç»Ÿ](backend.md) - è®¡ç®—æ“ä½œ
- [è®­ç»ƒç³»ç»Ÿ](trainer.md) - è®­ç»ƒå’Œä¼˜åŒ–