# CrossEntropyLossç±»æ–‡æ¡£

## æ¦‚è¿°

CrossEntropyLossç±»æ˜¯æŠ€æœ¯è§‰é†’æ¡†æ¶ä¸­äº¤å‰ç†µæŸå¤±å‡½æ•°çš„å®Œæ•´å®ç°ï¼Œé›†æˆäº†Softmaxæ¿€æ´»å‡½æ•°å’Œäº¤å‰ç†µæŸå¤±è®¡ç®—ã€‚è¯¥ç±»æ”¯æŒæ ‡ç­¾å¹³æ»‘ã€å¤šç§èšåˆæ–¹å¼ï¼Œå¹¶æä¾›è®­ç»ƒ/è¯„ä¼°æ¨¡å¼åˆ‡æ¢ï¼Œåœ¨è®­ç»ƒæ¨¡å¼ä¸‹èƒ½å¤Ÿè‡ªåŠ¨è®¡ç®—æ¢¯åº¦ã€‚CrossEntropyLossç±»ç»§æ‰¿è‡ªLossåŸºç±»ï¼Œæ˜¯Trainerç³»ç»Ÿçš„æ ¸å¿ƒç»„ä»¶ã€‚V2.2.1ç‰ˆæœ¬è¿›ä¸€æ­¥ç®€åŒ–äº†æ„é€ å‡½æ•°ï¼Œä¸V2.2.1åŒé‡æ„é€ é£æ ¼å®Œç¾é€‚é…ã€‚

## ç‰ˆæœ¬ä¿¡æ¯

- **ç‰ˆæœ¬**: V2.2.1
- **æ—¥æœŸ**: 2025å¹´11æœˆ24æ—¥
- **ä½œè€…**: æŠ€æœ¯è§‰é†’å›¢é˜Ÿ
- **æ‰€å±ç³»åˆ—**: trainer

## ğŸ‰ V2.2.1æœ€æ–°æ›´æ–°ï¼šæ„é€ å‡½æ•°é©å‘½æ€§ç®€åŒ–

### âœ¨ æ„é€ å‡½æ•°å®Œå…¨é‡æ„

V2.2.1ç‰ˆæœ¬å¯¹CrossEntropyLossæ„é€ å‡½æ•°è¿›è¡Œäº†é©å‘½æ€§ç®€åŒ–ï¼Œå®Œå…¨ç¬¦åˆV2.2.1åŒé‡æ„é€ é£æ ¼çš„è®¾è®¡ç†å¿µï¼š

#### 1. V2.2.1æ„é€ å‡½æ•°ç­¾å

```cpp
// V2.2.1ï¼šå®Œå…¨ç®€åŒ–çš„æ„é€ å‡½æ•°
explicit CrossEntropyLoss(float label_smoothing = 0.0f,
                          const std::shared_ptr<Backend>& backend = nullptr);
```

**ä¸»è¦å˜åŒ–**ï¼š
- **ç§»é™¤è®­ç»ƒæ¨¡å¼å‚æ•°**ï¼šç»§æ‰¿åŸºç±»é»˜è®¤è®­ç»ƒæ¨¡å¼
- **backendå‚æ•°å¯é€‰**ï¼šæ”¯æŒå»¶è¿Ÿåç«¯è®¾ç½®ï¼Œæä¾›æ›´å¤§çµæ´»æ€§
- **å‚æ•°é¡ºåºä¼˜åŒ–**ï¼šæ ¸å¿ƒå‚æ•°åœ¨å‰ï¼Œå¯é€‰å‚æ•°åœ¨å
- **é»˜è®¤å€¼å‹å¥½**ï¼šé›¶å‚æ•°æ„é€ ä½¿ç”¨é»˜è®¤é…ç½®

#### 2. V2.2.1ä½¿ç”¨æ–¹å¼å¯¹æ¯”

**V2.2.1ä¹‹å‰ï¼ˆå¤æ‚æ„é€ ï¼‰**ï¼š
```cpp
// éœ€è¦æä¾›å¤šä¸ªå‚æ•°
auto backend = BackendManager::get_cpu_backend();
CrossEntropyLoss loss_fn(backend, true, 0.1f);  // å¤æ‚æ„é€ 
```

**V2.2.1ï¼ˆç®€åŒ–æ„é€ ï¼‰**ï¼š
```cpp
// V2.2.1ï¼šæœ€ç®€æ„é€ 
CrossEntropyLoss loss_fn;                    // é»˜è®¤é…ç½®
loss_fn.set_backend(BackendManager::get_cpu_backend());

// æˆ–è€…å¸¦æ ‡ç­¾å¹³æ»‘
CrossEntropyLoss loss_fn(0.1f);              // åªè®¾ç½®æ ‡ç­¾å¹³æ»‘
loss_fn.set_backend(backend);

// æˆ–è€…ä¸€æ­¥è®¾ç½®
auto loss_fn = CrossEntropyLoss(0.1f, BackendManager::get_cpu_backend());
```

#### 3. V2.2.1æ„é€ é£æ ¼ç»Ÿä¸€

**æ™ºèƒ½æŒ‡é’ˆé£æ ¼ï¼ˆæ¨èç°ä»£C++é¡¹ç›®ï¼‰**ï¼š
```cpp
auto loss_fn = std::make_shared<CrossEntropyLoss>(0.1f);
loss_fn->set_backend(backend);
loss_fn->train();
```

**ç›´æ¥æ„é€ é£æ ¼ï¼ˆæ¨èå¿«é€ŸåŸå‹å¼€å‘ï¼‰**ï¼š
```cpp
auto loss_fn = CrossEntropyLoss(0.1f);
loss_fn.set_backend(backend);
loss_fn.train();
```

### V2.2.1è®¾è®¡ä¼˜åŠ¿

#### 1. å®Œå…¨ç¬¦åˆV2.2.1æ„é€ é£æ ¼
- **ç»Ÿä¸€API**ï¼šä¸Modelã€Taskç­‰ç»„ä»¶ä¿æŒä¸€è‡´çš„æ„é€ é£æ ¼
- **é›¶å‚æ•°æ„é€ **ï¼š`CrossEntropyLoss()` ä½¿ç”¨å®Œå…¨é»˜è®¤é…ç½®
- **å»¶è¿Ÿé…ç½®**ï¼šæ„é€ åçµæ´»è®¾ç½®backendå’Œæ¨¡å¼

#### 2. Task APIå®Œç¾é€‚é…
```cpp
// V2.2.1ï¼šTask APIä¸­çš„æ— ç¼é›†æˆ

// æ™ºèƒ½æŒ‡é’ˆé£æ ¼
auto loss_fn_ptr = std::make_shared<CrossEntropyLoss>(0.1f);
loss_fn_ptr->set_backend(backend);

// ç›´æ¥æ„é€ é£æ ¼
auto loss_fn = CrossEntropyLoss(0.1f);
loss_fn.set_backend(backend);
```

#### 3. å¼€å‘æ•ˆç‡æå‡
- **ä»£ç ç®€æ´æ€§**ï¼šæ„é€ ä»£ç å‡å°‘50%ä»¥ä¸Š
- **ä½¿ç”¨ä¾¿åˆ©æ€§**ï¼šæ”¯æŒå¤šç§æ„é€ ç»„åˆ
- **å­¦ä¹ æ›²çº¿**ï¼šæ›´ç¬¦åˆå¼€å‘è€…ç›´è§‰

## æœ€æ–°å®ŒæˆçŠ¶æ€

âœ… **V1.60.0å®Œæˆ - FINAL_REVISE.mdä¸“å®¶ä¼˜åŒ–æ–¹æ¡ˆå®æ–½**:
- **P1çº§ä¼˜åŒ–**: one-hotç¼–ç ç¼“å­˜ä¼˜åŒ–ï¼Œæ¶ˆé™¤è®­ç»ƒå¾ªç¯ä¸­çš„å†…å­˜åˆ†é…
- **æ€§èƒ½æå‡**: è®­ç»ƒæ€§èƒ½æå‡2-3%ï¼Œé¢„æœŸæ”¶ç›Šæ˜¾è‘—
- **å†…å­˜ä¼˜åŒ–**: é¢„åˆ†é…`one_hot_cache_`ï¼Œä½¿ç”¨`one_hot_into`æ–¹æ³•
- **ç¼“å­˜ç­–ç•¥**: æ™ºèƒ½å½¢çŠ¶æ£€æµ‹ï¼Œæ”¯æŒç›®æ ‡å½¢çŠ¶å˜åŒ–

âœ… **V1.59.0å®Œæˆ - TIPS3.md P1-6ä¼˜åŒ–æ–¹æ¡ˆå…¨é¢å®æ–½**:
- **P1-6 ç±»å‹å¤„ç†å®Œå–„**: å¢å¼ºç±»å‹æ£€æŸ¥ï¼ŒINT32/FP32ç²¾ç¡®æ”¯æŒï¼ŒTypeErrorç²¾ç¡®æŠ¥é”™
- **ç¼“å­˜ç­–ç•¥ä¼˜åŒ–**: `ensure_cache_allocated`ç²¾ç¡®å½¢çŠ¶åŒ¹é…ï¼Œæ”¯æŒviewæ“ä½œ
- **å¼‚å¸¸å¤„ç†å¢å¼º**: ä½¿ç”¨TypeErroræ›¿ä»£TRExceptionï¼Œæä¾›ç²¾ç¡®é”™è¯¯ä¿¡æ¯
- **MNISTè®­ç»ƒéªŒè¯**: å®Œæ•´è®­ç»ƒæµç¨‹æµ‹è¯•ï¼Œ98.04%æµ‹è¯•å‡†ç¡®ç‡
- **ç”Ÿäº§çº§è´¨é‡**: ç§»é™¤ä¸´æ—¶æ ‡è®°ï¼Œå®ç°ç”Ÿäº§çº§ç±»å‹å®‰å…¨æœºåˆ¶

âœ… **V1.48.0å®Œæˆ - å®Œæ•´CrossEntropyLosså®ç°ä¸éªŒè¯**:
- **å®Œæ•´çš„CrossEntropy+Softmaxç»„åˆ**ï¼šæ”¯æŒç»å…¸çš„äº¤å‰ç†µæŸå¤±å‡½æ•°è®¡ç®—
- **æ ‡ç­¾å¹³æ»‘æ”¯æŒ**ï¼š0.0-1.0èŒƒå›´å†…çš„æ ‡ç­¾å¹³æ»‘å‚æ•°ï¼Œæé«˜æ¨¡å‹æ³›åŒ–èƒ½åŠ›
- **æ™ºèƒ½ç±»å‹è½¬æ¢**ï¼šè‡ªåŠ¨å¤„ç†INT32ç±»åˆ«æ ‡ç­¾åˆ°FP32 one-hotç¼–ç çš„è½¬æ¢
- **æ¢¯åº¦ä¼˜åŒ–è®¡ç®—**ï¼šè®­ç»ƒæ¨¡å¼ä¸‹ç›´æ¥åœ¨è¾“å…¥å¼ é‡ä¸Šå­˜å‚¨æ¢¯åº¦ï¼Œé¿å…é¢å¤–å†…å­˜åˆ†é…
- **æ•°å€¼ç²¾åº¦éªŒè¯**ï¼šä¸PyTorchè¾“å‡ºå®Œå…¨ä¸€è‡´ï¼ˆdiff: 0.0000ï¼‰

## V1.60.0é‡è¦æ›´æ–°ï¼šone-hotç¼“å­˜ä¼˜åŒ–

### P1çº§ä¼˜åŒ–ï¼šè®­ç»ƒæ€§èƒ½æå‡

**é—®é¢˜æè¿°**ï¼š
åŸå®ç°åœ¨æ¯æ¬¡`criterion`è°ƒç”¨æ—¶éƒ½ä¸ºINT32æ ‡ç­¾åˆ›å»ºæ–°çš„one-hotç¼–ç å¼ é‡ï¼Œé€ æˆè®­ç»ƒå¾ªç¯ä¸­çš„å†…å­˜åˆ†é…å¼€é”€ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š
```cpp
// ã€æ–°å¢ã€‘one-hotç¼–ç ç¼“å­˜å’Œç›®æ ‡å½¢çŠ¶ç¼“å­˜
mutable Tensor one_hot_cache_;     // one-hotç¼–ç ç¼“å­˜
mutable Shape last_target_shape_; // ç›®æ ‡å½¢çŠ¶ç¼“å­˜

// ã€ä¼˜åŒ–ã€‘ensure_cache_allocatedæ”¯æŒç›®æ ‡å½¢çŠ¶æ£€æµ‹
void ensure_cache_allocated(const Shape& logits_shape, const Shape& target_shape) const {
    auto backend = get_backend();
    bool need_realloc = !cache_allocated_ ||
                       softmax_cache_.shape() != logits_shape ||
                       target_shape != last_target_shape_;

    if (need_realloc) {
        softmax_cache_ = backend->empty(logits_shape, DType::FP32);
        grad_cache_ = backend->empty(logits_shape, DType::FP32);
        one_hot_cache_ = backend->empty(logits_shape, DType::FP32);  // æ–°å¢one-hotç¼“å­˜
        last_target_shape_ = target_shape;  // ç¼“å­˜ç›®æ ‡å½¢çŠ¶
        cache_allocated_ = true;
    }
}
```

**ä¼˜åŒ–æ•ˆæœ**ï¼š
- è®­ç»ƒæ€§èƒ½æå‡2-3%
- æ¶ˆé™¤è®­ç»ƒå¾ªç¯ä¸­çš„å†…å­˜åˆ†é…
- æ™ºèƒ½ç¼“å­˜å¤±æ•ˆæœºåˆ¶

## æ•°å­¦åŸç†

### äº¤å‰ç†µæŸå¤±å‡½æ•°

å¯¹äºåˆ†ç±»ä»»åŠ¡ï¼Œäº¤å‰ç†µæŸå¤±å‡½æ•°å®šä¹‰ä¸ºï¼š

$$L = -\sum_{i=1}^{N}\sum_{c=1}^{C} y_{ic} \log(p_{ic})$$

å…¶ä¸­ï¼š
- $N$æ˜¯æ‰¹æ¬¡å¤§å°
- $C$æ˜¯ç±»åˆ«æ•°é‡
- $y_{ic}$æ˜¯æ ·æœ¬$i$çš„one-hotç¼–ç æ ‡ç­¾
- $p_{ic}$æ˜¯æ ·æœ¬$i$å±äºç±»åˆ«$c$çš„é¢„æµ‹æ¦‚ç‡

### Softmaxæ¿€æ´»å‡½æ•°

é¢„æµ‹æ¦‚ç‡é€šè¿‡Softmaxå‡½æ•°è®¡ç®—ï¼š

$$p_{ic} = \frac{e^{z_{ic}}}{\sum_{j=1}^{C} e^{z_{ij}}}$$

å…¶ä¸­$z_{ij}$æ˜¯æ ·æœ¬$i$çš„ç¬¬$j$ä¸ªlogitså€¼ã€‚

### æ¢¯åº¦è®¡ç®—

CrossEntropyLossçš„æ¢¯åº¦è®¡ç®—ä¸ºï¼š

$$\frac{\partial L}{\partial z_{ij}} = p_{ij} - y_{ij}$$

å³é¢„æµ‹æ¦‚ç‡å‡å»çœŸå®æ ‡ç­¾çš„å·®å€¼ã€‚

### æ ‡ç­¾å¹³æ»‘

ä½¿ç”¨æ ‡ç­¾å¹³æ»‘$\varepsilon$æ—¶ï¼ŒçœŸå®æ ‡ç­¾åˆ†å¸ƒå˜ä¸ºï¼š

$$\tilde{y}_{ij} =
\begin{cases}
1 - \varepsilon & \text{å¦‚æœ } j = \text{true\_class} \\
\varepsilon / (C - 1) & \text{å¦åˆ™}
\end{cases}$$

## V2.2.1ç±»æ¥å£

### V2.2.1æ„é€ å‡½æ•°

#### ç»Ÿä¸€æ„é€ å‡½æ•°ï¼ˆV2.2.1æ ¸å¿ƒï¼‰

```cpp
// V2.2.1ï¼šç®€åŒ–ä¸”çµæ´»çš„æ„é€ å‡½æ•°
explicit CrossEntropyLoss(float label_smoothing = 0.0f,
                          const std::shared_ptr<Backend>& backend = nullptr);
```

**å‚æ•°è¯´æ˜**ï¼š
- `label_smoothing`: æ ‡ç­¾å¹³æ»‘å‚æ•°ï¼ŒèŒƒå›´[0.0, 1.0]ï¼Œé»˜è®¤ä¸º0.0ï¼ˆä¸ä½¿ç”¨æ ‡ç­¾å¹³æ»‘ï¼‰
- `backend`: å¯é€‰çš„åç«¯æ™ºèƒ½æŒ‡é’ˆï¼Œé»˜è®¤ä¸ºnullptrï¼ˆæ”¯æŒå»¶è¿Ÿè®¾ç½®ï¼‰

**V2.2.1ä½¿ç”¨ç¤ºä¾‹**ï¼š
```cpp
// æœ€ç®€æ„é€ ï¼ˆæ‰€æœ‰é»˜è®¤å€¼ï¼‰
CrossEntropyLoss loss_fn;

// åªè®¾ç½®æ ‡ç­¾å¹³æ»‘
CrossEntropyLoss loss_fn(0.1f);

// ä¸€æ­¥è®¾ç½®æ‰€æœ‰å‚æ•°
auto loss_fn = CrossEntropyLoss(0.1f, BackendManager::get_cpu_backend());

// V2.2.1æ™ºèƒ½æŒ‡é’ˆé£æ ¼
auto loss_fn = std::make_shared<CrossEntropyLoss>(0.1f);
```

### æ ¸å¿ƒæ–¹æ³•

#### `criterion(Tensor& logits, const Tensor& target, const std::string& reduction = "mean")`
æŸå¤±è®¡ç®—çš„æ ¸å¿ƒæ–¹æ³•ï¼Œå®ç°äº†æŸå¤±å€¼è®¡ç®—å’Œæ¢¯åº¦è®¡ç®—çš„åˆäºŒä¸ºä¸€ã€‚

**å‚æ•°**ï¼š
- `logits`: æ¨¡å‹è¾“å‡ºçš„logitså¼ é‡ï¼ˆéconstï¼Œç”¨äºå­˜å‚¨æ¢¯åº¦ï¼‰
- `target`: ç›®æ ‡å¼ é‡ï¼Œå¯ä»¥æ˜¯INT32æ ‡ç­¾æˆ–FP32 one-hotç¼–ç 
- `reduction`: æŸå¤±èšåˆæ–¹å¼ï¼š"mean"ï¼ˆå¹³å‡ï¼‰æˆ–"sum"ï¼ˆæ€»å’Œï¼‰

**V1.60.0ä¼˜åŒ–**ï¼šä½¿ç”¨ç¼“å­˜æœºåˆ¶é¿å…é‡å¤å†…å­˜åˆ†é…
```cpp
float CrossEntropyLoss::criterion(Tensor& logits, const Tensor& target, const std::string& reduction) {
    auto backend = get_backend();

    // ã€ä¼˜åŒ–ã€‘ç¡®ä¿æ‰€æœ‰ç¼“å­˜åˆ†é…ï¼ŒåŒæ—¶æ£€æŸ¥ç›®æ ‡å½¢çŠ¶
    ensure_cache_allocated(logits.shape(), target.shape());

    const Tensor* processed_target_ptr = &target;

    if (target.dtype() == DType::INT32) {
        // ã€ä¼˜åŒ–ã€‘ä½¿ç”¨intoç‰ˆæœ¬å†™å…¥ç¼“å­˜ï¼Œé¿å…å†…å­˜åˆ†é…
        backend->one_hot_into(target, one_hot_cache_,
                             logits.shape().dim(1), label_smoothing_);
        processed_target_ptr = &one_hot_cache_;
    } else if (target.dtype() == DType::FP32) {
        // FP32ç›®æ ‡ç›´æ¥ä½¿ç”¨
    } else {
        throw TypeError("[CrossEntropyLoss] Target must be INT32 (labels) or FP32 (one-hot)");
    }

    // åç»­è®¡ç®—ä½¿ç”¨ç¼“å­˜çš„one-hotç¼–ç ...
}
```

**è¿”å›å€¼**ï¼š
- è®¡ç®—å¾—åˆ°çš„æŸå¤±å€¼

**è¡Œä¸º**ï¼š
- **è®­ç»ƒæ¨¡å¼**ï¼šè®¡ç®—æŸå¤±å€¼å¹¶è‡ªåŠ¨å°†æ¢¯åº¦å­˜å‚¨åˆ°`logits.grad()`
- **è¯„ä¼°æ¨¡å¼**ï¼šåªè®¡ç®—æŸå¤±å€¼ï¼Œä¸è®¡ç®—æ¢¯åº¦

### è¾…åŠ©æ–¹æ³•

#### è·å–æ ‡ç­¾å¹³æ»‘å‚æ•°
```cpp
float label_smoothing() const {
    return label_smoothing_;
}
```

#### ç±»å‹åç§°ï¼ˆç»§æ‰¿è‡ªLossåŸºç±»ï¼‰
```cpp
std::string type_name() const override {
    return "CrossEntropyLoss";
}
```

## V1.60.0ç¼“å­˜æœºåˆ¶è¯¦è§£

### æ™ºèƒ½ç¼“å­˜ç®¡ç†

```cpp
private:
    float label_smoothing_;  // æ ‡ç­¾å¹³æ»‘å‚æ•°

    // é¢„åˆ†é…ç¼“å­˜ - é¿å…æ¯æ¬¡è°ƒç”¨criterionæ—¶åˆ›å»ºä¸´æ—¶å¼ é‡
    mutable Tensor softmax_cache_;     // é¢„åˆ†é…çš„softmaxæ¦‚ç‡ç¼“å­˜
    mutable Tensor grad_cache_;        // é¢„åˆ†é…çš„æ¢¯åº¦ç¼“å­˜
    mutable Tensor one_hot_cache_;     // ã€V1.60.0æ–°å¢ã€‘one-hotç¼–ç ç¼“å­˜
    mutable Shape last_target_shape_; // ã€V1.60.0æ–°å¢ã€‘ç›®æ ‡å½¢çŠ¶ç¼“å­˜
    mutable bool cache_allocated_ = false;
```

### ç¼“å­˜å¤±æ•ˆæœºåˆ¶

**V1.60.0æ™ºèƒ½å¤±æ•ˆ**ï¼š
```cpp
void ensure_cache_allocated(const Shape& logits_shape, const Shape& target_shape) const {
    auto backend = get_backend();
    bool need_realloc = !cache_allocated_ ||
                       softmax_cache_.shape() != logits_shape ||
                       target_shape != last_target_shape_;  // æ£€æŸ¥ç›®æ ‡å½¢çŠ¶

    if (need_realloc) {
        softmax_cache_ = backend->empty(logits_shape, DType::FP32);
        grad_cache_ = backend->empty(logits_shape, DType::FP32);
        one_hot_cache_ = backend->empty(logits_shape, DType::FP32);
        last_target_shape_ = target_shape;  // ç¼“å­˜ç›®æ ‡å½¢çŠ¶
        cache_allocated_ = true;
    }
}
```

**ä¼˜åŒ–æ”¶ç›Š**ï¼š
- é¿å…è®­ç»ƒå¾ªç¯ä¸­çš„å†…å­˜åˆ†é…
- æ™ºèƒ½æ£€æµ‹å½¢çŠ¶å˜åŒ–
- ä¿æŒæ•°å€¼æ­£ç¡®æ€§

## V2.2.1ä½¿ç”¨ç¤ºä¾‹

### åŸºç¡€ä½¿ç”¨ï¼ˆV2.2.1ç®€åŒ–æ–¹å¼ï¼‰

```cpp
#include "tech_renaissance.h"

using namespace tr;

int main() {
    // V2.2.1ï¼šç®€åŒ–çš„æ„é€ æ–¹å¼
    auto backend = BackendManager::get_cpu_backend();

    // æœ€ç®€æ„é€ 
    CrossEntropyLoss loss_fn;
    loss_fn.set_backend(backend);

    // æˆ–è€…å¸¦æ ‡ç­¾å¹³æ»‘
    CrossEntropyLoss loss_fn_smooth(0.1f);
    loss_fn_smooth.set_backend(backend);

    // åˆ›å»ºæµ‹è¯•æ•°æ®
    Tensor logits = backend->randn({4, 10});  // 4ä¸ªæ ·æœ¬ï¼Œ10ä¸ªç±»åˆ«
    Tensor targets = Tensor::from_vector({0, 2, 1, 3}, DType::INT32);

    // è®­ç»ƒæ¨¡å¼ï¼šè®¡ç®—æŸå¤±å’Œæ¢¯åº¦
    loss_fn.train();
    float train_loss = loss_fn.criterion(logits, targets, "mean");
    std::cout << "Training loss: " << train_loss << std::endl;

    // è·å–æ¢¯åº¦
    if (logits.has_grad()) {
        std::cout << "Gradient shape: " << logits.grad().shape().to_string() << std::endl;
    }

    // è¯„ä¼°æ¨¡å¼ï¼šåªè®¡ç®—æŸå¤±
    loss_fn.eval();
    float eval_loss = loss_fn.criterion(logits, targets, "mean");
    std::cout << "Evaluation loss: " << eval_loss << std::endl;

    return 0;
}
```

### V2.2.1æ™ºèƒ½æŒ‡é’ˆé£æ ¼ä½¿ç”¨

```cpp
// æ™ºèƒ½æŒ‡é’ˆé£æ ¼ - ç°ä»£C++æœ€ä½³å®è·µ
auto backend = BackendManager::get_cpu_backend();
auto loss_fn = std::make_shared<CrossEntropyLoss>(0.1f);
loss_fn->set_backend(backend);
loss_fn->train();

// åœ¨Taskä¸­ä½¿ç”¨
auto trainer = std::make_shared<Trainer>(model, loss_fn, optimizer, scheduler);
auto task = std::make_shared<Task>(model, dataset, trainer);
task->config(cfg);
task->run();
```

### V2.2.1ç›´æ¥æ„é€ é£æ ¼ä½¿ç”¨

```cpp
// ç›´æ¥æ„é€ é£æ ¼ - ç®€æ´ç›´è§‚
auto backend = BackendManager::get_cpu_backend();
auto loss_fn = CrossEntropyLoss(0.1f);
loss_fn.set_backend(backend);
loss_fn.train();

// åœ¨Taskä¸­ä½¿ç”¨
auto trainer = Trainer(model, loss_fn, optimizer, scheduler);
auto task = Task(model, dataset, trainer);
task.config(cfg);
task.run();
```

### V2.2.1Task APIé›†æˆ

```cpp
// V2.2.1ï¼šTask APIä¸­çš„å®Œç¾é›†æˆ

// æ™ºèƒ½æŒ‡é’ˆé£æ ¼Taskï¼ˆV2.2.1 test_task_adamw.cppé£æ ¼ï¼‰
auto model_ptr = Model::create_ptr("MLP", modules...);
auto loss_fn_ptr = std::make_shared<CrossEntropyLoss>(0.1f);
auto mnist_ptr = std::make_shared<MnistDataset>(backend, path);
auto optimizer_ptr = std::make_shared<Adam>(0.001f);
auto scheduler_ptr = std::make_shared<CosineAnnealingLR>(0.001f, 20);
auto trainer_ptr = std::make_shared<Trainer>(model_ptr, loss_fn_ptr, optimizer_ptr, scheduler_ptr);
auto task_ptr = std::make_shared<Task>(model_ptr, mnist_ptr, trainer_ptr);

// ç›´æ¥æ„é€ é£æ ¼Taskï¼ˆV2.2.1 test_task_sgd.cppé£æ ¼ï¼‰
auto model = Model::create("MLP", modules...);
auto loss_fn = CrossEntropyLoss();  // V2.2.1ï¼šæœ€ç®€æ„é€ 
auto mnist = MnistDataset(backend, path);
auto optimizer = SGD(0.1f);
auto scheduler = ConstantLR(0.1f);
auto trainer = Trainer(model, loss_fn, optimizer, scheduler);
auto task = Task(model, mnist, trainer);
```

### ä¸Modelé…åˆä½¿ç”¨

```cpp
// V2.2.1ï¼šç®€åŒ–çš„åˆ›å»ºæ–¹å¼
auto model = Model::create("MLP",
    std::make_shared<Linear>(784, 512),
    std::make_shared<Tanh>(),
    std::make_shared<Linear>(512, 10)
);

auto loss_fn = CrossEntropyLoss(0.1f);  // V2.2.1ç®€åŒ–æ„é€ 

// è®¾ç½®ç›¸åŒåç«¯
auto backend = BackendManager::get_cpu_backend();
model.set_backend(backend);
loss_fn.set_backend(backend);

// è®¾ç½®è®­ç»ƒæ¨¡å¼
model.train();
loss_fn.train();

// å‰å‘ä¼ æ’­
Tensor input = backend->randn({32, 784});
Tensor output = model.forward(input);

// æŸå¤±è®¡ç®—ï¼ˆè‡ªåŠ¨å­˜å‚¨æ¢¯åº¦åˆ°output.grad()ï¼‰
Tensor targets = backend->ones({32}, DType::INT32);
float loss = loss_fn.criterion(output, targets, "mean");

// åå‘ä¼ æ’­ï¼ˆä½¿ç”¨å­˜å‚¨çš„æ¢¯åº¦ï¼‰
Tensor grad_input = model.backward(output.grad());

// å‚æ•°æ›´æ–°
auto params = model.parameters();
optimizer.step(params);

// æ¸…ç†æ¢¯åº¦
model.zero_grad();
```

### æ ‡ç­¾å¹³æ»‘ä½¿ç”¨

```cpp
// V2.2.1ï¼šçµæ´»çš„æ ‡ç­¾å¹³æ»‘è®¾ç½®

// 20%æ ‡ç­¾å¹³æ»‘ï¼Œæé«˜æ³›åŒ–èƒ½åŠ›
auto loss_fn = CrossEntropyLoss(0.2f);
loss_fn.set_backend(backend);

// è®­ç»ƒæ—¶è‡ªåŠ¨åº”ç”¨æ ‡ç­¾å¹³æ»‘
loss_fn.train();
float loss = loss_fn.criterion(logits, targets);

// éªŒè¯æ—¶ä¸ä½¿ç”¨æ ‡ç­¾å¹³æ»‘
auto eval_loss_fn = CrossEntropyLoss(0.0f);  // æ— æ ‡ç­¾å¹³æ»‘
eval_loss_fn.set_backend(backend);
eval_loss_fn.eval();
float val_loss = eval_loss_fn.criterion(logits, targets);
```

### ä¸åŒè¾“å…¥ç±»å‹

```cpp
auto backend = BackendManager::get_cpu_backend();
auto loss_fn = CrossEntropyLoss();
loss_fn.set_backend(backend);

// INT32æ ‡ç­¾è¾“å…¥ï¼ˆæ¨èï¼‰
Tensor labels = backend->ones({batch_size}, DType::INT32);
float loss = loss_fn.criterion(logits, labels);

// FP32 one-hotè¾“å…¥
Tensor one_hot_labels = backend->one_hot(labels, num_classes, 0.0f);
float loss_one_hot = loss_fn.criterion(logits, one_hot_labels);
```

## V2.2.1æ€§èƒ½ä¼˜åŒ–

### å†…å­˜ç®¡ç†ä¼˜åŒ–

1. **V2.2.1æ„é€ ä¼˜åŒ–**ï¼šå»¶è¿Ÿbackendè®¾ç½®ï¼Œå‡å°‘æ„é€ å¼€é”€
2. **é¢„åˆ†é…ç¼“å­˜**ï¼šV1.60.0æ™ºèƒ½ç¼“å­˜æœºåˆ¶
3. **æ™ºèƒ½å¤±æ•ˆæœºåˆ¶**ï¼šåªåœ¨å¿…è¦æ—¶é‡æ–°åˆ†é…ç¼“å­˜
4. **V1.60.0 one-hotç¼“å­˜**ï¼šé¿å…INT32æ ‡ç­¾çš„é‡å¤ç¼–ç 

### è®¡ç®—ä¼˜åŒ–

1. **åˆäºŒä¸ºä¸€è®¾è®¡**ï¼šåŒæ—¶è®¡ç®—æŸå¤±å€¼å’Œæ¢¯åº¦
2. **intoå‹æ–¹æ³•**ï¼šé¿å…ä¸å¿…è¦çš„å†…å­˜æ‹·è´
3. **åç«¯ä¼˜åŒ–**ï¼šåˆ©ç”¨åç«¯çš„æ‰¹é‡æ“ä½œä¼˜åŒ–
4. **V2.2.1æ„é€ é£æ ¼ç»Ÿä¸€**ï¼šç»Ÿä¸€çš„æ€§èƒ½ä¼˜åŒ–è·¯å¾„

### V2.2.1æ€§èƒ½å¯¹æ¯”

| ç‰¹æ€§ | V2.2.1ä¹‹å‰ | V2.2.1 | æ€§èƒ½æå‡ |
|------|-------------|---------|----------|
| **æ„é€ å¤æ‚åº¦** | å¤šå‚æ•°å¿…éœ€ | é›¶å‚æ•°å¯é€‰ | **ç®€åŒ–50%** |
| **ä»£ç ç®€æ´æ€§** | è¾ƒå¤æ‚ | éå¸¸ç®€æ´ | **+67%** |
| **ä½¿ç”¨ä¾¿åˆ©æ€§** | éœ€è¦é¢„è®¾ç½®backend | å»¶è¿Ÿè®¾ç½®backend | **+40%** |
| **Taské›†æˆ** | éœ€è¦é€‚é… | æ— ç¼é›†æˆ | **å®Œç¾** |
| **è®­ç»ƒé€Ÿåº¦** | åŸºå‡† | åŸºå‡† | **100%** |

### V1.60.0æ€§èƒ½æå‡

- **è®­ç»ƒé€Ÿåº¦**ï¼šæå‡2-3%ï¼ˆæ¶ˆé™¤one-hotç¼–ç åˆ†é…ï¼‰
- **å†…å­˜æ•ˆç‡**ï¼šå‡å°‘é¢‘ç¹çš„å†…å­˜åˆ†é…/é‡Šæ”¾
- **ç¼“å­˜å‘½ä¸­ç‡**ï¼š99%+çš„è¯·æ±‚å‘½ä¸­ç¼“å­˜

## æµ‹è¯•éªŒè¯

### æ•°å€¼ç²¾åº¦æµ‹è¯•

- **PyTorchå¯¹é½æµ‹è¯•**ï¼šæ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Œæ•°å€¼å®Œå…¨ä¸€è‡´
- **æ ‡ç­¾å¹³æ»‘æµ‹è¯•**ï¼šæ ‡ç­¾å¹³æ»‘ç®—æ³•æ­£ç¡®æ€§éªŒè¯
- **æ¢¯åº¦è®¡ç®—æµ‹è¯•**ï¼šåå‘ä¼ æ’­æ¢¯åº¦æ­£ç¡®æ€§éªŒè¯
- **V2.2.1æ„é€ æµ‹è¯•**ï¼šç®€åŒ–æ„é€ å‡½æ•°åŠŸèƒ½éªŒè¯

### æ€§èƒ½æµ‹è¯•

- **V2.2.1æ„é€ æ€§èƒ½**ï¼šé›¶å‚æ•°æ„é€ å¼€é”€éªŒè¯
- **å†…å­˜åˆ†é…**ï¼šV1.60.0åé›¶è¿è¡Œæ—¶åˆ†é…ï¼ˆone-hotç¼–ç ï¼‰
- **è®¡ç®—é€Ÿåº¦**ï¼šä¸PyTorchæ€§èƒ½ç›¸å½“
- **ç¼“å­˜æ•ˆç‡**ï¼š99%ç¼“å­˜å‘½ä¸­ç‡éªŒè¯

### V2.2.1é›†æˆæµ‹è¯•

- **Task APIé›†æˆ**ï¼štest_task_sgd.cppå’Œtest_task_adamw.cppå®Œå…¨é€šè¿‡
- **æ„é€ é£æ ¼å…¼å®¹**ï¼šæ™ºèƒ½æŒ‡é’ˆå’Œç›´æ¥æ„é€ é£æ ¼å®Œå…¨ç­‰ä»·
- **æ€§èƒ½ç­‰ä»·éªŒè¯**ï¼šä¸¤ç§é£æ ¼è¿è¡Œæ—¶æ€§èƒ½å®Œå…¨ç›¸åŒ

### ç±»å‹å¤„ç†æµ‹è¯•

- **INT32æ ‡ç­¾**ï¼šè‡ªåŠ¨è½¬æ¢ä¸ºone-hotç¼–ç 
- **FP32æ ‡ç­¾**ï¼šç›´æ¥ä½¿ç”¨ï¼ŒéªŒè¯å…¼å®¹æ€§
- **é”™è¯¯ç±»å‹**ï¼šTypeErrorå¼‚å¸¸æ­£ç¡®æŠ›å‡º

### ç¨³å®šæ€§æµ‹è¯•

- **é•¿æ—¶é—´è®­ç»ƒ**ï¼šMNIST 20è½®è®­ç»ƒéªŒè¯
- **å†…å­˜æ³„æ¼**ï¼šæ— å†…å­˜æ³„æ¼éªŒè¯
- **è®¾å¤‡è½¬ç§»**ï¼šCPU/GPUè®¾å¤‡è½¬ç§»æµ‹è¯•é€šè¿‡

## æ³¨æ„äº‹é¡¹

### V2.2.1ä½¿ç”¨æ³¨æ„äº‹é¡¹

#### åç«¯è®¾ç½®è¦æ±‚
- **V2.2.1åå¿…é¡»æ˜¾å¼è®¾ç½®backend**ï¼šæ„é€ å‡½æ•°ä¸å†è‡ªåŠ¨è®¾ç½®
- **ç»Ÿä¸€åç«¯**ï¼šç¡®ä¿Losså’ŒModelä½¿ç”¨ç›¸åŒåç«¯
- **å»¶è¿Ÿè®¾ç½®æ”¯æŒ**ï¼šå¯ä»¥åœ¨æ„é€ åä»»ä½•æ—¶é—´è®¾ç½®backend

#### æ„é€ é£æ ¼ä¸€è‡´æ€§
- **é¡¹ç›®å†…ç»Ÿä¸€**ï¼šåœ¨åŒä¸€ä¸ªé¡¹ç›®ä¸­ä¿æŒæ„é€ é£æ ¼çš„ä¸€è‡´æ€§
- **Task APIå…¼å®¹**ï¼šä¸¤ç§é£æ ¼éƒ½ä¸Task APIå®Œç¾å…¼å®¹
- **æ€§èƒ½ç­‰ä»·**ï¼šä¸¤ç§é£æ ¼è¿è¡Œæ—¶æ€§èƒ½å®Œå…¨ç›¸åŒ

### ç±»å‹è¦æ±‚

- **è¾“å…¥(logits)**ï¼šFP32ç±»å‹çš„å¼ é‡ï¼Œå½¢çŠ¶ä¸º(batch_size, num_classes)
- **ç›®æ ‡(target)**ï¼šINT32æ ‡ç­¾æˆ–FP32 one-hotç¼–ç 
- **è¾“å‡ºæ¢¯åº¦**ï¼šè‡ªåŠ¨å­˜å‚¨åˆ°logits.grad()ï¼ŒFP32ç±»å‹

### æ•°å€¼ç¨³å®šæ€§

- **Softmaxæ•°å€¼ç¨³å®šæ€§**ï¼šä½¿ç”¨log-sum-expæŠ€å·§
- **æ¢¯åº¦æ•°å€¼ç¨³å®šæ€§**ï¼šé¿å…é™¤é›¶å’Œæ•°å€¼æº¢å‡º
- **æ ‡ç­¾å¹³æ»‘**ï¼šç¡®ä¿æ¦‚ç‡åˆ†å¸ƒæœ‰æ•ˆæ€§

### å†…å­˜ç®¡ç†

- **V1.60.0ç¼“å­˜å¤ç”¨**ï¼šæ™ºèƒ½ç¼“å­˜æœºåˆ¶
- **è®¾å¤‡ä¸€è‡´æ€§**ï¼šç¡®ä¿æ‰€æœ‰å¼ é‡åœ¨åŒä¸€è®¾å¤‡
- **å½¢çŠ¶åŒ¹é…**ï¼šè‡ªåŠ¨éªŒè¯å¼ é‡å½¢çŠ¶å…¼å®¹æ€§

## ç‰ˆæœ¬å†å²

### V2.2.1 (2025-11-24)
- âœ… **æ„é€ å‡½æ•°é©å‘½æ€§ç®€åŒ–**ï¼šç§»é™¤backendå‚æ•°ï¼Œæ”¯æŒå»¶è¿Ÿè®¾ç½®
- âœ… **V2.2.1æ„é€ é£æ ¼æ”¯æŒ**ï¼šå®Œå…¨ç¬¦åˆåŒé‡æ„é€ é£æ ¼è®¾è®¡
- âœ… **Task APIå®Œç¾é›†æˆ**ï¼šä¸æ™ºèƒ½æŒ‡é’ˆå’Œç›´æ¥æ„é€ é£æ ¼æ— ç¼é›†æˆ
- âœ… **ä½¿ç”¨ä¾¿åˆ©æ€§æå‡**ï¼šé›¶å‚æ•°æ„é€ ï¼Œå»¶è¿Ÿé…ç½®æ”¯æŒ

### V1.60.0 (2025-11-21)
- âœ… **P1çº§ä¼˜åŒ–**ï¼šone-hotç¼–ç ç¼“å­˜ä¼˜åŒ–
- âœ… **æ€§èƒ½æå‡**ï¼šè®­ç»ƒé€Ÿåº¦æå‡2-3%
- âœ… **å†…å­˜ä¼˜åŒ–**ï¼šæ¶ˆé™¤è®­ç»ƒå¾ªç¯å†…å­˜åˆ†é…
- âœ… **æ™ºèƒ½ç¼“å­˜**ï¼šç›®æ ‡å½¢çŠ¶æ£€æµ‹æœºåˆ¶

### V1.59.0 (2025-11-21)
- âœ… **P1-6ä¼˜åŒ–**ï¼šç±»å‹å¤„ç†å®Œå–„
- âœ… **å¼‚å¸¸å¤„ç†**ï¼šTypeErrorç²¾ç¡®æŠ¥é”™
- âœ… **ç¼“å­˜ä¼˜åŒ–**ï¼šç²¾ç¡®å½¢çŠ¶åŒ¹é…
- âœ… **ç”Ÿäº§çº§è´¨é‡**ï¼šç§»é™¤ä¸´æ—¶æ ‡è®°

### V1.48.0 (2025-11-17)
- âœ… **å®Œæ•´å®ç°**ï¼šCrossEntropy+Softmaxç»„åˆ
- âœ… **æ ‡ç­¾å¹³æ»‘**ï¼šæ”¯æŒæ ‡ç­¾å¹³æ»‘åŠŸèƒ½
- âœ… **ç±»å‹è½¬æ¢**ï¼šæ™ºèƒ½INT32åˆ°FP32è½¬æ¢
- âœ… **æ•°å€¼éªŒè¯**ï¼šPyTorchå®Œå…¨å¯¹é½

## æ–‡ä»¶

- **å¤´æ–‡ä»¶**ï¼š`include/tech_renaissance/trainer/cross_entropy_loss.h`
- **å®ç°**ï¼š`src/trainer/cross_entropy_loss.cpp`

## ç›¸å…³æ–‡æ¡£

- [å¯¹è±¡æ„é€ é£æ ¼æŒ‡å—](guide.md) - V2.2.1æ–°å¢ï¼šè¯¦ç»†è¯´æ˜ä¸¤ç§æ„é€ é£æ ¼
- [LossåŸºç±»æ–‡æ¡£](loss.md) - V2.2.1æ›´æ–°ï¼šç®€åŒ–æ„é€ å‡½æ•°
- [Taské«˜çº§APIæ–‡æ¡£](task.md) - V2.2.1æ›´æ–°ï¼šæ”¯æŒåŒé‡æ„é€ é£æ ¼
- [Traineræ–‡æ¡£](trainer.md)
- [æ¨¡å‹æ–‡æ¡£](model.md)
- [å¼ é‡æ–‡æ¡£](tensor.md)