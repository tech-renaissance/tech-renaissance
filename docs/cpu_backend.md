# CpuBackend API æ–‡æ¡£

## # é‡è¦è­¦å‘Šï¼šCPUåç«¯å¼ é‡åˆ›å»ºæŒ‡å—ï¼

**CpuBackendæ˜¯æ¨èçš„åç«¯å¼ é‡åˆ›å»ºæ–¹å¼ï¼**

CPUåç«¯æä¾›äº†å®Œæ•´çš„å¼ é‡åˆ›å»ºå’Œæ“ä½œAPIï¼Œæ˜¯æ¡†æ¶çš„é»˜è®¤è®¡ç®—åç«¯ï¼š

**æ¨èçš„ä½¿ç”¨æ–¹å¼ï¼š**
```cpp
auto cpu_backend = std::dynamic_pointer_cast<CpuBackend>(
    BackendManager::instance().get_backend(CPU));

// åŸºç¡€å¼ é‡åˆ›å»ºï¼ˆè‡ªåŠ¨åˆ†é…å†…å­˜ï¼‰
Tensor zeros = cpu_backend->zeros({2, 3, 4}, DType::FP32);
Tensor ones = cpu_backend->ones({2, 3, 4}, DType::FP32);
Tensor full = cpu_backend->full({2, 3, 4}, 1.5f);
Tensor empty = cpu_backend->empty({2, 3, 4}, DType::FP32);

// éšæœºå¼ é‡ç”Ÿæˆ
Tensor randn = cpu_backend->randn({2, 3, 4}, 12345);
Tensor uniform = cpu_backend->uniform({2, 3, 4}, 0.0f, 1.0f, 54321);
Tensor randint = cpu_backend->randint({2, 3, 4}, 0, 10, DType::INT32, 99999);

// ç±»å‹è½¬æ¢
Tensor int32_tensor = cpu_backend->cast(fp32_tensor, DType::INT32);
Tensor int8_tensor = cpu_backend->cast(fp32_tensor, DType::INT8);
```

**ç»å¯¹ç¦æ­¢çš„æ–¹å¼ï¼š**
```cpp
// é”™è¯¯ï¼šç›´æ¥ä½¿ç”¨æ„é€ å‡½æ•°ä¸ä¼šåˆ†é…å†…å­˜ï¼
Tensor tensor(shape, dtype, CPU);  // æ®µé”™è¯¯ï¼

// é”™è¯¯ï¼šä½¿ç”¨Tensoré™æ€æ–¹æ³•ï¼ˆä¸æ¨èï¼‰
Tensor tensor = Tensor::zeros(shape, dtype, device);

// é”™è¯¯ï¼šè¯¯è®¤ä¸ºBackendåŸºç±»æœ‰è¿™äº›æ–¹æ³•ï¼ˆæ–¹æ³•åœ¨å­ç±»ä¸­å®ç°ï¼‰
auto backend = BackendManager::instance().get_backend(CPU);
Tensor tensor = backend->zeros(shape, dtype);  // ç¼–è¯‘é”™è¯¯ï¼
```

## æ¦‚è¿°

`CpuBackend`æ˜¯æŠ€æœ¯è§‰é†’æ¡†æ¶çš„CPUè®¡ç®—åç«¯å®ç°ï¼Œç»§æ‰¿è‡ª`Backend`åŸºç±»ã€‚å®ƒæä¾›äº†åŸºäºCPUçš„é«˜æ€§èƒ½å¼ é‡è®¡ç®—èƒ½åŠ›ï¼Œæ”¯æŒEigenåº“ä¼˜åŒ–å’Œå¤šçº¿ç¨‹å¹¶è¡Œè®¡ç®—ï¼Œæ˜¯æ¡†æ¶çš„é»˜è®¤å’ŒåŸºç¡€è®¡ç®—åç«¯ã€‚

**ç‰ˆæœ¬**: V1.43.0
**æ›´æ–°æ—¥æœŸ**: 2025-11-16
**ä½œè€…**: æŠ€æœ¯è§‰é†’å›¢é˜Ÿ

## ğŸ†• V1.43.0é‡å¤§æ›´æ–°

### ğŸ¯ æ–°å¢çš„é«˜çº§æ“ä½œ

åœ¨V1.43.0ç‰ˆæœ¬ä¸­ï¼ŒCPUåç«¯æ–°å¢äº†å¤šä¸ªé«˜çº§æ“ä½œæ–¹æ³•ï¼š

#### è§†å›¾æ“ä½œ
```cpp
Tensor view(const Tensor& input, const Shape& new_shape) override;
```
**ç‰¹æ€§**:
- é›¶æ‹·è´å¼ é‡å˜æ¢ï¼Œå…±äº«åº•å±‚å­˜å‚¨
- æ”¯æŒè¿ç»­å¼ é‡çš„å½¢çŠ¶é‡è§£é‡Š
- è‡ªåŠ¨å†…å­˜ç®¡ç†ï¼ŒåŸºäºshared_ptr
- å¯å†™è§†å›¾ï¼Œä¿®æ”¹ä¼šåæ˜ åœ¨åŸå§‹å¼ é‡ä¸Š

#### å½¢çŠ¶å˜æ¢æ“ä½œ
```cpp
Tensor reshape(const Tensor& tensor_a, const Shape& shape) override;
void reshape_inplace(Tensor& tensor_a, const Shape& shape) override;
void reshape_into(const Tensor& tensor_a, Tensor& result, const Shape& shape) override;
```

#### åŒæ›²å‡½æ•°æ“ä½œ
```cpp
Tensor tanh(const Tensor& tensor_a) override;
void tanh_inplace(Tensor& tensor_a) override;
void tanh_into(const Tensor& tensor_a, Tensor& result) override;
Tensor dtanh(const Tensor& tensor_a) override;
void dtanh_inplace(Tensor& tensor_a) override;
void dtanh_into(const Tensor& tensor_a, Tensor& result) override;
```

#### æŸå¤±å‡½æ•°æ“ä½œ
```cpp
float crossentropy(const Tensor& pred, const Tensor& label, std::string reduction = "mean") override;
```

#### One-hotç¼–ç æ“ä½œ
```cpp
Tensor one_hot(const Tensor& label, int32_t num_classes, float label_smoothing = 0.0f) override;
void one_hot_into(const Tensor& label, Tensor& result, int32_t num_classes, float label_smoothing = 0.0f) override;
```

#### æ ‡é‡è¿ç®—å’Œå¹¿æ’­è¿ç®—
```cpp
// æ‰€æœ‰V1.43.0æ–°å¢çš„æ ‡é‡è¿ç®—å’Œå¹¿æ’­è¿ç®—æ–¹æ³•éƒ½å·²å®ç°
// åŒ…æ‹¬minusã€macã€clampä»¥åŠå„ç§å¹¿æ’­è¿ç®—
```

### âœ… é‡æ„å…¼å®¹æ€§

- **100%å‘åå…¼å®¹**ï¼šæ‰€æœ‰ç°æœ‰ä»£ç æ— éœ€ä¿®æ”¹å³å¯æ­£å¸¸å·¥ä½œ
- **æ€§èƒ½ä¼˜åŒ–**ï¼šæ–°å¢æ–¹æ³•åŸºäºEigenåº“ä¼˜åŒ–ï¼Œæä¾›é«˜æ€§èƒ½è®¡ç®—
- **å¼‚å¸¸å¤„ç†**ï¼šå®Œå–„çš„é”™è¯¯æ£€æŸ¥å’Œå¼‚å¸¸å¤„ç†æœºåˆ¶

## è®¾è®¡ç†å¿µ

### æ ¸å¿ƒè®¾è®¡åŸåˆ™

1. **è¡Œä¸»åºå­˜å‚¨**ï¼šCPUåç«¯ä½¿ç”¨**è¡Œä¸»åºï¼ˆRow-majorï¼‰**å­˜å‚¨å¼ é‡æ•°æ®ï¼Œç¬¦åˆC/C++è¯­è¨€æƒ¯ä¾‹
2. **é«˜æ€§èƒ½è®¡ç®—**ï¼šåŸºäºEigenåº“çš„SIMDä¼˜åŒ–ï¼Œæ”¯æŒå¤šçº¿ç¨‹å¹¶è¡Œè®¡ç®—
3. **è·¨åç«¯å…¼å®¹**ï¼šé€šè¿‡`from_cpu()`å’Œ`to_cpu()`æ–¹æ³•ä¸å…¶ä»–åç«¯ä¿æŒæ•°æ®ä¸€è‡´æ€§
4. **å†…å­˜å®‰å…¨**ï¼šRAIIæ™ºèƒ½æŒ‡é’ˆè‡ªåŠ¨å†…å­˜ç®¡ç†ï¼Œ64å­—èŠ‚å¯¹é½ä¼˜åŒ–SIMDè®¿é—®
5. **ç±»å‹å®‰å…¨**ï¼šå¼ºç±»å‹è®¾è®¡é˜²æ­¢æ•°æ®ç±»å‹é”™è¯¯ï¼Œå®Œå–„çš„è¾¹ç•Œæ£€æŸ¥
6. **ğŸ†• å®é©±åŠ¨æ‰©å±•**ï¼šé€šè¿‡V1.43.0çš„å®ç³»ç»Ÿå¿«é€Ÿå®ç°æ–°æ–¹æ³•

### å…³é”®æ¶æ„ç‰¹æ€§

#### **åç«¯ç®¡ç†å­˜å‚¨åŸåˆ™ï¼ˆæ ¸å¿ƒç‰¹æ€§ï¼‰**

CPUåç«¯éµå¾ª"åç«¯ç®¡ç†å­˜å‚¨"çš„è®¾è®¡åŸåˆ™ï¼š
- **CPUåç«¯**ï¼šä½¿ç”¨è¡Œä¸»åºï¼ˆRow-majorï¼‰å­˜å‚¨å¼ é‡æ•°æ®ï¼Œç¬¦åˆC/C++æƒ¯ä¾‹
- **CUDAåç«¯**ï¼šä½¿ç”¨åˆ—ä¸»åºï¼ˆColumn-majorï¼‰å­˜å‚¨å¼ é‡æ•°æ®ï¼Œä¸cuBLASåº“ä¸€è‡´
- **è½¬æ¢å±‚é€æ˜**ï¼šç”¨æˆ·æ— éœ€å…³å¿ƒåº•å±‚å­˜å‚¨æ ¼å¼ï¼Œ`from_cpu()`å’Œ`to_cpu()`è‡ªåŠ¨å¤„ç†è½¬æ¢

#### **è¡Œä¸»åºå­˜å‚¨å¸ƒå±€**

```cpp
// CPUå¼ é‡ä½¿ç”¨è¡Œä¸»åºå­˜å‚¨
// 2DçŸ©é˜µ A[M,N] = [[1, 2, 3],
//                  [4, 5, 6]]
// å†…å­˜å¸ƒå±€ï¼š[1, 2, 3, 4, 5, 6]
// è®¿é—®æ–¹å¼ï¼šdata[i * N + j] è·å–ç¬¬iè¡Œç¬¬jåˆ—å…ƒç´ 

// çŸ©é˜µä¹˜æ³•ï¼šC[M,N] = A[M,K] Ã— B[K,N]
for (int32_t i = 0; i < M; ++i) {
    for (int32_t j = 0; j < N; ++j) {
        float sum = 0.0f;
        for (int32_t k = 0; k < K; ++k) {
            sum += a_data[i * K + k] * b_data[k * N + j];
        }
        result_data[i * N + j] = sum;
    }
}
```

## å¤´æ–‡ä»¶

```cpp
#include "tech_renaissance/backend/cpu_backend.h"
```

## ä¸»è¦ç‰¹æ€§

- **è¡Œä¸»åºå­˜å‚¨**ï¼šä½¿ç”¨è¡Œä¸»åºå­˜å‚¨æ ¼å¼ï¼Œç¬¦åˆC/C++è¯­è¨€æƒ¯ä¾‹
- **Eigenä¼˜åŒ–**ï¼šé›†æˆEigenåº“æä¾›é«˜æ€§èƒ½çº¿æ€§ä»£æ•°è®¡ç®—å’ŒSIMDä¼˜åŒ–
- **å¤šçº¿ç¨‹æ”¯æŒ**ï¼šåŸºäºOpenMPçš„å¹¶è¡Œè®¡ç®—ï¼Œå……åˆ†åˆ©ç”¨å¤šæ ¸CPUæ€§èƒ½
- **å†…å­˜å¯¹é½**ï¼š64å­—èŠ‚å¯¹é½ä¼˜åŒ–ï¼Œæœ€å¤§åŒ–ç¼“å­˜æ•ˆç‡
- **ğŸ†• é«˜çº§æ“ä½œæ”¯æŒ**ï¼šV1.43.0æ–°å¢å½¢çŠ¶å˜æ¢ã€æ¿€æ´»å‡½æ•°ã€æŸå¤±å‡½æ•°ç­‰é«˜çº§æ“ä½œ

## æ„é€ å‡½æ•°

```cpp
CpuBackend();
```

**æè¿°**ï¼šæ„é€ CPUåç«¯å®ä¾‹ï¼Œå†…éƒ¨è°ƒç”¨`Backend(true)`è¿›è¡Œåˆå§‹åŒ–ã€‚

**ç‰¹æ€§**ï¼š
- è‡ªåŠ¨åˆå§‹åŒ–Eigenåº“
- è®¾ç½®OpenMPå¹¶è¡Œè®¡ç®—ç¯å¢ƒ
- é…ç½®å†…å­˜å¯¹é½å‚æ•°

**ç¤ºä¾‹**ï¼š
```cpp
auto cpu_backend = std::make_shared<CpuBackend>();
```

## å¼ é‡åˆ›å»ºæ¥å£

### `Tensor zeros(const Shape& shape, DType dtype = DType::FP32)`

åˆ›å»ºå…¨é›¶å¼ é‡ã€‚

**å‚æ•°**ï¼š
- `shape` - å¼ é‡å½¢çŠ¶
- `dtype` - æ•°æ®ç±»å‹ï¼ˆå¯é€‰ï¼Œé»˜è®¤FP32ï¼‰

**è¿”å›å€¼**ï¼š
- `Tensor` - å…¨é›¶å¼ é‡

**å¼‚å¸¸**ï¼š
- `TRException` - å½“å¼ é‡è¿‡å¤§æˆ–å†…å­˜ä¸è¶³æ—¶æŠ›å‡º

**ç¤ºä¾‹**ï¼š
```cpp
Tensor zeros = cpu_backend->zeros({2, 3, 4}, DType::FP32);
```

### `Tensor ones(const Shape& shape, DType dtype = DType::FP32)`

åˆ›å»ºå…¨ä¸€å¼ é‡ã€‚

**å‚æ•°**ï¼š
- `shape` - å¼ é‡å½¢çŠ¶
- `dtype` - æ•°æ®ç±»å‹ï¼ˆå¯é€‰ï¼Œé»˜è®¤FP32ï¼‰

**è¿”å›å€¼**ï¼š
- `Tensor` - å…¨ä¸€å¼ é‡

**ç¤ºä¾‹**ï¼š
```cpp
Tensor ones = cpu_backend->ones({2, 3}, DType::INT32);
```

### `Tensor full(const Shape& shape, float value, DType dtype = DType::FP32)`

åˆ›å»ºå¡«å……æŒ‡å®šå€¼çš„å¼ é‡ã€‚

**å‚æ•°**ï¼š
- `shape` - å¼ é‡å½¢çŠ¶
- `value` - å¡«å……å€¼
- `dtype` - æ•°æ®ç±»å‹ï¼ˆå¯é€‰ï¼Œé»˜è®¤FP32ï¼‰

**è¿”å›å€¼**ï¼š
- `Tensor` - å¡«å……å¼ é‡

**ç¤ºä¾‹**ï¼š
```cpp
Tensor full = cpu_backend->full({2, 3}, 3.14f, DType::FP32);
```

### `Tensor empty(const Shape& shape, DType dtype = DType::FP32)`

åˆ›å»ºæœªåˆå§‹åŒ–çš„å¼ é‡ï¼ˆä»…åˆ†é…å†…å­˜ï¼‰ã€‚

**å‚æ•°**ï¼š
- `shape` - å¼ é‡å½¢çŠ¶
- `dtype` - æ•°æ®ç±»å‹ï¼ˆå¯é€‰ï¼Œé»˜è®¤FP32ï¼‰

**è¿”å›å€¼**ï¼š
- `Tensor` - æœªåˆå§‹åŒ–çš„å¼ é‡

**æ³¨æ„**ï¼šå¼ é‡å†…å®¹æœªåˆå§‹åŒ–ï¼Œä½¿ç”¨å‰å¿…é¡»å…ˆå¡«å……æ•°æ®ã€‚

**ç¤ºä¾‹**ï¼š
```cpp
Tensor empty = cpu_backend->empty({1000, 1000}, DType::FP32);
cpu_backend->fill(empty, 0.0f);  // ä½¿ç”¨å‰å…ˆå¡«å……
```

## éšæœºå¼ é‡ç”Ÿæˆæ¥å£

### `Tensor randn(const Shape& shape, uint64_t seed = 42)`

ç”Ÿæˆæ ‡å‡†æ­£æ€åˆ†å¸ƒéšæœºå¼ é‡ã€‚

**å‚æ•°**ï¼š
- `shape` - å¼ é‡å½¢çŠ¶
- `seed` - éšæœºç§å­ï¼ˆå¯é€‰ï¼Œé»˜è®¤42ï¼‰

**è¿”å›å€¼**ï¼š
- `Tensor` - æ ‡å‡†æ­£æ€åˆ†å¸ƒéšæœºå¼ é‡

**åˆ†å¸ƒ**ï¼šå‡å€¼=0ï¼Œæ ‡å‡†å·®=1çš„æ­£æ€åˆ†å¸ƒ

**ç¤ºä¾‹**ï¼š
```cpp
Tensor randn = cpu_backend->randn({2, 3, 4}, 12345);
```

### `Tensor uniform(const Shape& shape, float min_val = 0.0f, float max_val = 1.0f, uint64_t seed = 42)`

ç”Ÿæˆå‡åŒ€åˆ†å¸ƒéšæœºå¼ é‡ã€‚

**å‚æ•°**ï¼š
- `shape` - å¼ é‡å½¢çŠ¶
- `min_val` - æœ€å°å€¼ï¼ˆå¯é€‰ï¼Œé»˜è®¤0.0ï¼‰
- `max_val` - æœ€å¤§å€¼ï¼ˆå¯é€‰ï¼Œé»˜è®¤1.0ï¼‰
- `seed` - éšæœºç§å­ï¼ˆå¯é€‰ï¼Œé»˜è®¤42ï¼‰

**è¿”å›å€¼**ï¼š
- `Tensor` - å‡åŒ€åˆ†å¸ƒéšæœºå¼ é‡

**ç¤ºä¾‹**ï¼š
```cpp
Tensor uniform = cpu_backend->uniform({2, 3}, -5.0f, 5.0f, 54321);
```

### `Tensor randint(const Shape& shape, int32_t low, int32_t high, DType dtype = DType::INT32, uint64_t seed = 42)`

ç”Ÿæˆæ•´æ•°éšæœºå¼ é‡ã€‚

**å‚æ•°**ï¼š
- `shape` - å¼ é‡å½¢çŠ¶
- `low` - æœ€å°å€¼ï¼ˆåŒ…å«ï¼‰
- `high` - æœ€å¤§å€¼ï¼ˆä¸åŒ…å«ï¼‰
- `dtype` - æ•°æ®ç±»å‹ï¼ˆå¯é€‰ï¼Œé»˜è®¤INT32ï¼‰
- `seed` - éšæœºç§å­ï¼ˆå¯é€‰ï¼Œé»˜è®¤42ï¼‰

**è¿”å›å€¼**ï¼š
- `Tensor` - æ•´æ•°éšæœºå¼ é‡

**ç¤ºä¾‹**ï¼š
```cpp
Tensor randint = cpu_backend->randint({2, 3}, 0, 10, DType::INT32, 99999);
```

### `Tensor randbool(const Shape& shape, float zero_rate = 0.5f, uint64_t seed = 42)`

ç”Ÿæˆå¸ƒå°”éšæœºå¼ é‡ï¼ˆ0æˆ–1ï¼‰ã€‚

**å‚æ•°**ï¼š
- `shape` - å¼ é‡å½¢çŠ¶
- `zero_rate` - 0å€¼çš„æ¦‚ç‡ï¼ˆå¯é€‰ï¼Œé»˜è®¤0.5ï¼‰
- `seed` - éšæœºç§å­ï¼ˆå¯é€‰ï¼Œé»˜è®¤42ï¼‰

**è¿”å›å€¼**ï¼š
- `Tensor` - å¸ƒå°”éšæœºå¼ é‡

**ç¤ºä¾‹**ï¼š
```cpp
Tensor randbool = cpu_backend->randbool({2, 3}, 0.3f, 77777);
```

## ğŸ†• V1.43.0æ–°å¢é«˜çº§æ“ä½œ

### å½¢çŠ¶å˜æ¢æ“ä½œ

#### `Tensor reshape(const Tensor& tensor_a, const Shape& shape)`

æ”¹å˜å¼ é‡å½¢çŠ¶ï¼Œè¿”å›æ–°å¼ é‡ã€‚

**å‚æ•°**ï¼š
- `tensor_a` - è¾“å…¥å¼ é‡
- `shape` - ç›®æ ‡å½¢çŠ¶

**è¿”å›å€¼**ï¼š
- `Tensor` - é‡å¡‘åçš„å¼ é‡

**ç‰¹æ€§**ï¼š
- ä¿æŒæ•°æ®æ€»æ•°ä¸å˜ï¼š`tensor_a.numel() == shape.numel()`
- åˆ›å»ºæ–°å¼ é‡ï¼Œä¸ä¿®æ”¹åŸå¼ é‡
- åŸºäºEigençš„é«˜æ€§èƒ½å®ç°

**ç¤ºä¾‹**ï¼š
```cpp
Tensor input = cpu_backend->ones({2, 3, 4});
Tensor reshaped = cpu_backend->reshape(input, {2, 12});
```

#### `void reshape_inplace(Tensor& tensor_a, const Shape& shape)`

åŸåœ°æ”¹å˜å¼ é‡å½¢çŠ¶ã€‚

**å‚æ•°**ï¼š
- `tensor_a` - è¾“å…¥å¼ é‡ï¼Œä¼šè¢«ä¿®æ”¹
- `shape` - ç›®æ ‡å½¢çŠ¶

**ç‰¹æ€§**ï¼š
- å°±åœ°ä¿®æ”¹ï¼Œä¸åˆ›å»ºæ–°å¼ é‡
- å†…å­˜æ•ˆç‡æ›´é«˜
- ä¿æŒæ•°æ®æ€»æ•°ä¸å˜

**ç¤ºä¾‹**ï¼š
```cpp
Tensor tensor = cpu_backend->ones({2, 3, 4});
cpu_backend->reshape_inplace(tensor, {6, 4});  // tensorè¢«ä¿®æ”¹
```

#### `void reshape_into(const Tensor& tensor_a, Tensor& result, const Shape& shape)`

å°†è¾“å…¥å¼ é‡é‡å¡‘åˆ°ç›®æ ‡å¼ é‡ä¸­ã€‚

**å‚æ•°**ï¼š
- `tensor_a` - è¾“å…¥å¼ é‡
- `result` - ç›®æ ‡å¼ é‡ï¼Œä¼šè¢«ä¿®æ”¹
- `shape` - ç›®æ ‡å½¢çŠ¶

**ç‰¹æ€§**ï¼š
- å°†tensor_açš„æ•°æ®é‡å¡‘åˆ°resultä¸­
- resultå¿…é¡»å·²åˆ†é…è¶³å¤Ÿçš„å†…å­˜
- é«˜æ•ˆçš„æ•°æ®å¤åˆ¶æ“ä½œ

**ç¤ºä¾‹**ï¼š
```cpp
Tensor input = cpu_backend->ones({2, 3, 4});
Tensor result = cpu_backend->empty({6, 4});
cpu_backend->reshape_into(input, result, {6, 4});
```

### åŒæ›²å‡½æ•°æ“ä½œ

#### `Tensor tanh(const Tensor& tensor_a)`

è®¡ç®—åŒæ›²æ­£åˆ‡å‡½æ•°ã€‚

**å‚æ•°**ï¼š
- `tensor_a` - è¾“å…¥å¼ é‡

**è¿”å›å€¼**ï¼š
- `Tensor` - tanhç»“æœï¼š`tanh(x) = (e^x - e^-x) / (e^x + e^-x)`

**æ•°å­¦å…¬å¼**ï¼š
```
tanh(x) = (exp(x) - exp(-x)) / (exp(x) + exp(-x))
```

**ç¤ºä¾‹**ï¼š
```cpp
Tensor input = cpu_backend->randn({2, 3});
Tensor tanh_result = cpu_backend->tanh(input);
```

#### `Tensor dtanh(const Tensor& tensor_a)`

è®¡ç®—åŒæ›²æ­£åˆ‡å‡½æ•°çš„å¯¼æ•°ã€‚

**å‚æ•°**ï¼š
- `tensor_a` - è¾“å…¥å¼ é‡

**è¿”å›å€¼**ï¼š
- `Tensor` - dtanhç»“æœï¼š`dtanh(x) = 1 - tanh(x)^2`

**æ•°å­¦å…¬å¼**ï¼š
```
dtanh(x) = 1 - tanh(x)^2
```

**ç”¨é€”**ï¼šç¥ç»ç½‘ç»œåå‘ä¼ æ’­ä¸­çš„æ¢¯åº¦è®¡ç®—

**ç¤ºä¾‹**ï¼š
```cpp
Tensor tanh_output = cpu_backend->tanh(input);
Tensor grad = cpu_backend->dtanh(tanh_output);
```

### æŸå¤±å‡½æ•°æ“ä½œ

#### `float crossentropy(const Tensor& pred, const Tensor& label, std::string reduction = "mean")`

è®¡ç®—äº¤å‰ç†µæŸå¤±ã€‚

**å‚æ•°**ï¼š
- `pred` - é¢„æµ‹å¼ é‡ï¼Œå½¢çŠ¶ä¸º[batch_size, num_classes]
- `label` - æ ‡ç­¾å¼ é‡ï¼Œå½¢çŠ¶ä¸º[batch_size]æˆ–[batch_size, num_classes]
- `reduction` - çº¦ç®€æ–¹å¼ï¼š"mean"ï¼ˆå¹³å‡ï¼‰æˆ–"sum"ï¼ˆæ±‚å’Œï¼‰

**è¿”å›å€¼**ï¼š
- `float` - äº¤å‰ç†µæŸå¤±å€¼

**æ•°å­¦å…¬å¼**ï¼š
```
CE(p, y) = -âˆ‘(i) y[i] * log(p[i])
```

**è¦æ±‚**ï¼š
- predæ•°æ®ç±»å‹ï¼šFP32
- labelæ•°æ®ç±»å‹ï¼šINT32ï¼ˆç±»åˆ«ç´¢å¼•ï¼‰æˆ–FP32ï¼ˆone-hotç¼–ç ï¼‰
- predå’Œlabelçš„batch_sizeå¿…é¡»ç›¸åŒ

**ç¤ºä¾‹**ï¼š
```cpp
// ç±»åˆ«ç´¢å¼•æ–¹å¼
Tensor pred = cpu_backend->randn({4, 10});  // 4ä¸ªæ ·æœ¬ï¼Œ10ä¸ªç±»åˆ«
Tensor labels = cpu_backend->ones({4}, DType::INT32);  // ç±»åˆ«1
float loss = cpu_backend->crossentropy(pred, labels, "mean");

// One-hotç¼–ç æ–¹å¼
Tensor one_hot_labels = cpu_backend->one_hot(labels, 10);
float loss2 = cpu_backend->crossentropy(pred, one_hot_labels, "mean");
```

### One-hotç¼–ç æ“ä½œ

#### `Tensor one_hot(const Tensor& label, int32_t num_classes, float label_smoothing = 0.0f)`

å°†ç±»åˆ«æ ‡ç­¾è½¬æ¢ä¸ºone-hotç¼–ç ã€‚

**å‚æ•°**ï¼š
- `label` - æ ‡ç­¾å¼ é‡ï¼Œå½¢çŠ¶ä¸º[batch_size]ï¼Œæ•°æ®ç±»å‹INT32
- `num_classes` - ç±»åˆ«æ€»æ•°
- `label_smoothing` - æ ‡ç­¾å¹³æ»‘å‚æ•°ï¼ˆå¯é€‰ï¼Œé»˜è®¤0.0ï¼‰

**è¿”å›å€¼**ï¼š
- `Tensor` - one-hotç¼–ç å¼ é‡ï¼Œå½¢çŠ¶ä¸º[batch_size, num_classes]

**æ•°å­¦å…¬å¼**ï¼š
- æ— æ ‡ç­¾å¹³æ»‘ï¼š`one_hot[i, label[i]] = 1`
- æœ‰æ ‡ç­¾å¹³æ»‘ï¼š`one_hot[i, label[i]] = 1 - Îµ`ï¼Œ`one_hot[i, jâ‰ label[i]] = Îµ/(num_classes-1)`

**ç¤ºä¾‹**ï¼š
```cpp
Tensor labels = Tensor::from_vector({0, 2, 1, 3}, DType::INT32);  // 4ä¸ªæ ‡ç­¾
Tensor one_hot = cpu_backend->one_hot(labels, 10, 0.1f);  // 10ä¸ªç±»åˆ«ï¼Œæ ‡ç­¾å¹³æ»‘0.1
```

### æ ‡é‡è¿ç®—æ“ä½œ

#### `Tensor minus(const Tensor& input, float scalar) const`

å¼ é‡å‡å»æ ‡é‡ï¼š`result = input - scalar`

#### `Tensor minus(float scalar, const Tensor& input) const`

æ ‡é‡å‡å»å¼ é‡ï¼š`result = scalar - input`

#### `Tensor mac(const Tensor& input, float scalar_x, float scalar_y) const`

ä¹˜åŠ è¿ç®—ï¼š`result = input * scalar_x + scalar_y`

#### `Tensor clamp(const Tensor& input, float min_val, float max_val) const`

å¼ é‡è£å‰ªï¼šå°†è¾“å…¥å¼ é‡é™åˆ¶åœ¨[min_val, max_val]èŒƒå›´å†…

**ç¤ºä¾‹**ï¼š
```cpp
Tensor input = cpu_backend->randn({2, 3});
Tensor result1 = cpu_backend->minus(input, 1.0f);  // input - 1.0
Tensor result2 = cpu_backend->minus(2.0f, input);  // 2.0 - input
Tensor result3 = cpu_backend->mac(input, 2.0f, 1.0f);  // input * 2.0 + 1.0
Tensor result4 = cpu_backend->clamp(input, -1.0f, 1.0f);  // é™åˆ¶åœ¨[-1,1]èŒƒå›´å†…
```

### å¹¿æ’­è¿ç®—æ“ä½œ

#### `Tensor add_broadcast(const Tensor& tensor_a, const Tensor& tensor_b) const`

å¹¿æ’­åŠ æ³•ï¼šæ”¯æŒä¸åŒå½¢çŠ¶çš„å¼ é‡ç›¸åŠ 

#### `Tensor mul_broadcast(const Tensor& tensor_a, const Tensor& tensor_b) const`

å¹¿æ’­ä¹˜æ³•ï¼šæ”¯æŒä¸åŒå½¢çŠ¶çš„å¼ é‡ç›¸ä¹˜

**å¹¿æ’­è§„åˆ™**ï¼š
- ä»å³å‘å·¦æ¯”è¾ƒç»´åº¦
- ç»´åº¦å¤§å°ç›¸ç­‰æˆ–å…¶ä¸­ä¸€ä¸ªä¸º1åˆ™å¯å¹¿æ’­
- ä¸åŒ¹é…çš„ç»´åº¦æ‰©å±•ä»¥åŒ¹é…è¾ƒå¤§çš„ç»´åº¦

**ç¤ºä¾‹**ï¼š
```cpp
Tensor a = cpu_backend->ones({2, 1, 3});  // å¯å¹¿æ’­åˆ° {2, 4, 3}
Tensor b = cpu_backend->ones({4, 3});     // å¯å¹¿æ’­åˆ° {2, 4, 3}
Tensor result = cpu_backend->add_broadcast(a, b);  // ç»“æœå½¢çŠ¶ {2, 4, 3}
```

## ç±»å‹è½¬æ¢æ¥å£

### `Tensor cast(const Tensor& tensor, DType target_dtype)`

å¼ é‡æ•°æ®ç±»å‹è½¬æ¢ã€‚

**å‚æ•°**ï¼š
- `tensor` - è¾“å…¥å¼ é‡
- `target_dtype` - ç›®æ ‡æ•°æ®ç±»å‹

**è¿”å›å€¼**ï¼š
- `Tensor` - è½¬æ¢åçš„å¼ é‡

**æ”¯æŒçš„è½¬æ¢**ï¼š
- FP32 â†’ INT32ï¼ˆæˆªæ–­å°æ•°éƒ¨åˆ†ï¼‰
- FP32 â†’ INT8ï¼ˆæˆªæ–­å¹¶é™åˆ¶åœ¨[-128, 127]èŒƒå›´ï¼‰
- INT32 â†’ FP32ï¼ˆç›´æ¥è½¬æ¢ï¼‰
- INT8 â†’ FP32ï¼ˆç›´æ¥è½¬æ¢ï¼‰

**ç¤ºä¾‹**ï¼š
```cpp
Tensor fp32_tensor = cpu_backend->randn({2, 3});
Tensor int32_tensor = cpu_backend->cast(fp32_tensor, DType::INT32);
```

## å†…å­˜ç®¡ç†æ¥å£

### `Tensor null_tensor()`

è¿”å›ç©ºå¼ é‡ï¼ˆä¸å ç”¨å†…å­˜ï¼‰ã€‚

**è¿”å›å€¼**ï¼š
- `Tensor` - ç©ºå¼ é‡

**ç”¨é€”**ï¼š
- å˜é‡åˆå§‹åŒ–
- å¼ é‡é”€æ¯åçš„çŠ¶æ€è®¾ç½®

**ç¤ºä¾‹**ï¼š
```cpp
Tensor empty_tensor = cpu_backend->null_tensor();
```

## ä½¿ç”¨ç¤ºä¾‹

### ğŸ†• V1.43.0æ–°åŠŸèƒ½ç¤ºä¾‹

```cpp
#include "tech_renaissance.h"
using namespace tr;

void v1_43_0_new_features() {
    auto cpu_backend = BackendManager::get_cpu_backend();

    // 1. å½¢çŠ¶å˜æ¢æ“ä½œ
    Tensor input = cpu_backend->randn({2, 3, 4}, 42);
    Tensor reshaped = cpu_backend->reshape(input, {2, 12});
    std::cout << "Reshaped tensor shape: " << reshaped.shape().to_string() << std::endl;

    // 2. åŒæ›²å‡½æ•°æ“ä½œ
    Tensor tanh_result = cpu_backend->tanh(input);
    Tensor dtanh_result = cpu_backend->dtanh(tanh_result);
    std::cout << "Tanh operation completed" << std::endl;

    // 3. äº¤å‰ç†µæŸå¤±è®¡ç®—
    Tensor pred = cpu_backend->randn({4, 10});
    Tensor labels = Tensor::from_vector({0, 2, 1, 3}, DType::INT32);
    float loss = cpu_backend->crossentropy(pred, labels, "mean");
    std::cout << "Cross entropy loss: " << loss << std::endl;

    // 4. One-hotç¼–ç 
    Tensor one_hot = cpu_backend->one_hot(labels, 10, 0.1f);
    std::cout << "One-hot encoding shape: " << one_hot.shape().to_string() << std::endl;

    // 5. æ ‡é‡è¿ç®—
    Tensor scaled = cpu_backend->mac(input, 2.0f, 1.0f);  // input * 2 + 1
    Tensor clamped = cpu_backend->clamp(input, -1.0f, 1.0f);

    // 6. å¹¿æ’­è¿ç®—
    Tensor a = cpu_backend->ones({2, 1, 3});
    Tensor b = cpu_backend->ones({4, 3});
    Tensor broadcast_result = cpu_backend->add_broadcast(a, b);
    std::cout << "Broadcast result shape: " << broadcast_result.shape().to_string() << std::endl;
}
```

### å®Œæ•´çš„ç¥ç»ç½‘ç»œç¤ºä¾‹

```cpp
#include "tech_renaissance.h"
using namespace tr;

void simple_neural_network() {
    auto cpu_backend = BackendManager::get_cpu_backend();

    // 1. åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
    Tensor input = cpu_backend->randn({4, 784});           // 4ä¸ªæ ·æœ¬ï¼Œ784ç»´è¾“å…¥
    Tensor labels = Tensor::from_vector({0, 1, 2, 3}, DType::INT32);  // 4ä¸ªç±»åˆ«æ ‡ç­¾

    // 2. çº¿æ€§å˜æ¢ï¼ˆæ¨¡æ‹Ÿå…¨è¿æ¥å±‚ï¼‰
    Tensor weights = cpu_backend->randn({784, 10});         // æƒé‡çŸ©é˜µ
    Tensor bias = cpu_backend->zeros({10});               // åç½®

    // çŸ©é˜µä¹˜æ³•ï¼šoutput = input Ã— weights + bias
    Tensor matmul_result = cpu_backend->empty({4, 10});
    cpu_backend->mm(matmul_result, input, weights);

    // åŠ åç½®
    Tensor biased = cpu_backend->add(matmul_result, bias);

    // 3. æ¿€æ´»å‡½æ•°
    Tensor activated = cpu_backend->tanh(biased);

    // 4. è®¡ç®—æŸå¤±
    float loss = cpu_backend->crossentropy(activated, labels, "mean");
    std::cout << "Neural network loss: " << loss << std::endl;

    // 5. åå‘ä¼ æ’­ï¼ˆç®€åŒ–ç‰ˆï¼‰
    Tensor grad_output = cpu_backend->dtanh(activated);  // tanhçš„å¯¼æ•°
    std::cout << "Gradient computed successfully" << std::endl;
}
```

### æ€§èƒ½æµ‹è¯•ç¤ºä¾‹

```cpp
void performance_test() {
    auto cpu_backend = BackendManager::get_cpu_backend();

    // æµ‹è¯•çŸ©é˜µä¹˜æ³•æ€§èƒ½
    const int M = 1024, K = 2048, N = 512;

    Tensor a = cpu_backend->randn({M, K});
    Tensor b = cpu_backend->randn({K, N});
    Tensor result = cpu_backend->empty({M, N});

    auto start = std::chrono::high_resolution_clock::now();
    cpu_backend->mm(result, a, b);
    auto end = std::chrono::high_resolution_clock::now();

    auto duration = std::chrono::duration_cast<std::chrono::microseconds>(end - start);
    double gflops = (2.0 * M * K * N) / (duration.count() * 1e6) / 1e9;

    std::cout << "CPU MM Performance: " << gflops << " GFLOPS" << std::endl;
    std::cout << "Execution time: " << duration.count() << " microseconds" << std::endl;
}
```

## æ€§èƒ½ç‰¹æ€§

### è®¡ç®—æ€§èƒ½

- **çŸ©é˜µä¹˜æ³•**ï¼šåŸºäºEigenåº“ä¼˜åŒ–ï¼Œæ”¯æŒSIMDæŒ‡ä»¤
- **å¤šçº¿ç¨‹å¹¶è¡Œ**ï¼šOpenMPè‡ªåŠ¨å¹¶è¡ŒåŒ–ï¼Œå……åˆ†åˆ©ç”¨å¤šæ ¸CPU
- **å†…å­˜å¯¹é½**ï¼š64å­—èŠ‚å¯¹é½ï¼Œæœ€å¤§åŒ–ç¼“å­˜å‘½ä¸­ç‡

### å†…å­˜æ•ˆç‡

- **æ™ºèƒ½æŒ‡é’ˆç®¡ç†**ï¼šè‡ªåŠ¨å†…å­˜å›æ”¶ï¼Œé¿å…å†…å­˜æ³„æ¼
- **å°±åœ°æ“ä½œ**ï¼šæä¾›inplaceç‰ˆæœ¬ï¼Œå‡å°‘å†…å­˜åˆ†é…
- **é›¶æ‹·è´ä¼˜åŒ–**ï¼šreshapeç­‰æ“ä½œæ— éœ€æ•°æ®å¤åˆ¶

### æ•°å€¼ç²¾åº¦

- **IEEE 754**ï¼šä¸¥æ ¼éµå¾ªIEEE 754æµ®ç‚¹æ•°æ ‡å‡†
- **æ•°å€¼ç¨³å®šæ€§**ï¼šç®—æ³•å®ç°è€ƒè™‘æ•°å€¼ç¨³å®šæ€§
- **ç²¾åº¦éªŒè¯**ï¼šä¸PyTorchç­‰æ¡†æ¶å¯¹æ¯”éªŒè¯

## é”™è¯¯å¤„ç†

### å¸¸è§å¼‚å¸¸

```cpp
try {
    auto cpu_backend = BackendManager::get_cpu_backend();

    // å½¢çŠ¶ä¸åŒ¹é…
    Tensor a = cpu_backend->ones({2, 3});
    Tensor b = cpu_backend->ones({3, 4});
    // Tensor result = cpu_backend->add(a, b);  // æŠ›å‡ºTRException

    // æ•°æ®ç±»å‹ä¸åŒ¹é…
    Tensor fp32_tensor = cpu_backend->ones({2, 3}, DType::FP32);
    Tensor int32_tensor = cpu_backend->ones({2, 3}, DType::INT32);
    // Tensor result = cpu_backend->add(fp32_tensor, int32_tensor);  // æŠ›å‡ºTRException

} catch (const TRException& e) {
    std::cerr << "CPU Backend error: " << e.what() << std::endl;
}
```

### é”™è¯¯ç±»å‹

- **å½¢çŠ¶é”™è¯¯**ï¼šå¼ é‡å½¢çŠ¶ä¸å…¼å®¹
- **ç±»å‹é”™è¯¯**ï¼šæ•°æ®ç±»å‹ä¸åŒ¹é…
- **å†…å­˜é”™è¯¯**ï¼šå†…å­˜åˆ†é…å¤±è´¥æˆ–ä¸è¶³
- **å‚æ•°é”™è¯¯**ï¼šå‡½æ•°å‚æ•°è¶…å‡ºæœ‰æ•ˆèŒƒå›´

## æœ€ä½³å®è·µ

1. **ä½¿ç”¨BackendManager**ï¼šé€šè¿‡BackendManagerè·å–CPUåç«¯å®ä¾‹
2. **ç±»å‹æ£€æŸ¥**ï¼šåœ¨è®¡ç®—å‰æ£€æŸ¥å¼ é‡çš„æ•°æ®ç±»å‹å’Œå½¢çŠ¶
3. **å†…å­˜ç®¡ç†**ï¼šåˆ©ç”¨å°±åœ°æ“ä½œå‡å°‘å†…å­˜åˆ†é…
4. **å¼‚å¸¸å¤„ç†**ï¼šæ‰€æœ‰æ“ä½œéƒ½åº”åŒ…å«é€‚å½“çš„å¼‚å¸¸å¤„ç†
5. **æ€§èƒ½ä¼˜åŒ–**ï¼šå¯¹äºå¤§å¼ é‡æ“ä½œï¼Œè€ƒè™‘ä½¿ç”¨å¤šçº¿ç¨‹å¹¶è¡Œ
6. **ğŸ†• åˆ©ç”¨æ–°ç‰¹æ€§**ï¼šä½¿ç”¨V1.43.0æ–°å¢çš„é«˜çº§æ“ä½œç®€åŒ–ä»£ç 

## ç‰ˆæœ¬ä¿¡æ¯

- **ç‰ˆæœ¬**: V1.43.0
- **æ›´æ–°æ—¥æœŸ**: 2025-11-16
- **ä½œè€…**: æŠ€æœ¯è§‰é†’å›¢é˜Ÿ
- **ä¸»è¦æ›´æ–°**:
  - ğŸ†• æ–°å¢å½¢çŠ¶å˜æ¢æ“ä½œï¼šreshapeç³»åˆ—æ–¹æ³•
  - ğŸ†• æ–°å¢åŒæ›²å‡½æ•°ï¼štanhã€dtanhç³»åˆ—æ–¹æ³•
  - ğŸ†• æ–°å¢æŸå¤±å‡½æ•°ï¼šcrossentropy
  - ğŸ†• æ–°å¢One-hotç¼–ç ï¼šone_hotç³»åˆ—æ–¹æ³•
  - ğŸ†• æ–°å¢æ ‡é‡è¿ç®—ï¼šminusã€macã€clampç³»åˆ—æ–¹æ³•
  - ğŸ†• æ–°å¢å¹¿æ’­è¿ç®—ï¼šadd_broadcastã€mul_broadcastç³»åˆ—æ–¹æ³•
  - âœ… æ‰€æœ‰æ–°æ–¹æ³•éƒ½åŸºäºEigenåº“ä¼˜åŒ–
  - âœ… 100%å‘åå…¼å®¹ï¼Œç°æœ‰ä»£ç æ— éœ€ä¿®æ”¹
  - âœ… å®Œå–„çš„å¼‚å¸¸å¤„ç†å’Œé”™è¯¯æ£€æŸ¥