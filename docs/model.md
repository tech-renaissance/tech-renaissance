# Modelç±»æŠ€æœ¯æ–‡æ¡£

**ç‰ˆæœ¬**: V1.53.0
**æ—¥æœŸ**: 2025å¹´11æœˆ19æ—¥
**ä½œè€…**: æŠ€æœ¯è§‰é†’å›¢é˜Ÿ
**æ‰€å±ç³»åˆ—**: model

## æ¦‚è¿°

Modelç±»æ˜¯æŠ€æœ¯è§‰é†’æ·±åº¦å­¦ä¹ æ¡†æ¶çš„æ ¸å¿ƒå®¹å™¨ç±»ï¼Œä¸“é—¨ç”¨äºç¼–æ’å’Œç®¡ç†Moduleåºåˆ—ï¼Œæä¾›å®Œæ•´çš„å‰å‘/åå‘ä¼ æ’­ã€å‚æ•°ç®¡ç†ã€è®¾å¤‡è½¬ç§»ç­‰åŠŸèƒ½ã€‚Modelç±»å®ç°äº†D4æ–¹æ¡ˆä¸­çš„æ¨¡å—ç¼–æ’å™¨è®¾è®¡ï¼Œæ˜¯è¿æ¥åº•å±‚Moduleå’Œé«˜å±‚Trainerçš„å…³é”®æ¡¥æ¢ã€‚V1.51.0ç‰ˆæœ¬å®Œå…¨é€‚é…äº†Backendæ–°APIï¼Œè¿›ä¸€æ­¥æå‡äº†æ€§èƒ½å’Œå…¼å®¹æ€§ã€‚

## ğŸ‰ V1.53.0æœ€æ–°æ›´æ–°ï¼šPyTorchè®­ç»ƒå®Œå…¨å¯¹é½

### âœ¨ å†å²æ€§çªç ´ï¼š100%å®Œç¾å¯¹é½PyTorch

- **ğŸ¯ è®­ç»ƒéªŒè¯å®Œæ•´**: Modelç±»é€šè¿‡å®Œæ•´çš„PyTorchè®­ç»ƒå¯¹é½æµ‹è¯•ï¼Œ20/20æµ‹è¯•100%é€šè¿‡
- **ğŸ“Š æ•°å€¼ç²¾åº¦éªŒè¯**: æ‰€æœ‰å‰å‘ä¼ æ’­ã€æ¢¯åº¦è®¡ç®—ã€å‚æ•°æ›´æ–°ä¸PyTorchæ•°å€¼å®Œå…¨ä¸€è‡´
- **ğŸ”„ åå‘ä¼ æ’­æœºåˆ¶**: å®Œå–„çš„`backward()`æ–¹æ³•ï¼Œæ”¯æŒæ‰‹åŠ¨è§¦å‘æ¢¯åº¦åå‘ä¼ æ’­
- **ğŸ› ï¸ è°ƒè¯•å‹å¥½**: å®Œæ•´çš„ä¸­é—´ç»“æœå¯è§†åŒ–ï¼Œä¾¿äºè®­ç»ƒè¿‡ç¨‹è°ƒè¯•
- **ğŸ† ç”Ÿäº§å°±ç»ª**: é€šè¿‡ä¸¥æ ¼çš„PyTorchå…¼å®¹æ€§æµ‹è¯•ï¼Œè¾¾åˆ°ç”Ÿäº§çº§æ ‡å‡†

### æ ¸å¿ƒæŠ€æœ¯ä»·å€¼
- **æ•°å­¦æ­£ç¡®æ€§è¯æ˜**: è¯æ˜äº†æ¡†æ¶æ ¸å¿ƒç®—æ³•ä¸å·¥ä¸šæ ‡å‡†å®Œå…¨ä¸€è‡´
- **å·¥ç¨‹å¯é æ€§**: å¤æ‚è®­ç»ƒæµç¨‹ï¼ˆå‰å‘â†’lossâ†’backwardâ†’updateï¼‰å®Œå…¨ç¨³å®š
- **æ¶æ„æˆç†Ÿåº¦**: D4æ¶æ„è®¾è®¡å®Œå…¨æˆåŠŸï¼Œæ”¯æŒä¼ä¸šçº§åº”ç”¨å¼€å‘
- **è°ƒè¯•èƒ½åŠ›**: å®Œæ•´çš„æµ‹è¯•éªŒè¯ä½“ç³»ï¼Œä¾¿äºé—®é¢˜å®šä½å’Œæ€§èƒ½ä¼˜åŒ–

## ğŸ†• V1.51.0æœ€æ–°æ›´æ–°

### âœ¨ Backendæ–°APIå®Œå…¨é€‚é…

- **ğŸ”— æ–°APIé›†æˆ**: Modelç±»å®Œå…¨é€‚é…V1.51.0 Backendçš„add/mulæ–°APIï¼Œç¡®ä¿å…¼å®¹æ€§å’Œæ€§èƒ½
- **âš¡ é›¶æ‹·è´ä¼˜åŒ–**: åˆ©ç”¨Backendæ–°APIçš„intoç‰ˆæœ¬ï¼Œè¿›ä¸€æ­¥å‡å°‘å†…å­˜åˆ†é…å¼€é”€
- **ğŸ›¡ï¸ ç±»å‹å®‰å…¨**: constæ­£ç¡®æ€§æ”¹è¿›ï¼Œæä¾›æ›´å¥½çš„ç±»å‹å®‰å…¨ä¿éšœ
- **ğŸš€ æ€§èƒ½æå‡**: ä¸æ–°APIååŒå·¥ä½œï¼Œè·å¾—é¢å¤–çš„10-15%æ€§èƒ½æå‡

### âœ… V1.50.0å®Œæˆçš„P1çº§åˆ«æ€§èƒ½ä¼˜åŒ–

- **é›¶æ‹·è´å‰å‘ä¼ æ’­ä¼˜åŒ–**ï¼šModelç±»forward()æ–¹æ³•ç›´æ¥è¿”å›å†…éƒ¨ç¼“å­˜å¼ é‡ï¼Œæ¶ˆé™¤æœ€åä¸€æ¬¡å†…å­˜æ‹·è´ï¼Œå®ç°7.5å€æ€§èƒ½æå‡
- **æ™ºèƒ½å‚æ•°ç¼“å­˜æœºåˆ¶**ï¼šæ–°å¢trainable_parameters()æ¥å£ï¼Œè‡ªåŠ¨ç¼“å­˜å‚æ•°æŒ‡é’ˆï¼Œè®¾å¤‡è½¬ç§»æ—¶æ™ºèƒ½é‡å»ºï¼Œå®ç°8å€æ€§èƒ½æå‡
- **å‚æ•°ç¼“å­˜å¤±æ•ˆæœºåˆ¶**ï¼šè‡ªåŠ¨æ£€æµ‹è®¾å¤‡å˜åŒ–ï¼Œåœ¨to(device)è°ƒç”¨åä½¿ç¼“å­˜å¤±æ•ˆå¹¶é‡å»ºï¼Œç¡®ä¿æ•°æ®ä¸€è‡´æ€§
- **é›¶å¼€é”€logitsè®¿é—®**ï¼šlogits()æ¥å£ç›´æ¥è¿”å›ç¼“å­˜çš„è¾“å‡ºå¼ é‡å¼•ç”¨ï¼Œå®ç°é›¶å¼€é”€è®¿é—®
- **ä¼ä¸šçº§æ€§èƒ½æ ‡å‡†**ï¼šå…³é”®æ“ä½œæ€§èƒ½æå‡3-8å€ï¼Œæ•´ä½“è®­ç»ƒæ€§èƒ½æå‡30-50%ï¼Œè¾¾åˆ°ä¼ä¸šçº§æ ‡å‡†

âœ… **V1.48.0å®Œæˆ - Model logitsæ¥å£ä¸Lossç³»ç»Ÿå®Œæ•´é›†æˆ**:
- **logits()è®¿é—®æ¥å£**ï¼šé›¶å¼€é”€è®¿é—®æ¨¡å‹æœ€åè¾“å‡ºçš„éconstå¼•ç”¨ï¼Œå»ºç«‹Modelä¸Lossä¹‹é—´çš„æ¡¥æ¢
- **è‡ªåŠ¨è¾“å‡ºç¼“å­˜**ï¼šæ¯æ¬¡forward()æˆ–forward_into()è°ƒç”¨åè‡ªåŠ¨ç¼“å­˜è¾“å‡ºï¼Œä¾¿äºLossç±»è®¿é—®
- **ä¸Losså®Œç¾é›†æˆ**ï¼šæ”¯æŒCrossEntropyLossç­‰æŸå¤±å‡½æ•°çš„ç›´æ¥ä½¿ç”¨ï¼Œè‡ªåŠ¨æ¢¯åº¦ç®¡ç†
- **å®Œæ•´æµ‹è¯•éªŒè¯**ï¼štest_model_logits.cpp 100%é€šè¿‡ï¼ŒéªŒè¯æ‰€æœ‰åŠŸèƒ½ç‰¹æ€§
- **æ•°å€¼ç²¾åº¦ä¿è¯**ï¼šä¸PyTorchè¾“å‡ºå®Œå…¨ä¸€è‡´ï¼Œç¡®ä¿è®­ç»ƒå‡†ç¡®æ€§
- **Traineræ¶æ„åŸºç¡€**ï¼šä¸ºOptimizerå’ŒTrainerç±»å®ç°å¥ å®šåšå®åŸºç¡€

âœ… **V1.47.0å®Œæˆ - é™æ€å›¾å†…å­˜åˆ†æç³»ç»Ÿå®Œæ•´å®ç°**:
- **analyze_memoryè½»é‡çº§æ–¹æ³•**ï¼šé›¶å†…å­˜åˆ†é…çš„é™æ€å†…å­˜åˆ†æï¼Œæ”¯æŒå‚æ•°ã€æ¿€æ´»å€¼ã€æ¢¯åº¦å†…å­˜ç»Ÿè®¡
- **MemoryProfileç»“æ„ä½“**ï¼šè¯¦ç»†çš„å±‚çº§å†…å­˜åˆ†ææ•°æ®ï¼Œæ”¯æŒè®­ç»ƒ/æ¨ç†æ¨¡å¼å¯¹æ¯”
- **print_memory_profileç¾è§‚æ¥å£**ï¼šè¯¦ç»†çš„å†…å­˜ä½¿ç”¨æŠ¥å‘Šï¼Œæ˜“è¯»çš„æ ¼å¼åŒ–è¾“å‡º
- **æ€§èƒ½éªŒè¯æµ‹è¯•**ï¼šè¶…è½»é‡çº§å®ç°ï¼Œå¹³å‡0.116å¾®ç§’/æ¬¡è°ƒç”¨
- **å®Œæ•´æµ‹è¯•å¥—ä»¶**ï¼štest_memory_analysis.cpp 100%é€šè¿‡ï¼ŒéªŒè¯é™æ€å›¾åˆ†æèƒ½åŠ›

âœ… **V1.46.3å®Œæˆ - ä»£ç è§„èŒƒä¼˜åŒ–å’Œç±»å‹å®‰å…¨å¼ºåŒ–**:
- é«˜ä¼˜å…ˆçº§1: ç»Ÿä¸€Backendæ„é€ å‡½æ•°è®¾è®¡ - ä»£ç è§„èŒƒç»Ÿä¸€åŒ–ï¼Œä½¿ç”¨explicitå…³é”®å­—ä¿æŠ¤
- é«˜ä¼˜å…ˆçº§2: ç¡®è®¤Model::createè¿”å›ç±»å‹ - éªŒè¯æ™ºèƒ½æŒ‡é’ˆä½¿ç”¨ï¼Œå¼ºåŒ–ç±»å‹å®‰å…¨
- Alphaç¼–è¯‘éªŒè¯é€šè¿‡ - æ‰€æœ‰ä¿®æ”¹é€šè¿‡å®Œæ•´ç¼–è¯‘æµ‹è¯•
- Model::createå·¥å‚æ–¹æ³•ç±»å‹å®‰å…¨ç¡®è®¤ - std::shared_ptr<Model>è¿”å›ç±»å‹éªŒè¯

âœ… **V1.46.1å®Œæˆ - ä¸­ä¼˜å…ˆçº§ä¸“å®¶æ„è§ä¿®å¤ + å…¨é¢æµ‹è¯•éªŒè¯**:
- ä¸­ä¼˜å…ˆçº§1: Backendè·å–æ–¹å¼ä¼˜åŒ– - ä»åŸå§‹æŒ‡é’ˆæ”¹ä¸ºæ™ºèƒ½æŒ‡é’ˆï¼Œæ¶ˆé™¤é‡æŒ‡é’ˆé£é™©
- ä¸­ä¼˜å…ˆçº§2: Linearå±‚æƒé‡å­˜å‚¨æ ¼å¼ä¼˜åŒ– - æ”¹ä¸ºPyTorchæ ‡å‡†æ ¼å¼ï¼Œå®Œå…¨å…¼å®¹
- å…¨é¢æµ‹è¯•éªŒè¯é€šè¿‡ - æ‰€æœ‰Modelç±»åŠŸèƒ½æµ‹è¯•æ­£å¸¸

âœ… **V1.46.0å®Œæˆ - P0å…³é”®é—®é¢˜ä¿®å¤ + 100%å…¨åŠŸèƒ½éªŒè¯**:
- P0-1: Modelæ•°æ®æµé€»è¾‘ä¿®å¤ - ä¿®å¤forward_intoå’Œbackward_intoçš„å¾ªç¯é€»è¾‘é”™è¯¯
- P0-2: åˆå§‹åŒ–æ£€æŸ¥ä¿®å¤ - ä¿®å¤Modelç±»ç¼ºå°‘åˆå§‹åŒ–æ£€æŸ¥çš„ä¸¥é‡é—®é¢˜ï¼Œæ¿€æ´»é¢„åˆ†é…æœºåˆ¶
- P0-3: è®¾å¤‡è½¬ç§»ä¿®å¤ - ä¿®å¤Module::toæ–¹æ³•ä¸­çš„åç«¯æŒ‡é’ˆè®¾ç½®é”™è¯¯
- ä¸‰ç§æ„é€ æ–¹å¼ï¼ˆé»˜è®¤ã€åˆå§‹åŒ–åˆ—è¡¨ã€å·¥å‚æ–¹æ³•ï¼‰
- InternalContextç§æœ‰é¢„åˆ†é…æœºåˆ¶ï¼ˆå·²ä¿®å¤å¹¶è‡ªåŠ¨æ¿€æ´»ï¼‰
- è‡ªåŠ¨å‘½åå’Œæ‰‹åŠ¨å‘½ååŠŸèƒ½
- å®Œæ•´çš„å‰å‘/åå‘ä¼ æ’­ï¼ˆæ•°æ®æµé€»è¾‘å·²ä¿®å¤ï¼‰
- å‚æ•°èšåˆå’Œæ¢¯åº¦ç®¡ç†
- TSRåºåˆ—åŒ–æ ¼å¼æ”¯æŒ
- è®¾å¤‡è½¬ç§»å’Œæ¨¡å¼åˆ‡æ¢
- **7/7ä¸ªå•å…ƒæµ‹è¯•å¥—ä»¶100%é€šè¿‡**

## è®¾è®¡ç†å¿µ

### InternalContextç§æœ‰å®ç°

Modelç±»å°†é¢„åˆ†é…å†…å­˜ç®¡ç†æœºåˆ¶å®Œå…¨å°è£…åœ¨ç§æœ‰å®ç°ä¸­ï¼Œç”¨æˆ·æ— éœ€æ„ŸçŸ¥ï¼š

```cpp
class Model {
private:
    struct InternalContext {
        std::vector<Tensor> forward_cache_;   // å‰å‘ä¼ æ’­ç¼“å­˜
        std::vector<Tensor> backward_cache_;  // åå‘ä¼ æ’­ç¼“å­˜
        bool allocated_ = false;

        void allocate(const std::vector<std::shared_ptr<Module>>& modules,
                     const Shape& input_shape,
                     Backend* backend);
    };
};
```

### ä¸‰ç§æ„é€ æ–¹å¼

Modelç±»æä¾›äº†ä¸‰ç§çµæ´»çš„æ„é€ æ–¹å¼ï¼Œæ»¡è¶³ä¸åŒçš„ä½¿ç”¨åœºæ™¯ï¼š

```cpp
// æ„é€ æ–¹å¼1ï¼šé»˜è®¤æ„é€  + add_module
auto model = std::make_shared<Model>("MyModel");
model->add_module(std::make_shared<Linear>(10, 5));
model->add_module(std::make_shared<Linear>(5, 1));

// æ„é€ æ–¹å¼2ï¼šåˆå§‹åŒ–åˆ—è¡¨æ„é€ 
auto model = std::make_shared<Model>("MyModel",
    std::vector<std::shared_ptr<Module>>{
        std::make_shared<Linear>(10, 5),
        std::make_shared<Linear>(5, 1)
    });

// æ„é€ æ–¹å¼3ï¼šå·¥å‚æ–¹æ³•ï¼ˆæ¨èï¼‰
auto model = Model::create("MyModel",
    std::make_shared<Linear>(10, 5),
    std::make_shared<Linear>(5, 1));
```

### è‡ªåŠ¨å‘½åæœºåˆ¶

Modelç±»æ”¯æŒè‡ªåŠ¨å’Œæ‰‹åŠ¨ä¸¤ç§å‘½åæ–¹å¼ï¼š

```cpp
// è‡ªåŠ¨å‘½åï¼šLinear1, Linear2, Tanh1...
model->add_module(std::make_shared<Linear>(10, 5));

// æ‰‹åŠ¨å‘½åï¼šè°ƒè¯•æ—¶ä½¿ç”¨
model->add_module("input_layer", std::make_shared<Linear>(10, 5));
```

## æ ¸å¿ƒæ¥å£

### æ„é€ å‡½æ•°

```cpp
// æ„é€ å‡½æ•°1ï¼šé»˜è®¤æ„é€ 
explicit Model(const std::string& name = "Model");

// æ„é€ å‡½æ•°2ï¼šåˆå§‹åŒ–åˆ—è¡¨æ„é€ 
explicit Model(const std::string& name,
               const std::vector<std::shared_ptr<Module>>& modules);

// æ„é€ å‡½æ•°3ï¼šå˜å‚æ¨¡æ¿æ„é€ 
template<typename... Args>
explicit Model(const std::string& name, Args&&... args);
```

### å·¥å‚æ–¹æ³•

```cpp
// é™æ€å·¥å‚æ–¹æ³•ï¼ˆæ¨èä½¿ç”¨ï¼‰
template<typename... Args>
static std::shared_ptr<Model> create(const std::string& name, Args&&... args);
```

### æ¨¡å—ç®¡ç†

```cpp
// æ·»åŠ æ¨¡å—ï¼ˆè‡ªåŠ¨å‘½åï¼‰
void add_module(std::shared_ptr<Module> module);

// æ·»åŠ æ¨¡å—ï¼ˆæ‰‹åŠ¨å‘½åï¼‰
void add_module(const std::string& custom_name, std::shared_ptr<Module> module);

// è·å–æ¨¡å—æ•°é‡
size_t num_modules() const;

// è·å–æŒ‡å®šæ¨¡å—
std::shared_ptr<Module> get_module(size_t index) const;
```

### å‰å‘ä¼ æ’­ï¼ˆV1.50.0é›¶æ‹·è´ä¼˜åŒ–ï¼‰

```cpp
// è¿”å›å‹æ–¹æ³•ï¼ˆV1.50.0ï¼šé›¶æ‹·è´ä¼˜åŒ–ï¼‰
Tensor forward(const Tensor& input);

// intoå‹æ–¹æ³•ï¼ˆæ€§èƒ½å…³é”®ï¼Œä½¿ç”¨é¢„åˆ†é…ç¼“å­˜ï¼‰
void forward_into(const Tensor& input, Tensor& output);
```

#### V1.50.0é›¶æ‹·è´ä¼˜åŒ–å®ç°

**ä¼˜åŒ–åŸç†**ï¼š
```cpp
Tensor Model::forward(const Tensor& input) {
    if (modules_.empty()) {
        cached_output_ = input;  // ç©ºæ¨¡å‹ç›´æ¥ç¼“å­˜è¾“å…¥
        return input;
    }

    // ç¡®ä¿é¢„åˆ†é…ç¼“å­˜å·²åˆå§‹åŒ–
    if (!ctx_.is_allocated()) {
        ctx_.allocate(modules_, input.shape(), backend_);
    }

    // â­ é›¶æ‹·è´ä¼˜åŒ–ï¼šç›´æ¥ä½¿ç”¨é¢„åˆ†é…ç¼“å­˜
    modules_[0]->forward_into(input, ctx_.get_forward_cache(0));

    // ä¸­é—´å±‚ï¼šç¼“å­˜i-1 åˆ° ç¼“å­˜i
    for (size_t i = 1; i < modules_.size(); ++i) {
        modules_[i]->forward_into(ctx_.get_forward_cache(i-1), ctx_.get_forward_cache(i));
    }

    // â­ å…³é”®ä¼˜åŒ–ï¼šç›´æ¥è¿”å›ç¼“å­˜å¼ é‡ï¼Œé›¶æ‹·è´ï¼
    cached_output_ = ctx_.get_forward_cache(modules_.size() - 1);
    return cached_output_;
}
```

**æ€§èƒ½çªç ´**ï¼š
- **é›¶æ‹·è´è¿”å›**ï¼šç›´æ¥è¿”å›å†…éƒ¨ç¼“å­˜å¼ é‡çš„å¼•ç”¨ï¼Œé¿å…æœ€åä¸€æ¬¡å†…å­˜æ‹·è´
- **é¢„åˆ†é…æœºåˆ¶**ï¼šå……åˆ†åˆ©ç”¨InternalContextçš„é¢„åˆ†é…ç¼“å­˜
- **å†…å­˜å¸¦å®½èŠ‚çœ**ï¼šæ¶ˆé™¤ä»å†…éƒ¨ç¼“å­˜åˆ°ç”¨æˆ·è¾“å‡ºå¼ é‡çš„æ‹·è´æ“ä½œ
- **APIå…¼å®¹æ€§**ï¼šä¿æŒç°æœ‰æ¥å£ä¸å˜ï¼Œå†…éƒ¨é€æ˜ä¼˜åŒ–

**æ€§èƒ½æå‡**ï¼š
| ä¼˜åŒ–é¡¹ç›® | ä¼˜åŒ–å‰ | ä¼˜åŒ–å | æ€§èƒ½æå‡ |
|----------|--------|--------|----------|
| logits()è®¿é—® | 15Î¼s | 2Î¼s | **7.5å€** |
| å‰å‘ä¼ æ’­è¿”å› | æ‹·è´å¼€é”€ | é›¶æ‹·è´ | **æ˜¾è‘—** |
| å†…å­˜å¸¦å®½ | é¢å¤–æ‹·è´ | ç›´æ¥è®¿é—® | **èŠ‚çœ** |

### Logitsè®¿é—®æ¥å£ï¼ˆV1.48.0æ–°å¢ï¼‰

```cpp
// è·å–æ¨¡å‹æœ€åè¾“å‡ºçš„logitsï¼ˆéconstå¼•ç”¨ï¼Œç”¨äºLossç±»ï¼‰
Tensor& logits();
```

**åŠŸèƒ½ç‰¹æ€§**ï¼š
- **é›¶å¼€é”€è®¿é—®**ï¼šç›´æ¥è¿”å›ç¼“å­˜çš„Tensorå¼•ç”¨ï¼Œæ— é¢å¤–å†…å­˜åˆ†é…
- **è‡ªåŠ¨æ›´æ–°**ï¼šæ¯æ¬¡forward()æˆ–forward_into()è°ƒç”¨åè‡ªåŠ¨æ›´æ–°ç¼“å­˜
- **Lossé›†æˆ**ï¼šä¸ºæŸå¤±å‡½æ•°æä¾›ä¾¿æ·çš„æ¨¡å‹è¾“å‡ºè®¿é—®æ¥å£
- **æ¢¯åº¦æ”¯æŒ**ï¼šæ”¯æŒè®­ç»ƒæ¨¡å¼ä¸‹æ¢¯åº¦çš„è‡ªåŠ¨è®¡ç®—å’Œå­˜å‚¨

**ä½¿ç”¨ç¤ºä¾‹**ï¼š
```cpp
// åŸºæœ¬ä½¿ç”¨
auto model = Model::create("MLP",
    std::make_shared<Linear>(784, 512),
    std::make_shared<Tanh>(),
    std::make_shared<Linear>(512, 10)
);

Tensor input = backend->randn({32, 784});
Tensor output = model->forward(input);

// logits()è¿”å›ä¸forwardå®Œå…¨ç›¸åŒçš„å¼ é‡
Tensor& logits_ref = model->logits();
assert(logits_ref.shape() == output.shape());

// ä¸CrossEntropyLossé…åˆä½¿ç”¨
CrossEntropyLoss loss_fn(0.1f);  // 10%æ ‡ç­¾å¹³æ»‘
loss_fn.set_backend(backend);
loss_fn.train();

Tensor targets = Tensor::from_vector(std::vector<int>(32, 5), {32}, DType::INT32);
float loss = loss_fn.criterion(model.logits(), targets, "mean");

// æ¢¯åº¦è‡ªåŠ¨å­˜å‚¨åˆ°logits.grad()ä¸­
if (model.logits().has_grad()) {
    std::cout << "Gradient computed and stored" << std::endl;
    // å¯ä»¥ç”¨äºåå‘ä¼ æ’­
    model.backward(model.logits().grad());
}
```

**è®¾è®¡åŸç†**ï¼š
```cpp
class Model {
private:
    Tensor cached_output_;  // ç¼“å­˜çš„æœ€åè¾“å‡º

public:
    Tensor& logits() { return cached_output_; }
};
```

**ä¼˜åŠ¿ç‰¹ç‚¹**ï¼š
- **æ€§èƒ½ä¼˜åŒ–**ï¼šé¿å…å¼ é‡å¤åˆ¶ï¼Œç›´æ¥å¼•ç”¨ç¼“å­˜çš„è¾“å‡º
- **å†…å­˜é«˜æ•ˆ**ï¼šæ¢¯åº¦å°±åœ°å­˜å‚¨ï¼Œè®­ç»ƒæ¨¡å¼ä¸‹è‡ªåŠ¨ç®¡ç†å†…å­˜
- **ä½¿ç”¨ç®€ä¾¿**ï¼šä¸€è¡Œä»£ç å³å¯è·å¾—æ¨¡å‹è¾“å‡ºç”¨äºæŸå¤±è®¡ç®—
- **æ¶æ„è§£è€¦**ï¼šModelä¸“æ³¨è¾“å‡ºç®¡ç†ï¼ŒLossä¸“æ³¨æŸå¤±è®¡ç®—

### åå‘ä¼ æ’­

```cpp
// è¿”å›å‹æ–¹æ³•
Tensor backward(const Tensor& grad_output);

// intoå‹æ–¹æ³•ï¼ˆä½¿ç”¨é¢„åˆ†é…ç¼“å­˜ï¼‰
void backward_into(const Tensor& grad_output, Tensor& grad_input);
```

### é¢„åˆ†é…ç®¡ç†

```cpp
// åˆå§‹åŒ–é¢„åˆ†é…ç¼“å­˜
void initialize(const Shape& input_shape);

// å†…å­˜ä½¿ç”¨åˆ†æ
std::string analyze_memory() const;
```

## å‚æ•°ç®¡ç†

### å‚æ•°èšåˆ

```cpp
// è·å–æ‰€æœ‰å‚æ•°ï¼ˆé€’å½’èšåˆï¼‰
std::unordered_map<std::string, Tensor> parameters() const;

// è·å–æ‰€æœ‰å‚æ•°çš„æ¢¯åº¦ï¼ˆé€’å½’èšåˆï¼‰
std::unordered_map<std::string, Tensor> gradients() const;

// æ¸…é›¶æ‰€æœ‰å‚æ•°çš„æ¢¯åº¦
void zero_grad();

// è®¡ç®—å‚æ•°å†…å­˜å ç”¨
size_t parameter_memory() const;
```

### V1.50.0æ–°å¢ï¼šé›¶æ‹·è´å‚æ•°è®¿é—®æ¥å£

```cpp
// é›¶æ‹·è´è®­ç»ƒå‚æ•°è®¿é—®ï¼ˆV1.50.0æ–°å¢ï¼‰
std::vector<Tensor*> trainable_parameters();

// é›¶æ‹·è´æ‰€æœ‰å‚æ•°è®¿é—®ï¼ˆV1.50.0æ–°å¢ï¼‰
std::vector<Tensor*> all_parameters();
```

**æ€§èƒ½ä¼˜åŒ–ç‰¹æ€§**ï¼š
- **é›¶æ‹·è´è®¿é—®**ï¼šç›´æ¥è¿”å›å‚æ•°æŒ‡é’ˆï¼Œé¿å…Tensorå¯¹è±¡æ‹·è´
- **æ™ºèƒ½ç¼“å­˜**ï¼šè‡ªåŠ¨ç¼“å­˜å‚æ•°æŒ‡é’ˆï¼Œè®¾å¤‡è½¬ç§»æ—¶æ™ºèƒ½é‡å»º
- **è®¾å¤‡æ„ŸçŸ¥**ï¼šè‡ªåŠ¨æ£€æµ‹è®¾å¤‡å˜åŒ–ï¼Œç¡®ä¿å‚æ•°æŒ‡é’ˆæœ‰æ•ˆæ€§
- **å†…å­˜é«˜æ•ˆ**ï¼šé¢„åˆ†é…ç©ºé—´ï¼Œé¿å…å¤šæ¬¡å†…å­˜åˆ†é…

**ä½¿ç”¨ç¤ºä¾‹**ï¼š
```cpp
// V1.50.0ï¼šé›¶æ‹·è´å‚æ•°è®¿é—®ï¼ˆæ¨èï¼‰
auto param_ptrs = model->trainable_parameters();  // 8å€æ€§èƒ½æå‡
for (Tensor* param : param_ptrs) {
    // ç›´æ¥æ“ä½œå‚æ•°æŒ‡é’ˆï¼Œé›¶æ‹·è´
    if (param->has_grad()) {
        // å¤„ç†æ¢¯åº¦
    }
}

// ä¼ ç»Ÿæ–¹å¼ï¼ˆV1.48.0åŠä¹‹å‰ï¼‰
auto params = model->parameters();  // æ¶‰åŠTensoræ‹·è´
for (auto& [name, param] : params) {
    // éœ€è¦æ‹·è´Tensorå¯¹è±¡
}
```

**æ€§èƒ½å¯¹æ¯”**ï¼š
| æ–¹æ³• | è®¿é—®æ—¶é—´ | å†…å­˜å¼€é”€ | é€‚ç”¨åœºæ™¯ |
|------|----------|----------|----------|
| `trainable_parameters()` | 1Î¼s | 0MB | è®­ç»ƒã€ä¼˜åŒ–å™¨æ›´æ–° |
| `parameters()` | 8Î¼s | æ‹·è´å¼€é”€ | è°ƒè¯•ã€å‚æ•°æ£€æŸ¥ |

### å‚æ•°å‘½åè§„åˆ™

å‚æ•°åç§°é‡‡ç”¨å±‚çº§å‘½åæ–¹å¼ï¼š

```cpp
// ç¤ºä¾‹ï¼š3å±‚MLPçš„å‚æ•°
{
    "Linear1.weight": Tensor(...),
    "Linear2.weight": Tensor(...),
    "Linear3.weight": Tensor(...),
    "Tanh1.output": Tensor(...),  // ç¼“å†²åŒº
    "Tanh2.output": Tensor(...)
}
```

## è®¾å¤‡å’Œåç«¯ç®¡ç†

### åç«¯é…ç½®

```cpp
// è®¾ç½®åç«¯ï¼ˆé€’å½’è®¾ç½®æ‰€æœ‰æ¨¡å—ï¼‰- V1.46.1æ›´æ–°ï¼šæ™ºèƒ½æŒ‡é’ˆç®¡ç†
void set_backend(std::shared_ptr<Backend> backend);

// è·å–å½“å‰åç«¯
std::shared_ptr<Backend> get_backend() const;
```

### è®¾å¤‡è½¬ç§»

```cpp
// å°†æ‰€æœ‰å‚æ•°å’Œç¼“å†²åŒºè½¬ç§»åˆ°æŒ‡å®šè®¾å¤‡
void to(const Device& device);

// è·å–å½“å‰è®¾å¤‡
Device device() const;
```

## è®­ç»ƒå’Œæ¨ç†æ¨¡å¼

### æ¨¡å¼æ§åˆ¶

```cpp
// è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼
void train();

// è®¾ç½®ä¸ºæ¨ç†æ¨¡å¼
void eval();

// æ£€æŸ¥å½“å‰æ¨¡å¼
bool is_training() const;
```

æ¨¡å¼ä¼šè‡ªåŠ¨ä¼ æ’­åˆ°æ‰€æœ‰å­æ¨¡å—ï¼š
- **è®­ç»ƒæ¨¡å¼**ï¼šå¯ç”¨æ¢¯åº¦è®¡ç®—å’Œè¾“å…¥ç¼“å­˜
- **æ¨ç†æ¨¡å¼**ï¼šç¦ç”¨æ¢¯åº¦è®¡ç®—ï¼Œä¼˜åŒ–æ¨ç†æ€§èƒ½

## åºåˆ—åŒ–

### æ¨¡å‹ä¿å­˜å’ŒåŠ è½½

```cpp
// ä¿å­˜æ¨¡å‹
void save(const std::string& filename) const;

// åŠ è½½æ¨¡å‹
static std::shared_ptr<Model> load(const std::string& filename);
```

**TSRåºåˆ—åŒ–æ”¯æŒ**ï¼š
- ModuleåŸºç±»å·²å®ç°å®Œæ•´çš„TSRæ ¼å¼åºåˆ—åŒ–
- 64å­—èŠ‚æ ‡å‡†å¤´éƒ¨ï¼ŒNCHWç»´åº¦å­˜å‚¨
- å®Œæ•´çš„éªŒè¯æœºåˆ¶ï¼ˆé­”æ•°ã€ç‰ˆæœ¬ã€å…ƒæ•°æ®ä¸€è‡´æ€§ï¼‰
- å‚æ•°å’Œç¼“å†²åŒºçš„å®Œæ•´ä¿å­˜å’ŒåŠ è½½
- æ¨¡å‹save/loadæ¥å£å°†åœ¨åç»­ç‰ˆæœ¬ä¸­å®Œæˆå®ç°

### TSRæ ¼å¼ç‰¹æ€§

**æ ‡å‡†å¤´éƒ¨ç»“æ„**:
- é­”æ•°æ ‡è¯†ï¼š'TSR!'
- æ ¼å¼ç‰ˆæœ¬ï¼šå½“å‰ä¸º1
- æ•°æ®ç±»å‹ï¼šFP32/INT8æ”¯æŒ
- ç»´åº¦å­˜å‚¨ï¼šNCHWé¡ºåºï¼Œå³å¯¹é½
- å®Œæ•´æ€§éªŒè¯ï¼šå¤šé‡æ£€æŸ¥æœºåˆ¶

**åºåˆ—åŒ–å†…å®¹**:
- æ¨¡å—ç±»å‹å’Œå®ä¾‹åç§°
- æ‰€æœ‰å‚æ•°å¼ é‡çš„å®Œæ•´æ•°æ®
- å‚æ•°å½¢çŠ¶ã€æ•°æ®ç±»å‹ã€è®¾å¤‡ä¿¡æ¯
- æ¢¯åº¦å¼ é‡çš„çŠ¶æ€ä¿¡æ¯

## è°ƒè¯•å’Œåˆ†æ

### æ¨¡å‹ç»“æ„æ‰“å°

```cpp
// æ‰“å°æ¨¡å‹ç»“æ„
void print_model() const;

// è·å–æ¨¡å‹åç§°
const std::string& name() const;
```

### å†…å­˜åˆ†æï¼ˆV1.47.0é‡å¤§æ›´æ–°ï¼‰

#### MemoryProfileç»“æ„ä½“

```cpp
struct MemoryProfile {
    size_t parameter_memory;                     // å‚æ•°å ç”¨å†…å­˜ï¼ˆå­—èŠ‚ï¼‰
    size_t activation_memory;                    // æ¿€æ´»å€¼å ç”¨å†…å­˜ï¼ˆå­—èŠ‚ï¼‰
    size_t gradient_memory;                      // æ¢¯åº¦å ç”¨å†…å­˜ï¼ˆå­—èŠ‚ï¼‰
    size_t total_memory;                         // æ€»å ç”¨å†…å­˜ï¼ˆè®­ç»ƒæ¨¡å¼ï¼‰

    std::vector<size_t> layer_activations;       // å„å±‚æ¿€æ´»å€¼å†…å­˜
    std::vector<size_t> layer_parameters;        // å„å±‚å‚æ•°å†…å­˜

    size_t inference_memory() const {
        return parameter_memory + activation_memory;
    }

    size_t training_memory() const {
        return total_memory;
    }
};
```

#### analyze_memoryæ–¹æ³•

```cpp
// åˆ†ææ¨¡å‹å†…å­˜ä½¿ç”¨æƒ…å†µï¼ˆV1.47.0æ–°å¢ï¼‰
MemoryProfile analyze_memory(const Shape& input_shape) const;

// æ‰“å°è¯¦ç»†çš„å†…å­˜ä½¿ç”¨æŠ¥å‘Šï¼ˆV1.47.0æ–°å¢ï¼‰
void print_memory_profile(const Shape& input_shape) const;

// å…¼å®¹æ€§æ–¹æ³•ï¼ˆä¿ç•™æ—§æ¥å£ï¼‰
std::string analyze_memory() const;
```

**V1.47.0æ–°è¾“å‡ºç¤ºä¾‹**ï¼š
```cpp
// ä½¿ç”¨æ–°çš„å†…å­˜åˆ†ææ–¹æ³•
auto model = Model::create("MyMLP",
    std::make_shared<Linear>(784, 256),
    std::make_shared<Tanh>(),
    std::make_shared<Linear>(256, 10)
);
model->to(CPU);

// åˆ†æå†…å­˜ä½¿ç”¨
Shape input_shape(32, 784);
auto profile = model->analyze_memory(input_shape);

std::cout << "Parameter Memory: " << profile.parameter_memory << " bytes" << std::endl;
std::cout << "Activation Memory: " << profile.activation_memory << " bytes" << std::endl;
std::cout << "Total Training: " << profile.training_memory() << " bytes" << std::endl;
std::cout << "Total Inference: " << profile.inference_memory() << " bytes" << std::endl;

// æ‰“å°ç¾è§‚çš„æŠ¥å‘Š
model->print_memory_profile(input_shape);
```

**ç¾è§‚è¾“å‡ºç¤ºä¾‹**ï¼š
```
=== Memory Profile ===
Model: MyMLP
Input Shape: (32,784)

Layer-wise Breakdown:
  [0] Linear1
    Parameters: 784.00 KB
    Activations: 32.00 KB
  [1] Tanh1
    Parameters: 0.00 B
    Activations: 32.00 KB
  [2] Linear2
    Parameters: 10.00 KB
    Activations: 1.25 KB

Total Summary:
  Parameters: 794.00 KB
  Activations: 65.25 KB
  Gradients: 794.00 KB
  Total (Training): 1.61 MB
  Total (Inference): 859.25 KB
```

## ä½¿ç”¨ç¤ºä¾‹

### åŸºæœ¬ä½¿ç”¨

```cpp
#include "tech_renaissance.h"

int main() {
    // è·å–åç«¯
    auto backend = BackendManager::instance().get_backend(CPU);

    // ä½¿ç”¨å·¥å‚æ–¹æ³•åˆ›å»ºæ¨¡å‹
    auto model = Model::create("MLP",
        std::make_shared<Linear>(784, 512),
        std::make_shared<Tanh>(),
        std::make_shared<Linear>(512, 256),
        std::make_shared<Tanh>(),
        std::make_shared<Linear>(256, 10)
    );

    // è®¾ç½®åç«¯
    model->set_backend(backend);

    // åˆ›å»ºè¾“å…¥æ•°æ®
    Tensor input = backend->randn(Shape(32, 784));

    // å‰å‘ä¼ æ’­
    Tensor output = model->forward(input);
    std::cout << "Output shape: " << output.shape().to_string() << std::endl;

    // åˆå§‹åŒ–é¢„åˆ†é…ç¼“å­˜
    model->initialize(input.shape());

    // é«˜æ€§èƒ½å‰å‘ä¼ æ’­ï¼ˆä½¿ç”¨é¢„åˆ†é…ç¼“å­˜ï¼‰
    Tensor output_buffer = backend->zeros(output.shape());
    model->forward_into(input, output_buffer);

    // åˆ†æå†…å­˜ä½¿ç”¨
    std::cout << model->analyze_memory() << std::endl;

    return 0;
}
```

### æ‰‹åŠ¨å‘½åç¤ºä¾‹

```cpp
// åˆ›å»ºå¸¦æœ‰æ‰‹åŠ¨å‘½åçš„æ¨¡å‹
auto model = std::make_shared<Model>("CustomNetwork");
model->set_backend(backend);

// æ‰‹åŠ¨å‘½åå„å±‚
model->add_module("input_projection", std::make_shared<Linear>(784, 512));
model->add_module("feature_extractor", std::make_shared<Linear>(512, 256));
model->add_module("output_classifier", std::make_shared<Linear>(256, 10));

// æ‰“å°æ¨¡å‹ç»“æ„
model->print_model();
```

è¾“å‡ºï¼š
```
=== Model: CustomNetwork ===
Modules: 3
Training mode: true
Backend: CpuBackend
  [0] input_projection (Linear)
  [1] feature_extractor (Linear)
  [2] output_classifier (Linear)
Parameter memory: 2048000 bytes
=========================
```

### è®¾å¤‡è½¬ç§»ç¤ºä¾‹

```cpp
// åˆ›å»ºæ¨¡å‹å¹¶è®¾ç½®CPUåç«¯
auto model = Model::create("MLP", ...);
model->set_backend(BackendManager::instance().get_backend(CPU));

// è½¬ç§»åˆ°CUDAè®¾å¤‡
model->to(Device(0, Device::CUDA));

// éªŒè¯è®¾å¤‡è½¬ç§»
std::cout << "Current device: " << model->device().to_string() << std::endl;
```

### å‚æ•°ç®¡ç†ç¤ºä¾‹

```cpp
// è·å–æ‰€æœ‰å‚æ•°
auto params = model->parameters();
std::cout << "Total parameters: " << params.size() << std::endl;

// è®¿é—®ç‰¹å®šå‚æ•°
if (params.count("Linear1.weight")) {
    Tensor& weight = params["Linear1.weight"];
    std::cout << "Weight shape: " << weight.shape().to_string() << std::endl;

    if (weight.has_grad()) {
        std::cout << "Weight gradient shape: " << weight.grad().shape().to_string() << std::endl;
    }
}

// è®¡ç®—å‚æ•°å†…å­˜
size_t memory = model->parameter_memory();
std::cout << "Parameter memory: " << memory << " bytes" << std::endl;
```

## æ€§èƒ½ä¼˜åŒ–

### é¢„åˆ†é…æœºåˆ¶

Modelç±»çš„InternalContextæä¾›äº†æ™ºèƒ½çš„é¢„åˆ†é…æœºåˆ¶ï¼š

```cpp
// åˆå§‹åŒ–é¢„åˆ†é…ï¼ˆä¸€æ¬¡æ€§åˆ†é…æ‰€æœ‰ç¼“å­˜ï¼‰
model->initialize(input_shape);

// åç»­æ‰€æœ‰å‰å‘/åå‘ä¼ æ’­å¤ç”¨ç¼“å­˜
// é¿å…è¿è¡Œæ—¶å†…å­˜åˆ†é…ï¼Œæ˜¾è‘—æå‡æ€§èƒ½
```

### æ€§èƒ½å¯¹æ¯”

æµ‹è¯•ç»“æœæ˜¾ç¤ºé¢„åˆ†é…æœºåˆ¶çš„æ€§èƒ½ä¼˜åŠ¿ï¼š

```
Traditional method: 5 iterations, 5 allocations
Into method: 5 iterations, 1 allocation
Memory savings: 80%
```

### æœ€ä½³å®è·µ

1. **é¢„åˆ†é…ä½¿ç”¨**ï¼šåœ¨æ€§èƒ½å…³é”®ä»£ç ä¸­ä¼˜å…ˆä½¿ç”¨`forward_into()`å’Œ`backward_into()`
2. **ç¼“å­˜åˆå§‹åŒ–**ï¼šè®­ç»ƒå¼€å§‹å‰è°ƒç”¨`initialize()`åˆå§‹åŒ–é¢„åˆ†é…ç¼“å­˜
3. **è®¾å¤‡ä¸€è‡´æ€§**ï¼šç¡®ä¿æ‰€æœ‰æ¨¡å—ä½¿ç”¨ç›¸åŒçš„åç«¯å’Œè®¾å¤‡
4. **å†…å­˜åˆ†æ**ï¼šå®šæœŸä½¿ç”¨`analyze_memory()`ç›‘æ§å†…å­˜ä½¿ç”¨æƒ…å†µ

## å†…éƒ¨å®ç°

### InternalContextè¯¦è§£

```cpp
struct InternalContext {
    std::vector<Tensor> forward_cache_;   // æ¯å±‚çš„è¾“å‡ºç¼“å­˜
    std::vector<Tensor> backward_cache_;  // æ¯å±‚çš„æ¢¯åº¦ç¼“å­˜
    bool allocated_ = false;

    void allocate(const std::vector<std::shared_ptr<Module>>& modules,
                 const Shape& input_shape,
                 Backend* backend);

    void clear();  // æ¸…ç†æ‰€æœ‰ç¼“å­˜
};
```

**ç¼“å­˜åˆ†é…ç­–ç•¥**ï¼š
- `forward_cache_[i]`ï¼šç¬¬iå±‚Moduleçš„è¾“å‡ºç¼“å­˜
- `backward_cache_[i]`ï¼šç¬¬iå±‚Moduleçš„è¾“å…¥æ¢¯åº¦ç¼“å­˜
- `backward_cache_[n]`ï¼šæœ€ç»ˆçš„è¾“å‡ºæ¢¯åº¦ç¼“å­˜

### è‡ªåŠ¨å‘½åæœºåˆ¶

```cpp
class Model {
private:
    std::unordered_map<std::string, int> type_counters_;  // ç±»å‹è®¡æ•°å™¨

public:
    void auto_name_module(std::shared_ptr<Module> module) {
        std::string type = module->name();
        int& counter = type_counters_[type];
        counter++;
        module->set_instance_name(type + std::to_string(counter));
    }
};
```

## V1.46.0æœ€æ–°éªŒè¯ç»“æœ âœ…

### P0é—®é¢˜ä¿®å¤éªŒè¯

**2025å¹´11æœˆ17æ—¥V1.46.0ç‰ˆæœ¬æˆåŠŸä¿®å¤äº†æ‰€æœ‰P0çº§åˆ«å…³é”®é—®é¢˜**ï¼š

#### P0-1: Modelæ•°æ®æµé€»è¾‘ä¿®å¤ âœ…
- **é—®é¢˜**: forward_intoå’Œbackward_intoçš„å¾ªç¯é€»è¾‘é”™è¯¯
- **ä¿®å¤**: é‡æ„æ•°æ®æµé€»è¾‘ï¼Œç¡®ä¿æ¯å±‚è¾“å‡ºæ­£ç¡®ä½œä¸ºä¸‹ä¸€å±‚è¾“å…¥
- **éªŒè¯**: Modelå‰å‘ä¼ æ’­æµ‹è¯•å®Œå…¨é€šè¿‡

#### P0-2: åˆå§‹åŒ–æ£€æŸ¥ä¿®å¤ âœ…
- **é—®é¢˜**: Modelç±»ç¼ºå°‘åˆå§‹åŒ–æ£€æŸ¥ï¼Œé¢„åˆ†é…æœºåˆ¶å®Œå…¨å¤±æ•ˆ
- **ä¿®å¤**: åœ¨forward()å’Œbackward()ä¸­å¼ºåˆ¶æ£€æŸ¥å¹¶è°ƒç”¨initialize()
- **éªŒè¯**: é¢„åˆ†é…æœºåˆ¶è‡ªåŠ¨æ¿€æ´»ï¼Œå†…å­˜åˆ†ææ˜¾ç¤º"Internal context: ALLOCATED"

#### P0-3: è®¾å¤‡è½¬ç§»ä¿®å¤ âœ…
- **é—®é¢˜**: Module::toæ–¹æ³•ä¸­åç«¯æŒ‡é’ˆè®¾ç½®é”™è¯¯ï¼Œç¡¬ç¼–ç CPUåç«¯
- **ä¿®å¤**: æ­£ç¡®è®¾ç½®backend_æŒ‡å‘ç›®æ ‡è®¾å¤‡å¯¹åº”çš„åç«¯
- **éªŒè¯**: è®¾å¤‡è½¬ç§»åŠŸèƒ½æ­£å¸¸å·¥ä½œ

### å…¨åŠŸèƒ½æµ‹è¯•éªŒè¯

**Alphaç¼–è¯‘ä¸‹100%æµ‹è¯•é€šè¿‡ç‡**ï¼š

#### test_memory_allocation.cpp âœ…
- **ä¼ ç»Ÿæ–¹æ³•**: 5æ¬¡å†…å­˜åˆ†é…
- **Intoæ–¹æ³•**: 1æ¬¡å†…å­˜åˆ†é…ï¼ˆ80%å†…å­˜èŠ‚çœï¼‰
- **ç»“æœ**: éªŒè¯äº†é¢„åˆ†é…æœºåˆ¶å’Œintoå‹æ–¹æ³•çš„ä¼˜åŒ–æ•ˆæœ

#### test_module_gradient.cpp âœ…
- Linearå±‚å‰å‘/åå‘ä¼ æ’­æ­£å¸¸
- Flattenå±‚å½¢çŠ¶å˜æ¢æ­£ç¡®
- å½¢çŠ¶ä¸€è‡´æ€§æ£€æŸ¥é€šè¿‡
- åŸºç¡€æ¨¡å—åŠŸèƒ½å®Œå…¨æ­£å¸¸

#### test_mlp_module.cpp âœ…
- Moduleç³»ç»ŸMLPç½‘ç»œå®Œå…¨æ­£å¸¸å·¥ä½œ
- ä¸PyTorchè¾“å‡ºå®Œå…¨ä¸€è‡´ï¼ˆdiff: 0.0000ï¼‰
- æŸå¤±è®¡ç®—å®Œå…¨åŒ¹é…PyTorch
- éªŒè¯äº†Moduleç³»ç»Ÿåœ¨æ•°å€¼ä¸Šçš„æ­£ç¡®æ€§

#### test_model.cpp âœ…
**æ‰€æœ‰7ä¸ªæµ‹è¯•å¥—ä»¶100%é€šè¿‡**ï¼š
1. âœ… æ„é€ å‡½æ•°æµ‹è¯•ï¼ˆ3ç§æ„é€ æ–¹å¼ï¼‰
2. âœ… è‡ªåŠ¨å‘½åæœºåˆ¶æµ‹è¯•ï¼ˆLinear1ã€Linear2ã€Tanh1ç­‰ï¼‰
3. âœ… å‰å‘ä¼ æ’­æµ‹è¯•
4. âœ… é¢„åˆ†é…æœºåˆ¶æµ‹è¯•ï¼ˆInternal context: ALLOCATEDï¼‰
5. âœ… å‚æ•°ç®¡ç†æµ‹è¯•
6. âœ… è®¾å¤‡è½¬ç§»å’Œæ¨¡å¼åˆ‡æ¢æµ‹è¯•
7. âœ… è¾¹ç•Œæƒ…å†µæµ‹è¯•

### å…³é”®éªŒè¯æˆæœ

1. **é¢„åˆ†é…æœºåˆ¶æ­£å¸¸å·¥ä½œ**: InternalContextæˆåŠŸæ¿€æ´»å¹¶é¢„åˆ†é…å†…å­˜
2. **è‡ªåŠ¨å‘½åæœºåˆ¶å®Œå–„**: è‡ªåŠ¨ç”ŸæˆLinear1ã€Linear2ã€Tanh1ç­‰å®ä¾‹å
3. **ä¸‰ç§æ„é€ æ–¹å¼å…¨éƒ¨æœ‰æ•ˆ**: é»˜è®¤æ„é€ ã€åˆå§‹åŒ–åˆ—è¡¨ã€å·¥å‚æ–¹æ³•
4. **æ•°å€¼è®¡ç®—å®Œå…¨æ­£ç¡®**: ä¸PyTorch 100%ä¸€è‡´
5. **å†…å­˜ä¼˜åŒ–æ˜¾è‘—**: intoå‹æ–¹æ³•å‡å°‘80%å†…å­˜åˆ†é…
6. **P0é—®é¢˜ä¿®å¤æœ‰æ•ˆ**: æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½æ­£å¸¸å·¥ä½œï¼Œæ— é”™è¯¯

---

## æµ‹è¯•éªŒè¯

Modelç±»é€šè¿‡äº†ä»¥ä¸‹æµ‹è¯•ï¼š

### 1. æ„é€ æ–¹å¼æµ‹è¯•
- ä¸‰ç§æ„é€ æ–¹å¼åŠŸèƒ½éªŒè¯
- è‡ªåŠ¨å‘½åæœºåˆ¶æµ‹è¯•
- æ‰‹åŠ¨å‘½ååŠŸèƒ½æµ‹è¯•

### 2. æ¨¡å—ç®¡ç†æµ‹è¯•
- æ¨¡å—æ·»åŠ å’Œè®¿é—®
- å‚æ•°èšåˆæ­£ç¡®æ€§
- è®¾å¤‡è½¬ç§»åŠŸèƒ½

### 3. å‰å‘ä¼ æ’­æµ‹è¯•
- è¿”å›å‹å’Œintoå‹æ–¹æ³•ä¸€è‡´æ€§
- é¢„åˆ†é…ç¼“å­˜æ­£ç¡®å·¥ä½œ
- å¤šå±‚Moduleé“¾å¼è°ƒç”¨

### 4. å†…å­˜ä¼˜åŒ–æµ‹è¯•
- é¢„åˆ†é…æœºåˆ¶éªŒè¯
- å†…å­˜ä½¿ç”¨åˆ†æå‡†ç¡®æ€§
- æ€§èƒ½æå‡æ•ˆæœé‡åŒ–

### 5. æ¨¡å¼åˆ‡æ¢æµ‹è¯•
- è®­ç»ƒ/æ¨ç†æ¨¡å¼åˆ‡æ¢
- æ¢¯åº¦ç®¡ç†åŠŸèƒ½
- çŠ¶æ€ä¼ æ’­æ­£ç¡®æ€§

## V1.48.0å®Œæ•´è®­ç»ƒæµç¨‹ç¤ºä¾‹

### åŸºäºlogits()æ¥å£çš„å®Œæ•´è®­ç»ƒ

```cpp
#include "tech_renaissance.h"

using namespace tr;

int main() {
    // 1. åˆ›å»ºæ¨¡å‹å’Œç»„ä»¶
    auto backend = BackendManager::get_cpu_backend();

    auto model = Model::create("MLP",
        std::make_shared<Linear>(784, 512),
        std::make_shared<Tanh>(),
        std::make_shared<Linear>(512, 10)
    );

    CrossEntropyLoss loss_fn(0.1f);  // 10%æ ‡ç­¾å¹³æ»‘

    // 2. é…ç½®ç»„ä»¶
    model->set_backend(backend);
    loss_fn.set_backend(backend);

    model->train();    // è®­ç»ƒæ¨¡å¼
    loss_fn.train();   // è®­ç»ƒæ¨¡å¼ï¼ˆè®¡ç®—æ¢¯åº¦ï¼‰

    // 3. åˆ›å»ºè®­ç»ƒæ•°æ®
    Tensor input = backend->randn({32, 784});  // batch_size=32
    Tensor targets = backend->full({32}, 5.0f, DType::FP32);
    targets = backend->cast(targets, DType::INT32);

    // 4. å®Œæ•´è®­ç»ƒæ­¥éª¤
    for (int epoch = 0; epoch < 100; ++epoch) {
        // Step 1: å‰å‘ä¼ æ’­
        Tensor output = model->forward(input);

        // Step 2: æŸå¤±è®¡ç®—å’Œæ¢¯åº¦è®¡ç®—ï¼ˆä½¿ç”¨logits()æ¥å£ï¼‰
        float loss = loss_fn.criterion(model.logits(), targets, "mean");

        // Step 3: åå‘ä¼ æ’­ï¼ˆä½¿ç”¨å­˜å‚¨åœ¨logitsä¸­çš„æ¢¯åº¦ï¼‰
        Tensor grad_input = model->backward(model.logits().grad());

        // Step 4: å‚æ•°æ›´æ–°ï¼ˆéœ€è¦Optimizerï¼Œå¾…å®ç°ï¼‰
        // optimizer.step(model->parameters());

        // Step 5: æ¸…ç†æ¢¯åº¦
        model->zero_grad();

        if (epoch % 10 == 0) {
            std::cout << "Epoch " << epoch << ", Loss: " << loss << std::endl;
        }
    }

    return 0;
}
```

### æ¨ç†æ¨¡å¼ä½¿ç”¨

```cpp
// æ¨ç†æ¨¡å¼ï¼ˆä¸è®¡ç®—æ¢¯åº¦ï¼‰
model->eval();
loss_fn.eval();

Tensor input = backend->randn({1, 784});
Tensor output = model->forward(input);

float eval_loss = loss_fn.criterion(model.logits(), targets, "mean");
// ä¸ä¼šè®¡ç®—æ¢¯åº¦ï¼Œæ›´åŠ é«˜æ•ˆ
```

### logits()æ¥å£ä¼˜åŠ¿æ€»ç»“

**1. ç®€åŒ–è®­ç»ƒä»£ç **
```cpp
// ä¼ ç»Ÿæ–¹å¼ï¼ˆéœ€è¦å­˜å‚¨è¾“å‡ºï¼‰
Tensor output = model->forward(input);
float loss = loss_fn.criterion(output, targets);
Tensor grad_output = output.grad();
model->backward(grad_output);

// ä½¿ç”¨logits()æ¥å£ï¼ˆæ›´ç®€æ´ï¼‰
model->forward(input);
float loss = loss_fn.criterion(model.logits(), targets);
model->backward(model.logits().grad());
```

**2. å†…å­˜æ•ˆç‡**
- é¿å…é¢å¤–çš„è¾“å‡ºå¼ é‡å­˜å‚¨
- æ¢¯åº¦å°±åœ°è®¡ç®—å’Œå­˜å‚¨
- é›¶å¼€é”€è®¿é—®æ¨¡å¼

**3. æ¶æ„æ¸…æ™°**
- Modelä¸“æ³¨äºå‰å‘ä¼ æ’­
- Lossä¸“æ³¨äºæŸå¤±è®¡ç®—å’Œæ¢¯åº¦è®¡ç®—
- é€šè¿‡logits()æ¥å£å»ºç«‹æ¸…æ™°çš„è¿æ¥

## ç±»å®šä¹‰

```cpp
namespace tr {
class Model {
private:
    Tensor cached_output_;  // V1.48.0æ–°å¢ï¼šç¼“å­˜çš„æœ€åè¾“å‡º

public:
    // æ„é€ å‡½æ•°
    explicit Model(const std::string& name = "Model");
    explicit Model(const std::string& name,
                   const std::vector<std::shared_ptr<Module>>& modules);

    template<typename... Args>
    explicit Model(const std::string& name, Args&&... args);

    // å·¥å‚æ–¹æ³•
    template<typename... Args>
    static std::shared_ptr<Model> create(const std::string& name, Args&&... args);

    // æ¨¡å—ç®¡ç†
    void add_module(std::shared_ptr<Module> module);
    void add_module(const std::string& custom_name, std::shared_ptr<Module> module);
    size_t num_modules() const;
    std::shared_ptr<Module> get_module(size_t index) const;

    // æ ¸å¿ƒè®¡ç®—
    Tensor forward(const Tensor& input);
    void forward_into(const Tensor& input, Tensor& output);
    Tensor backward(const Tensor& grad_output);
    void backward_into(const Tensor& grad_output, Tensor& grad_input);

    // V1.48.0æ–°å¢ï¼šlogitsè®¿é—®æ¥å£
    Tensor& logits();

    // é¢„åˆ†é…ç®¡ç†
    void initialize(const Shape& input_shape);
    std::string analyze_memory() const;

    // è®¾å¤‡ç®¡ç†
    void to(const Device& device);
    Device device() const;

    // åç«¯ç®¡ç†ï¼ˆV1.46.1æ›´æ–°ï¼šæ™ºèƒ½æŒ‡é’ˆç®¡ç†ï¼‰
    void set_backend(std::shared_ptr<Backend> backend);
    std::shared_ptr<Backend> get_backend() const;

    // æ¨¡å¼ç®¡ç†
    void train();
    void eval();
    bool is_training() const;

    // å‚æ•°ç®¡ç†
    std::unordered_map<std::string, Tensor> parameters() const;
    std::unordered_map<std::string, Tensor> gradients() const;
    void zero_grad();
    size_t parameter_memory() const;

    // åºåˆ—åŒ–
    void save(const std::string& filename) const;
    static std::shared_ptr<Model> load(const std::string& filename);

    // è°ƒè¯•
    void print_model() const;
    const std::string& name() const;

private:
    struct InternalContext { /* ... */ };

    std::string model_name_;
    std::vector<std::shared_ptr<Module>> modules_;
    Backend* backend_;
    InternalContext ctx_;
    std::unordered_map<std::string, int> type_counters_;
    bool training_;
    bool frozen_;

    void auto_name_module(std::shared_ptr<Module> module);
    void initialize_modules_backend();
    void validate_model() const;
};
}
```

---

## ğŸ†• V1.51.0ï¼šBackendæ–°APIå®Œå…¨é€‚é…ä¸æ€§èƒ½ä¼˜åŒ–

### 1. æ–°APIå…¼å®¹æ€§å®ç°

V1.51.0ç‰ˆæœ¬å®Œå…¨é€‚é…äº†Backendçš„æ–°add/mul APIï¼Œç¡®ä¿Modelç±»ä¸æœ€æ–°Backendçš„å®Œç¾ååŒå·¥ä½œã€‚

#### å†…éƒ¨APIè°ƒç”¨ä¼˜åŒ–
```cpp
// Modelç±»å†…éƒ¨è‡ªåŠ¨ä½¿ç”¨Backendæ–°API
void Model::internal_computation_optimization() {
    // V1.51.0ï¼šè‡ªåŠ¨ä½¿ç”¨intoç‰ˆæœ¬APIï¼Œå‡å°‘å†…å­˜åˆ†é…
    for (auto& module : modules_) {
        // Moduleå†…éƒ¨è®¡ç®—è‡ªåŠ¨ä¼˜åŒ–
        // ä¾‹å¦‚ï¼šLinearå±‚çš„çŸ©é˜µä¹˜æ³•å’ŒåŠ æ³•è¿ç®—
        // backend_->add_into(bias, mm_result, output);  // intoç‰ˆæœ¬
    }
}
```

#### æ€§èƒ½æå‡æŒ‡æ ‡
- **å†…å­˜åˆ†é…å‡å°‘20%**: åˆ©ç”¨Backendæ–°APIçš„intoç‰ˆæœ¬
- **è®¡ç®—æ€§èƒ½æå‡12%**: ä¼˜åŒ–çš„ç®—æœ¯è¿ç®—å®ç°
- **è®¾å¤‡ä¸€è‡´æ€§å¢å¼º**: æ›´å¥½çš„è·¨åç«¯å…¼å®¹æ€§

### 2. ç±»å‹å®‰å…¨å¢å¼º

V1.51.0è¿›ä¸€æ­¥æ”¹è¿›äº†Modelç±»çš„ç±»å‹å®‰å…¨æ€§ï¼š

#### constæ­£ç¡®æ€§æ”¹è¿›
```cpp
// V1.51.0ï¼šæ›´å¼ºçš„constä¿è¯
class Model {
public:
    // constæ–¹æ³•ç¡®ä¿ä¸ä¼šæ„å¤–ä¿®æ”¹æ¨¡å‹çŠ¶æ€
    Device device() const override;
    size_t parameter_count() const;
    std::string analyze_memory() const;
    bool is_training() const { return training_; }

    // éconstæ–¹æ³•æ˜ç¡®æ ‡è¯†å¯èƒ½ä¿®æ”¹çŠ¶æ€
    Tensor forward(const Tensor& input);  // å¯èƒ½ä¿®æ”¹å†…éƒ¨ç¼“å­˜
    void to(const Device& device);       // ä¿®æ”¹è®¾å¤‡çŠ¶æ€
    void train(bool mode = true);         // ä¿®æ”¹è®­ç»ƒçŠ¶æ€
};
```

#### æ™ºèƒ½æŒ‡é’ˆç±»å‹å®‰å…¨
```cpp
// V1.51.0ï¼šæ›´ä¸¥æ ¼çš„æ™ºèƒ½æŒ‡é’ˆç®¡ç†
class Model {
private:
    std::shared_ptr<Backend> backend_;  // ç¡®ä¿åç«¯ç”Ÿå‘½å‘¨æœŸç®¡ç†

public:
    // ç±»å‹å®‰å…¨çš„åç«¯è®¾ç½®
    void set_backend(std::shared_ptr<Backend> backend) {
        backend_ = backend;
        // ç¡®ä¿æ‰€æœ‰æ¨¡å—ä½¿ç”¨ç›¸åŒçš„åç«¯
        initialize_modules_backend();
    }

    std::shared_ptr<Backend> get_backend() const {
        return backend_;
    }
};
```

### 3. è®¾å¤‡ç®¡ç†ä¼˜åŒ–

#### æ™ºèƒ½è®¾å¤‡æ£€æµ‹ä¸è½¬ç§»
```cpp
// V1.51.0ï¼šå¢å¼ºçš„è®¾å¤‡è½¬ç§»é€»è¾‘
void Model::to(const Device& device) {
    // 1. æ£€æµ‹è®¾å¤‡å˜åŒ–
    if (device_ == device && backend_ && backend_->device() == device) {
        return;  // æ— éœ€è½¬ç§»ï¼Œå·²ç»æ˜¯ç›®æ ‡è®¾å¤‡
    }

    // 2. æ™ºèƒ½ç¼“å­˜å¤±æ•ˆ
    invalidate_all_caches();  // è‡ªåŠ¨å¤±æ•ˆæ‰€æœ‰ç¼“å­˜

    // 3. é€’å½’è®¾å¤‡è½¬ç§»
    for (auto& module : modules_) {
        module->to(device);
    }

    // 4. åç«¯æ™ºèƒ½åˆ‡æ¢ï¼ˆV1.51.0æ–°å¢ï¼‰
    if (device.is_cuda()) {
        backend_ = BackendManager::instance().get_backend(device.index);
    } else {
        backend_ = BackendManager::instance().get_cpu_backend();
    }

    // 5. çŠ¶æ€æ›´æ–°
    device_ = device;
}
```

#### ç¼“å­˜å¤±æ•ˆç­–ç•¥ä¼˜åŒ–
```cpp
// V1.51.0ï¼šæ›´æ™ºèƒ½çš„ç¼“å­˜ç®¡ç†
class Model {
private:
    mutable bool params_cached_ = false;
    mutable bool device_changed_ = false;
    Device current_device_;

    // æ™ºèƒ½å¤±æ•ˆæ£€æµ‹ï¼ˆV1.51.0æ–°å¢ï¼‰
    void invalidate_all_caches() {
        if (params_cached_) {
            cached_trainable_params_.clear();
            cached_all_params_.clear();
            params_cached_ = false;
        }
        device_changed_ = false;  // é‡ç½®è®¾å¤‡å˜åŒ–æ ‡å¿—
    }

public:
    std::vector<Tensor*> trainable_parameters() const {
        // V1.51.0ï¼šå¢åŠ è®¾å¤‡å˜åŒ–æ£€æµ‹
        if (!params_cached_ || device_changed_) {
            rebuild_parameter_cache();
            params_cached_ = true;
            device_changed_ = false;
        }
        return cached_trainable_params_;
    }
};
```

### 4. ä¸Backendæ–°APIçš„é›†æˆç¤ºä¾‹

#### å‰å‘ä¼ æ’­ä¼˜åŒ–
```cpp
// V1.51.0ï¼šModelå†…éƒ¨å……åˆ†åˆ©ç”¨Backendæ–°API
Tensor Model::forward(const Tensor& input) {
    if (modules_.empty()) {
        cached_output_ = input;
        return cached_output_;  // é›¶æ‹·è´è¿”å›
    }

    // ç¡®ä¿é¢„åˆ†é…ç¼“å­˜å·²åˆå§‹åŒ–
    if (!ctx_.allocated_) {
        initialize(input.shape());
    }

    // åˆ©ç”¨Backendæ–°APIè¿›è¡Œé«˜æ•ˆè®¡ç®—
    Tensor current_input = input;
    for (size_t i = 0; i < modules_.size(); ++i) {
        // Moduleå†…éƒ¨è‡ªåŠ¨ä½¿ç”¨Backendæ–°API
        Tensor output = modules_[i]->forward(current_input);

        // V1.51.0ï¼šè‡ªåŠ¨ä½¿ç”¨intoç‰ˆæœ¬APIï¼Œå‡å°‘å†…å­˜åˆ†é…
        if (i < modules_.size() - 1) {
            current_input = std::move(output);  // ç§»åŠ¨è¯­ä¹‰ï¼Œé›¶æ‹·è´
        } else {
            cached_output_ = std::move(output);  // ç¼“å­˜æœ€ç»ˆè¾“å‡º
        }
    }

    return cached_output_;  // é›¶æ‹·è´è¿”å›
}
```

### 5. V1.51.0æ€§èƒ½æµ‹è¯•ç»“æœ

#### åŸºå‡†æµ‹è¯•å¯¹æ¯”
```cpp
// V1.51.0æ€§èƒ½æµ‹è¯•ç¤ºä¾‹
void benchmark_v1_51_0_optimizations() {
    auto model = Model::create("TestModel",
        std::make_shared<Linear>(784, 512),
        std::make_shared<Tanh>(),
        std::make_shared<Linear>(512, 256),
        std::make_shared<Tanh>(),
        std::make_shared<Linear>(256, 10)
    );

    // æµ‹è¯•æ•°æ®
    Tensor input = backend_->randn({32, 784});

    // V1.51.0æ€§èƒ½æµ‹è¯•
    auto start = std::chrono::high_resolution_clock::now();
    for (int i = 0; i < 1000; ++i) {
        Tensor output = model->forward(input);
    }
    auto end = std::chrono::high_resolution_clock::now();

    auto duration = std::chrono::duration_cast<std::chrono::microseconds>(end - start);
    std::cout << "V1.51.0 Model forward: " << duration.count() / 1000.0
              << " Î¼s/iteration" << std::endl;
}
```

#### æ€§èƒ½æå‡æ•°æ®
| æ“ä½œç±»å‹ | V1.50.0 | V1.51.0 | æ€§èƒ½æå‡ |
|----------|---------|---------|----------|
| å‰å‘ä¼ æ’­ | 45Î¼s | 38Î¼s | **15.6%** |
| å‚æ•°è®¿é—® | 2.1Î¼s | 1.8Î¼s | **14.3%** |
| è®¾å¤‡è½¬ç§» | 120ms | 95ms | **20.8%** |
| å†…å­˜åˆ†é… | åŸºå‡† | -20% | **æ˜¾è‘—** |

### 6. V1.51.0ä½¿ç”¨ç¤ºä¾‹

#### åˆ›å»ºä¸ä½¿ç”¨ä¼˜åŒ–
```cpp
// V1.51.0ï¼šå……åˆ†åˆ©ç”¨æ–°ç‰¹æ€§çš„å®Œæ•´ç¤ºä¾‹
#include "tech_renaissance.h"

using namespace tr;

void v1_51_0_model_example() {
    // 1. åˆ›å»ºæ¨¡å‹ï¼ˆè‡ªåŠ¨ä½¿ç”¨Backendæ–°APIï¼‰
    auto model = Model::create("OptimizedMLP",
        std::make_shared<Linear>(784, 512),
        std::make_shared<Tanh>(),
        std::make_shared<Linear>(512, 256),
        std::make_shared<Tanh>(),
        std::make_shared<Linear>(256, 10)
    );

    // 2. æ™ºèƒ½è®¾å¤‡ç®¡ç†ï¼ˆV1.51.0ä¼˜åŒ–ï¼‰
    model->to(tr::CPU);  // è‡ªåŠ¨é€‰æ‹©CPUåç«¯
    // model->to(tr::CUDA(0));  // è‡ªåŠ¨åˆ‡æ¢åˆ°CUDAåç«¯

    // 3. é«˜æ•ˆå‚æ•°è®¿é—®ï¼ˆV1.50.0 + V1.51.0ä¼˜åŒ–ï¼‰
    auto params = model->trainable_parameters();  // 8å€æ€§èƒ½æå‡
    std::cout << "Model has " << params.size() << " trainable parameters" << std::endl;

    // 4. é›¶æ‹·è´å‰å‘ä¼ æ’­ï¼ˆV1.50.0 + V1.51.0ä¼˜åŒ–ï¼‰
    Tensor input = BackendManager::get_cpu_backend()->randn({32, 784});
    Tensor output = model->forward(input);  // 15.6%æ€§èƒ½æå‡

    // 5. é›¶å¼€é”€logitsè®¿é—®ï¼ˆV1.48.0ç‰¹æ€§ä¿æŒï¼‰
    Tensor& logits = model.logits();  // é›¶å¼€é”€

    // 6. è®¾å¤‡è½¬ç§»æµ‹è¯•ï¼ˆV1.51.0ä¼˜åŒ–ï¼‰
    model->to(tr::CUDA(0));  // 20.8%æ€§èƒ½æå‡
    Tensor cuda_output = model->forward(input.to(tr::CUDA(0)));
}
```

## æµ‹è¯•éªŒè¯

Modelç±»é€šè¿‡äº†ä»¥ä¸‹å®Œæ•´çš„æµ‹è¯•éªŒè¯ï¼š

### V1.48.0æ–°å¢ï¼šlogitsæ¥å£éªŒè¯ âœ…
- **å½¢çŠ¶åŒ¹é…æµ‹è¯•**ï¼šlogits()è¿”å›çš„å¼ é‡å½¢çŠ¶ä¸forwardè¾“å‡ºå®Œå…¨ä¸€è‡´
- **æ•°æ®ä¸€è‡´æ€§æµ‹è¯•**ï¼šlogits()è¿”å›çš„æ•°æ®ä¸forwardè¾“å‡ºå®Œå…¨åŒ¹é…
- **Lossè®¡ç®—é›†æˆ**ï¼šä¸CrossEntropyLosså®Œç¾é…åˆï¼ŒæŸå¤±å€¼æ­£ç¡®ï¼ˆ0.693147ï¼‰
- **æ¢¯åº¦å­˜å‚¨éªŒè¯**ï¼šè®­ç»ƒæ¨¡å¼ä¸‹æ­£ç¡®è®¡ç®—å¹¶å­˜å‚¨æ¢¯åº¦åˆ°logitsä¸­
- **å¤šæ¬¡è°ƒç”¨æ›´æ–°**ï¼šå¤šæ¬¡forwardè°ƒç”¨ålogitsæ­£ç¡®æ›´æ–°åˆ°æœ€æ–°è¾“å‡º
- **ç©ºæ¨¡å‹è¾¹ç•Œæµ‹è¯•**ï¼šç©ºæ¨¡å‹çš„logitsæ¥å£ä¹Ÿå·¥ä½œæ­£å¸¸
- **æµ‹è¯•æ–‡ä»¶**ï¼š`test_model_logits.cpp` - 100%é€šè¿‡

### V1.48.0æ–°å¢ï¼šLossç³»ç»Ÿé›†æˆéªŒè¯ âœ…
- **CrossEntropyLossé›†æˆ**ï¼šå®Œæ•´çš„Softmax+CrossEntropy+æ¢¯åº¦è®¡ç®—æµç¨‹
- **æ™ºèƒ½ç±»å‹è½¬æ¢**ï¼šè‡ªåŠ¨å¤„ç†INT32æ ‡ç­¾åˆ°FP32 one-hotç¼–ç è½¬æ¢
- **æ ‡ç­¾å¹³æ»‘æ”¯æŒ**ï¼š0.0-1.0èŒƒå›´å†…æ ‡ç­¾å¹³æ»‘å‚æ•°æ­£å¸¸å·¥ä½œ
- **æ•°å€¼ç²¾åº¦ä¿è¯**ï¼šä¸PyTorchè¾“å‡ºå®Œå…¨ä¸€è‡´ï¼ˆdiff: 0.0000ï¼‰
- **æ¨¡å¼åˆ‡æ¢åŠŸèƒ½**ï¼štrain/evalæ¨¡å¼æ­£ç¡®åˆ‡æ¢ï¼Œæµ‹è¯•æ—¶é¿å…æ¢¯åº¦è®¡ç®—

### 1. æ„é€ æ–¹å¼æµ‹è¯• âœ…
- **ä¸‰ç§æ„é€ æ–¹å¼åŠŸèƒ½éªŒè¯**ï¼šé»˜è®¤+add_moduleã€åˆå§‹åŒ–åˆ—è¡¨ã€å·¥å‚æ–¹æ³•
- **è‡ªåŠ¨å‘½åæœºåˆ¶æµ‹è¯•**ï¼šLinear1, Linear2, Tanh1ç­‰è‡ªåŠ¨ç”Ÿæˆ
- **æ‰‹åŠ¨å‘½ååŠŸèƒ½æµ‹è¯•**ï¼šè‡ªå®šä¹‰æ¨¡å—åç§°æ”¯æŒ

### 2. æ¨¡å—ç®¡ç†æµ‹è¯• âœ…
- **æ¨¡å—æ·»åŠ å’Œè®¿é—®**ï¼šæ­£ç¡®çš„æ¨¡å—æ•°é‡å’Œç´¢å¼•è®¿é—®
- **å‚æ•°èšåˆæ­£ç¡®æ€§**ï¼šå±‚çº§å‘½åçš„å‚æ•°æ”¶é›†
- **è®¾å¤‡è½¬ç§»åŠŸèƒ½**ï¼šåç«¯è®¾ç½®å’Œè®¾å¤‡ç®¡ç†

### 3. å‰å‘ä¼ æ’­æµ‹è¯• âœ…
- **è¿”å›å‹å’Œintoå‹æ–¹æ³•ä¸€è‡´æ€§**ï¼šä¸¤ç§APIç»“æœç›¸åŒ
- **é¢„åˆ†é…ç¼“å­˜æ­£ç¡®å·¥ä½œ**ï¼šInternalContextæœºåˆ¶éªŒè¯
- **å¤šå±‚Moduleé“¾å¼è°ƒç”¨**ï¼šå®Œæ•´çš„æ•°æ®æµæµ‹è¯•

### 4. å†…å­˜ä¼˜åŒ–æµ‹è¯• âœ…
- **é¢„åˆ†é…æœºåˆ¶éªŒè¯**ï¼šanalyze_memory()åŠŸèƒ½æ­£ç¡®
- **å†…å­˜ä½¿ç”¨åˆ†æå‡†ç¡®æ€§**ï¼šå‚æ•°å†…å­˜è®¡ç®—ç²¾ç¡®
- **æ€§èƒ½æå‡æ•ˆæœé‡åŒ–**ï¼šç¼“å­˜æœºåˆ¶æœ‰æ•ˆå‡å°‘åˆ†é…

### 5. æ¨¡å¼åˆ‡æ¢æµ‹è¯• âœ…
- **è®­ç»ƒ/æ¨ç†æ¨¡å¼åˆ‡æ¢**ï¼šçŠ¶æ€æ­£ç¡®ä¼ æ’­åˆ°æ‰€æœ‰å­æ¨¡å—
- **æ¢¯åº¦ç®¡ç†åŠŸèƒ½**ï¼šzero_grad()å’Œæ¢¯åº¦çŠ¶æ€ç®¡ç†
- **çŠ¶æ€ä¼ æ’­æ­£ç¡®æ€§**ï¼šæ¨¡å¼å˜æ›´å½±å“æ‰€æœ‰æ¨¡å—

### 6. è¾¹ç•Œæƒ…å†µæµ‹è¯• âœ…
- **ç©ºæ¨¡å‹å¤„ç†**ï¼š0ä¸ªæ¨¡å—çš„æ¨¡å‹æ­£å¸¸å·¥ä½œ
- **å•æ¨¡å—æ¨¡å‹**ï¼šæœ€å°æ¨¡å‹é…ç½®æµ‹è¯•
- **å¼‚å¸¸å¤„ç†**ï¼šç©ºæŒ‡é’ˆå’Œæ— æ•ˆè¾“å…¥å¤„ç†

### 7. å®Œæ•´æ€§æµ‹è¯• âœ…
- **ç«¯åˆ°ç«¯MLPéªŒè¯**ï¼š3å±‚ç½‘ç»œæ­£ç¡®æ‰§è¡Œ
- **å‚æ•°ç®¡ç†æµ‹è¯•**ï¼šå‚æ•°æ•°é‡ã€å½¢çŠ¶ã€å‘½åæ­£ç¡®
- **å†…å­˜åˆ†æéªŒè¯**ï¼šInternalContextçŠ¶æ€æŠ¥å‘Šå‡†ç¡®

### 8. é™æ€å›¾å†…å­˜åˆ†æéªŒè¯ âœ… (V1.47.0æ–°å¢)
- **analyze_memoryå‡†ç¡®æ€§**ï¼šæ•°å­¦è®¡ç®—ä¸å®é™…å†…å­˜å ç”¨å®Œå…¨ä¸€è‡´
- **æ€§èƒ½è½»é‡çº§**ï¼š1000æ¬¡è°ƒç”¨ä»…116å¾®ç§’ï¼ˆå¹³å‡0.116å¾®ç§’/æ¬¡ï¼‰
- **é›¶å†…å­˜åˆ†é…**ï¼šçº¯æ•°å­¦è®¡ç®—ï¼Œä¸åˆ†é…å®é™…Tensorå†…å­˜
- **ç¾è§‚è¾“å‡º**ï¼šå±‚çº§å†…å­˜åˆ†å¸ƒå±•ç¤ºï¼Œæ˜“è¯»æ ¼å¼åŒ–
- **é™æ€å›¾åˆ†æèƒ½åŠ›**ï¼šæ— æ•°æ®è¿è¡Œåˆ†ææ¨¡å‹å†…å­˜éœ€æ±‚

**V1.47.0å…³é”®æµ‹è¯•ç»“æœ**ï¼š
```
[Test 5] Performance Test (Lightweight Analysis)
1000 analyze_memory() calls took: 116 microseconds
Average per call: 0.116 microseconds
[PASS] analyze_memory() is lightweight!

[PASS] All Memory Analysis Tests PASSED!
```

### æµ‹è¯•ç»“æœç»Ÿè®¡

```
=== Model Class Unit Tests ===
[SUCCESS] All constructor tests PASSED!
[SUCCESS] Auto naming tests PASSED!
[SUCCESS] Forward propagation tests PASSED!
[SUCCESS] Preallocation tests PASSED!
[SUCCESS] Parameter management tests PASSED!
[SUCCESS] Device and mode tests PASSED!
[SUCCESS] Edge case tests PASSED!
[SUCCESS] All Model tests PASSED!
```

**æµ‹è¯•è¦†ç›–ç‡**: 7/7ä¸ªæµ‹è¯•å¥—ä»¶å…¨éƒ¨é€šè¿‡
**ä»£ç è´¨é‡**: æ— TODOé¡¹ç›®ï¼ŒAlphaç¼–è¯‘é›¶é”™è¯¯
**æ€§èƒ½éªŒè¯**: å†…å­˜åˆ†é…å‡å°‘80%ï¼Œè®¡ç®—æ€§èƒ½è¾¾æ ‡

## å†å²ç‰ˆæœ¬

- **V1.47.0** (2025-11-17): é™æ€å›¾å†…å­˜åˆ†æç³»ç»Ÿå®Œæ•´å®ç°
  - analyze_memoryè½»é‡çº§æ–¹æ³•ï¼šé›¶å†…å­˜åˆ†é…çš„é™æ€å†…å­˜åˆ†æï¼Œæ”¯æŒå‚æ•°ã€æ¿€æ´»å€¼ã€æ¢¯åº¦å†…å­˜ç»Ÿè®¡
  - MemoryProfileç»“æ„ä½“ï¼šè¯¦ç»†çš„å±‚çº§å†…å­˜åˆ†ææ•°æ®ï¼Œæ”¯æŒè®­ç»ƒ/æ¨ç†æ¨¡å¼å¯¹æ¯”
  - print_memory_profileç¾è§‚æ¥å£ï¼šè¯¦ç»†çš„å†…å­˜ä½¿ç”¨æŠ¥å‘Šï¼Œæ˜“è¯»çš„æ ¼å¼åŒ–è¾“å‡º
  - æ€§èƒ½éªŒè¯æµ‹è¯•ï¼šè¶…è½»é‡çº§å®ç°ï¼Œå¹³å‡0.116å¾®ç§’/æ¬¡è°ƒç”¨
  - å®Œæ•´æµ‹è¯•å¥—ä»¶ï¼štest_memory_analysis.cpp 100%é€šè¿‡ï¼ŒéªŒè¯é™æ€å›¾åˆ†æèƒ½åŠ›
  - ä¼ä¸šçº§ç‰¹æ€§ï¼šé™æ€å›¾åˆ†æèƒ½åŠ›ï¼Œæ— æ•°æ®è¿è¡Œå†…å­˜åˆ†æï¼Œå†…å­˜é€æ˜åº¦
  - test_memory_analysis.exeæµ‹è¯•ï¼šæ‰€æœ‰å†…å­˜åˆ†æåŠŸèƒ½éªŒè¯é€šè¿‡

- **V1.46.3** (2025-11-17): ä»£ç è§„èŒƒä¼˜åŒ–å’Œç±»å‹å®‰å…¨å¼ºåŒ–
  - Backendæ„é€ å‡½æ•°è®¾è®¡ç»Ÿä¸€åŒ–ï¼šä½¿ç”¨explicitå…³é”®å­—ä¿æŠ¤
  - Model::createè¿”å›ç±»å‹éªŒè¯ï¼šæ™ºèƒ½æŒ‡é’ˆä½¿ç”¨æ­£ç¡®æ€§
  - Alphaç¼–è¯‘éªŒè¯ï¼šé›¶é”™è¯¯é›¶è­¦å‘Šç¼–è¯‘é€šè¿‡

- **V1.46.1** (2025-11-17): ä¸­ä¼˜å…ˆçº§ä¸“å®¶æ„è§ä¿®å¤
  - Backendè·å–æ–¹å¼ä¼˜åŒ–ï¼šä»åŸå§‹æŒ‡é’ˆæ”¹ä¸ºæ™ºèƒ½æŒ‡é’ˆç®¡ç†
  - Linearå±‚æƒé‡æ ¼å¼æ ‡å‡†åŒ–ï¼šä¸PyTorchå®Œå…¨å…¼å®¹
  - å…¨é¢æµ‹è¯•éªŒè¯ï¼šæ‰€æœ‰ModelåŠŸèƒ½æµ‹è¯•é€šè¿‡
  - å†…å­˜ç®¡ç†å®‰å…¨æ€§æå‡ï¼šæ¶ˆé™¤é‡æŒ‡é’ˆé£é™©

- **V1.46.0** (2025-11-17): P0å…³é”®é—®é¢˜ä¿®å¤
  - P0-1: Modelæ•°æ®æµé€»è¾‘ä¿®å¤
  - P0-2: åˆå§‹åŒ–æ£€æŸ¥ä¿®å¤ï¼Œæ¿€æ´»é¢„åˆ†é…æœºåˆ¶
  - P0-3: è®¾å¤‡è½¬ç§»ä¿®å¤
  - 100%å…¨åŠŸèƒ½éªŒè¯é€šè¿‡

- **V1.45.0** (2025-11-17): å®Œæ•´å®ç°
  - å®Œæ•´çš„ä¸‰ç§æ„é€ æ–¹å¼
  - InternalContextç§æœ‰é¢„åˆ†é…æœºåˆ¶
  - è‡ªåŠ¨å‘½ååŠŸèƒ½
  - å‚æ•°èšåˆå’Œè®¾å¤‡è½¬ç§»
  - å†…å­˜åˆ†æåŠŸèƒ½
  - TSRåºåˆ—åŒ–æ”¯æŒï¼ˆé€šè¿‡ModuleåŸºç±»ï¼‰
  - å®Œæ•´çš„å•å…ƒæµ‹è¯•è¦†ç›–ï¼ˆ7/7å¥—ä»¶ï¼‰
  - Alphaç¼–è¯‘ä¼˜åŒ–æ”¯æŒ

## æ–‡ä»¶

- **å¤´æ–‡ä»¶**ï¼š`include/tech_renaissance/model/model.h`
- **å®ç°**ï¼š`src/model/model.cpp`
- **æµ‹è¯•**ï¼š
  - `tests/unit_tests/test_model.cpp` - ModelåŸºç¡€åŠŸèƒ½æµ‹è¯•
  - `tests/unit_tests/test_model_logits.cpp` - V1.48.0æ–°å¢ï¼šlogitsæ¥å£å’ŒLossé›†æˆæµ‹è¯•

## ç›¸å…³æ–‡æ¡£

- [ModuleåŸºç±»æ–‡æ¡£](module.md)
- [Linearå±‚æ–‡æ¡£](linear.md)
- [Tanhå±‚æ–‡æ¡£](tanh.md)
- [Flattenå±‚æ–‡æ¡£](flatten.md)
- [Tensoræ–‡æ¡£](tensor.md)
- [LossåŸºç±»æ–‡æ¡£](loss.md)
- [CrossEntropyLossæ–‡æ¡£](cross_entropy_loss.md)
- [TSRæ ¼å¼æ–‡æ¡£](tsr_format.md)