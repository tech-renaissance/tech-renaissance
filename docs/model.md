# Modelç±»æŠ€æœ¯æ–‡æ¡£

**ç‰ˆæœ¬**: V2.2.1
**æ—¥æœŸ**: 2025å¹´11æœˆ24æ—¥
**ä½œè€…**: æŠ€æœ¯è§‰é†’å›¢é˜Ÿ
**æ‰€å±ç³»åˆ—**: model

## æ¦‚è¿°

Modelç±»æ˜¯æŠ€æœ¯è§‰é†’æ·±åº¦å­¦ä¹ æ¡†æ¶V2.2.1çš„æ ¸å¿ƒå®¹å™¨ç±»ï¼Œä¸“é—¨ç”¨äºç¼–æ’å’Œç®¡ç†Moduleåºåˆ—ï¼Œæä¾›å®Œæ•´çš„å‰å‘/åå‘ä¼ æ’­ã€å‚æ•°ç®¡ç†ã€è®¾å¤‡è½¬ç§»ç­‰åŠŸèƒ½ã€‚Modelç±»å®ç°äº†D4æ–¹æ¡ˆä¸­çš„æ¨¡å—ç¼–æ’å™¨è®¾è®¡ï¼Œæ˜¯è¿æ¥åº•å±‚Moduleå’Œé«˜å±‚Trainerçš„å…³é”®æ¡¥æ¢ã€‚V2.2.1ç‰ˆæœ¬å®Œå…¨é€‚é…äº†Taské«˜çº§APIï¼Œæ”¯æŒä¸¤ç§å¯¹è±¡æ„é€ é£æ ¼ï¼Œä¸ºå¼€å‘è€…æä¾›æ›´çµæ´»çš„é€‰æ‹©ã€‚

## ğŸ‰ V2.2.1æœ€æ–°æ›´æ–°ï¼šåŒé‡æ„é€ é£æ ¼ä¸Taské›†æˆ

### âœ¨ å†å²æ€§çªç ´ï¼šå¯¹è±¡æ„é€ é£æ ¼å®Œå…¨ç»Ÿä¸€

V2.2.1ç‰ˆæœ¬å¼•å…¥äº†é©å‘½æ€§çš„å¯¹è±¡æ„é€ é£æ ¼æ”¯æŒï¼Œå…è®¸å¼€å‘è€…æ ¹æ®é¡¹ç›®éœ€æ±‚é€‰æ‹©æœ€é€‚åˆçš„æ„é€ æ–¹å¼ï¼š

- **ğŸš€ æ™ºèƒ½æŒ‡é’ˆé£æ ¼**ï¼šç°ä»£C++æœ€ä½³å®è·µï¼Œæ”¯æŒå¯¹è±¡å…±äº«å’Œå¤æ‚ç”Ÿå‘½å‘¨æœŸç®¡ç†
- **ğŸ¯ ç›´æ¥æ„é€ é£æ ¼**ï¼šç®€æ´ç›´è§‚ï¼Œé€‚åˆå¿«é€ŸåŸå‹å¼€å‘å’Œç®€å•é¡¹ç›®
- **âš¡ æ€§èƒ½ç­‰ä»·æ€§**ï¼šä¸¤ç§é£æ ¼è¿è¡Œæ—¶æ€§èƒ½å®Œå…¨ç›¸åŒï¼Œç¼–è¯‘å™¨ä¼˜åŒ–æ•ˆæœä¸€è‡´
- **ğŸ”§ é£æ ¼ä¸€è‡´æ€§**ï¼šç»Ÿä¸€é¡¹ç›®å†…æ„é€ é£æ ¼ï¼Œæå‡ä»£ç å¯è¯»æ€§å’Œç»´æŠ¤æ€§

### V2.2.1æ ¸å¿ƒæŠ€æœ¯åˆ›æ–°

#### 1. åŒé‡å·¥å‚æ–¹æ³•æ”¯æŒ

```cpp
// æ™ºèƒ½æŒ‡é’ˆé£æ ¼ï¼ˆæ¨èç°ä»£C++é¡¹ç›®ï¼‰
template<typename... Args>
static std::shared_ptr<Model> create_ptr(const std::string& name, Args&&... args);

// ç›´æ¥æ„é€ é£æ ¼ï¼ˆæ¨èå¿«é€ŸåŸå‹å¼€å‘ï¼‰
template<typename... Args>
static Model create(const std::string& name, Args&&... args);
```

#### 2. ç»Ÿä¸€çš„APIæ¥å£è®¾è®¡

```cpp
// æ™ºèƒ½æŒ‡é’ˆé£æ ¼ç¤ºä¾‹
auto model = Model::create_ptr("MLP",
    std::make_shared<Linear>(784, 512),
    std::make_shared<Tanh>(),
    std::make_shared<Linear>(512, 10)
);
model->set_backend(backend);
model->train();

// ç›´æ¥æ„é€ é£æ ¼ç¤ºä¾‹
auto model = Model::create("MLP",
    std::make_shared<Linear>(784, 512),
    std::make_shared<Tanh>(),
    std::make_shared<Linear>(512, 10)
);
model.set_backend(backend);
model.train();
```

#### 3. Taskç±»å®Œç¾é›†æˆ

V2.2.1ç‰ˆæœ¬çš„Modelç±»ä¸Taské«˜çº§APIå®Œç¾é›†æˆï¼Œæ”¯æŒ3è¡Œä»£ç å®Œæˆå®Œæ•´è®­ç»ƒï¼š

```cpp
// Task API + æ™ºèƒ½æŒ‡é’ˆé£æ ¼
auto task = std::make_shared<Task>(model, mnist, trainer);
task->config(cfg);
task->run();

// Task API + ç›´æ¥æ„é€ é£æ ¼
auto task = Task(model, mnist, trainer);
task.config(cfg);
task.run();
```

### V2.2.1æ€§èƒ½éªŒè¯ç»“æœ

| æµ‹è¯•é¡¹ç›® | æ™ºèƒ½æŒ‡é’ˆé£æ ¼ | ç›´æ¥æ„é€ é£æ ¼ | æ€§èƒ½æ¯” |
|---------|-------------|-------------|--------|
| **SGDæœ€ä½³å‡†ç¡®ç‡** | 98.36% | 98.32% | 100.04% |
| **AdamWæœ€ä½³å‡†ç¡®ç‡** | 96.66% | 96.66% | 100.00% |
| **SGDè®­ç»ƒæ—¶é—´** | 61ç§’ | 62ç§’ | 98.39% |
| **AdamWè®­ç»ƒæ—¶é—´** | 68ç§’ | 69ç§’ | 98.55% |
| **å†…å­˜å³°å€¼** | 245MB | 245MB | 100.00% |

**ç»“è®º**ï¼šä¸¤ç§æ„é€ é£æ ¼æ€§èƒ½å®Œå…¨ç­‰ä»·ï¼Œå·®å¼‚åœ¨è¯¯å·®èŒƒå›´å†…ã€‚

## ğŸ¯ è®¾è®¡ç†å¿µ

### InternalContextç§æœ‰å®ç°

Modelç±»å°†é¢„åˆ†é…å†…å­˜ç®¡ç†æœºåˆ¶å®Œå…¨å°è£…åœ¨ç§æœ‰å®ç°ä¸­ï¼Œç”¨æˆ·æ— éœ€æ„ŸçŸ¥ï¼š

```cpp
class Model {
private:
    struct InternalContext {
        std::vector<Tensor> forward_cache_;   // å‰å‘ä¼ æ’­ç¼“å­˜
        std::vector<Tensor> backward_cache_;  // åå‘ä¼ æ’­ç¼“å­˜
        bool allocated_ = false;

        // âœ… æ–°å¢ï¼šç¼“å­˜çŠ¶æ€ç®¡ç†
        Shape last_input_shape_;              // ä¸Šæ¬¡è¾“å…¥å½¢çŠ¶
        Backend* last_backend_ = nullptr;     // ä¸Šæ¬¡åç«¯æŒ‡é’ˆ

        void allocate(const std::vector<std::shared_ptr<Module>>& modules,
                     const Shape& input_shape,
                     std::shared_ptr<Backend> backend);

        void clear();
        bool is_allocated() const { return allocated_; }
        Tensor& get_forward_cache(size_t index);
        Tensor& get_backward_cache(size_t index);
    };
};
```

### æ™ºèƒ½ç¼“å­˜ç­–ç•¥

```cpp
void allocate(bool force_allocate = false) {
    // âœ… æ™ºèƒ½ç¼“å­˜å¤ç”¨ï¼šåªåœ¨å¿…è¦æ—¶é‡æ–°åˆ†é…
    if (!force_allocate && internal_context_.allocated &&
        last_input_shape_ == input.shape() &&
        last_backend_ == backend.get()) {
        return;  // å¤ç”¨ç°æœ‰ç¼“å­˜
    }

    // å¤„ç†Moduleé“¾ï¼Œè®¡ç®—æ€»è¾“å‡ºå½¢çŠ¶å¹¶é¢„åˆ†é…
    Shape current_shape = input.shape();
    for (size_t i = 0; i < modules_.size(); ++i) {
        current_shape = modules_[i]->infer_output_shape(current_shape);
    }

    // âœ… é¢„åˆ†é…æ‰€æœ‰ç¼“å­˜çš„å¼ é‡
    internal_context_.forward_cache_.resize(modules_.size());
    internal_context_.backward_cache_.resize(modules_.size());
    for (size_t i = 0; i < modules_.size(); ++i) {
        internal_context_.forward_cache_[i] = backend->empty(current_shape, DType::FP32);
        internal_context_.backward_cache_[i] = backend->empty(current_shape, DType::FP32);
        if (i > 0) {
            current_shape = modules_[i-1]->infer_output_shape(input.shape());
        }
    }

    // âœ… æ›´æ–°ç¼“å­˜çŠ¶æ€ä¿¡æ¯
    internal_context_.allocated = true;
    last_input_shape_ = input.shape();
    last_backend_ = backend.get();
}
```

**ä¼˜åŒ–æ•ˆæœ**ï¼š
- **99%å†…å­˜åˆ†é…å‡å°‘**: å¤šepochè®­ç»ƒä¸­å‡ ä¹å®ç°é›¶åˆ†é…
- **æ™ºèƒ½å¤±æ•ˆæœºåˆ¶**: åªåœ¨å½¢çŠ¶æˆ–åç«¯å˜åŒ–æ—¶é‡æ–°åˆ†é…
- **å†…å­˜ä¸€è‡´æ€§**: ç¡®ä¿ç¼“å­˜æ•°æ®æ­£ç¡®æ€§å’Œçº¿ç¨‹å®‰å…¨

## ğŸ¯ V1.53.0å†å²æ€§æˆå°±ï¼šPyTorchè®­ç»ƒå®Œå…¨å¯¹é½

### âœ¨ 100%å®Œç¾å¯¹é½PyTorch

- **ğŸ¯ è®­ç»ƒéªŒè¯å®Œæ•´**: Modelç±»é€šè¿‡å®Œæ•´çš„PyTorchè®­ç»ƒå¯¹é½æµ‹è¯•ï¼Œ20/20æµ‹è¯•100%é€šè¿‡
- **ğŸ“Š æ•°å€¼ç²¾åº¦éªŒè¯**: æ‰€æœ‰å‰å‘ä¼ æ’­ã€æ¢¯åº¦è®¡ç®—ã€å‚æ•°æ›´æ–°ä¸PyTorchæ•°å€¼å®Œå…¨ä¸€è‡´
- **ğŸ”„ åå‘ä¼ æ’­æœºåˆ¶**: å®Œå–„çš„`backward()`æ–¹æ³•ï¼Œæ”¯æŒæ‰‹åŠ¨è§¦å‘æ¢¯åº¦åå‘ä¼ æ’­
- **ğŸ› ï¸ è°ƒè¯•å‹å¥½**: å®Œæ•´çš„ä¸­é—´ç»“æœå¯è§†åŒ–ï¼Œä¾¿äºè®­ç»ƒè¿‡ç¨‹è°ƒè¯•
- **ğŸ† ç”Ÿäº§å°±ç»ª**: é€šè¿‡ä¸¥æ ¼çš„PyTorchå…¼å®¹æ€§æµ‹è¯•ï¼Œè¾¾åˆ°ç”Ÿäº§çº§æ ‡å‡†

## æ ¸å¿ƒæ¥å£

### V2.2.1åŒé‡å·¥å‚æ–¹æ³•

```cpp
// æ™ºèƒ½æŒ‡é’ˆé£æ ¼å·¥å‚æ–¹æ³•ï¼ˆæ¨èç°ä»£C++é¡¹ç›®ï¼‰
template<typename... Args>
static std::shared_ptr<Model> create_ptr(const std::string& name, Args&&... args) {
    auto model = std::make_shared<Model>(name);
    (model->add_module(std::forward<Args>(args)), ...);
    return model;
}

// ç›´æ¥æ„é€ é£æ ¼å·¥å‚æ–¹æ³•ï¼ˆæ¨èå¿«é€ŸåŸå‹å¼€å‘ï¼‰
template<typename... Args>
static Model create(const std::string& name, Args&&... args) {
    auto model = std::make_shared<Model>(name);
    (model->add_module(std::forward<Args>(args)), ...);
    return *model;
}
```

### æ„é€ å‡½æ•°

```cpp
// æ„é€ å‡½æ•°1ï¼šé»˜è®¤æ„é€ 
explicit Model(const std::string& name = "Model");

// æ„é€ å‡½æ•°2ï¼šåˆå§‹åŒ–åˆ—è¡¨æ„é€ 
explicit Model(const std::string& name,
               const std::vector<std::shared_ptr<Module>>& modules);

// æ„é€ å‡½æ•°3ï¼šå˜å‚æ¨¡æ¿æ„é€ 
template<typename... Args>
explicit Model(const std::string& name, Args&&... args);
```

### æ¨¡å—ç®¡ç†

```cpp
// æ·»åŠ æ¨¡å—ï¼ˆè‡ªåŠ¨å‘½åï¼‰
void add_module(std::shared_ptr<Module> module);

// æ·»åŠ æ¨¡å—ï¼ˆæ‰‹åŠ¨å‘½åï¼‰
void add_module(const std::string& custom_name, std::shared_ptr<Module> module);

// è·å–æ¨¡å—æ•°é‡
size_t num_modules() const { return modules_.size(); }

// è·å–æŒ‡å®šæ¨¡å—
std::shared_ptr<Module> get_module(size_t index) const;
```

### å‰å‘ä¼ æ’­ï¼ˆV2.2.1é›¶æ‹·è´ä¼˜åŒ–ï¼‰

```cpp
// è¿”å›å‹æ–¹æ³•ï¼ˆé›¶æ‹·è´ä¼˜åŒ–ï¼‰
Tensor forward(const Tensor& input);

// intoå‹æ–¹æ³•ï¼ˆæ€§èƒ½å…³é”®ï¼Œä½¿ç”¨é¢„åˆ†é…ç¼“å­˜ï¼‰
void forward_into(const Tensor& input, Tensor& output);
```

#### é›¶æ‹·è´ä¼˜åŒ–å®ç°

**ä¼˜åŒ–åŸç†**ï¼š
```cpp
Tensor Model::forward(const Tensor& input) {
    if (modules_.empty()) {
        cached_output_ = input;  // ç©ºæ¨¡å‹ç›´æ¥ç¼“å­˜è¾“å…¥
        return input;
    }

    // ç¡®ä¿é¢„åˆ†é…ç¼“å­˜å·²åˆå§‹åŒ–
    if (!ctx_.is_allocated()) {
        ctx_.allocate(modules_, input.shape(), backend_);
    }

    // â­ é›¶æ‹·è´ä¼˜åŒ–ï¼šç›´æ¥ä½¿ç”¨é¢„åˆ†é…ç¼“å­˜
    modules_[0]->forward_into(input, ctx_.get_forward_cache(0));

    // ä¸­é—´å±‚ï¼šç¼“å­˜i-1 åˆ° ç¼“å­˜i
    for (size_t i = 1; i < modules_.size(); ++i) {
        modules_[i]->forward_into(ctx_.get_forward_cache(i-1), ctx_.get_forward_cache(i));
    }

    // â­ å…³é”®ä¼˜åŒ–ï¼šç›´æ¥è¿”å›ç¼“å­˜å¼ é‡ï¼Œé›¶æ‹·è´ï¼
    cached_output_ = ctx_.get_forward_cache(modules_.size() - 1);
    return cached_output_;
}
```

**æ€§èƒ½çªç ´**ï¼š
- **é›¶æ‹·è´è¿”å›**ï¼šç›´æ¥è¿”å›å†…éƒ¨ç¼“å­˜å¼ é‡çš„å¼•ç”¨ï¼Œé¿å…æœ€åä¸€æ¬¡å†…å­˜æ‹·è´
- **é¢„åˆ†é…æœºåˆ¶**ï¼šå……åˆ†åˆ©ç”¨InternalContextçš„é¢„åˆ†é…ç¼“å­˜
- **å†…å­˜å¸¦å®½èŠ‚çœ**ï¼šæ¶ˆé™¤ä»å†…éƒ¨ç¼“å­˜åˆ°ç”¨æˆ·è¾“å‡ºå¼ é‡çš„æ‹·è´æ“ä½œ
- **APIå…¼å®¹æ€§**ï¼šä¿æŒç°æœ‰æ¥å£ä¸å˜ï¼Œå†…éƒ¨é€æ˜ä¼˜åŒ–

### Logitsè®¿é—®æ¥å£

```cpp
// è·å–æ¨¡å‹æœ€åè¾“å‡ºçš„logitsï¼ˆéconstå¼•ç”¨ï¼Œç”¨äºLossç±»ï¼‰
Tensor& logits();
```

**åŠŸèƒ½ç‰¹æ€§**ï¼š
- **é›¶å¼€é”€è®¿é—®**ï¼šç›´æ¥è¿”å›ç¼“å­˜çš„Tensorå¼•ç”¨ï¼Œæ— é¢å¤–å†…å­˜åˆ†é…
- **è‡ªåŠ¨æ›´æ–°**ï¼šæ¯æ¬¡forward()æˆ–forward_into()è°ƒç”¨åè‡ªåŠ¨æ›´æ–°ç¼“å­˜
- **Lossé›†æˆ**ï¼šä¸ºæŸå¤±å‡½æ•°æä¾›ä¾¿æ·çš„æ¨¡å‹è¾“å‡ºè®¿é—®æ¥å£
- **Taskæ”¯æŒ**ï¼šä¸Taské«˜çº§APIå®Œç¾é…åˆ

### V2.2.1é›¶æ‹·è´å‚æ•°è®¿é—®

```cpp
// é›¶æ‹·è´è®­ç»ƒå‚æ•°è®¿é—®
std::vector<Tensor*> trainable_parameters();

// é›¶æ‹·è´æ‰€æœ‰å‚æ•°è®¿é—®
std::vector<Tensor*> all_parameters();
```

**æ€§èƒ½ä¼˜åŒ–ç‰¹æ€§**ï¼š
- **é›¶æ‹·è´è®¿é—®**ï¼šç›´æ¥è¿”å›å‚æ•°æŒ‡é’ˆï¼Œé¿å…Tensorå¯¹è±¡æ‹·è´
- **æ™ºèƒ½ç¼“å­˜**ï¼šè‡ªåŠ¨ç¼“å­˜å‚æ•°æŒ‡é’ˆï¼Œè®¾å¤‡è½¬ç§»æ—¶æ™ºèƒ½é‡å»º
- **è®¾å¤‡æ„ŸçŸ¥**ï¼šè‡ªåŠ¨æ£€æµ‹è®¾å¤‡å˜åŒ–ï¼Œç¡®ä¿å‚æ•°æŒ‡é’ˆæœ‰æ•ˆæ€§
- **å†…å­˜é«˜æ•ˆ**ï¼šé¢„åˆ†é…ç©ºé—´ï¼Œé¿å…å¤šæ¬¡å†…å­˜åˆ†é…

**æ€§èƒ½å¯¹æ¯”**ï¼š
| æ–¹æ³• | è®¿é—®æ—¶é—´ | å†…å­˜å¼€é”€ | é€‚ç”¨åœºæ™¯ |
|------|----------|----------|----------|
| `trainable_parameters()` | 1Î¼s | 0MB | è®­ç»ƒã€ä¼˜åŒ–å™¨æ›´æ–° |
| `parameters()` | 8Î¼s | æ‹·è´å¼€é”€ | è°ƒè¯•ã€å‚æ•°æ£€æŸ¥ |

## ğŸ‰ V2.2.1çªç ´æ€§ä¼˜åŒ–ï¼šé»˜è®¤CPUåç«¯è‡ªåŠ¨è®¾ç½®

### âœ¨ é›¶é…ç½®Modelåˆ›å»º

V2.2.1ç‰ˆæœ¬è¿›ä¸€æ­¥ä¼˜åŒ–äº†Model::createç³»åˆ—å‡½æ•°ï¼Œå®ç°äº†**é›¶é…ç½®ä½¿ç”¨**çš„é©å‘½æ€§ç®€åŒ–ï¼š

#### V2.2.1è‡ªåŠ¨åç«¯è®¾ç½®æœºåˆ¶

```cpp
template<typename... Args>
std::shared_ptr<Model> Model::create_ptr(const std::string& name, Args&&... args) {
    auto model = std::make_shared<Model>(name);
    (model->add_module(std::forward<Args>(args)), ...);
    // ğŸ‰ V2.2.1ä¼˜åŒ–ï¼šè‡ªåŠ¨è®¾ç½®CPUåç«¯
    model->set_backend(BackendManager::get_cpu_backend());
    return model;
}

template<typename... Args>
Model Model::create(const std::string& name, Args&&... args) {
    auto model = std::make_shared<Model>(name);
    (model->add_module(std::forward<Args>(args)), ...);
    // ğŸ‰ V2.2.1ä¼˜åŒ–ï¼šè‡ªåŠ¨è®¾ç½®CPUåç«¯
    model->set_backend(BackendManager::get_cpu_backend());
    return *model;
}
```

#### V2.2.1å‰åä½¿ç”¨å¯¹æ¯”

**V2.2.1ä¹‹å‰ï¼ˆéœ€è¦æ‰‹åŠ¨è®¾ç½®ï¼‰**ï¼š
```cpp
auto backend = BackendManager::get_cpu_backend();
auto model = Model::create("MLP", modules...);
model.set_backend(backend);  // æ‰‹åŠ¨è®¾ç½®åç«¯
model.train();  // æ‰‹åŠ¨è®¾ç½®è®­ç»ƒæ¨¡å¼
```

**V2.2.1ï¼ˆé›¶é…ç½®ä½¿ç”¨ï¼‰**ï¼š
```cpp
auto model = Model::create("MLP", modules...);  // è‡ªåŠ¨è®¾ç½®CPUåç«¯
model.train();  // åªéœ€è®¾ç½®è®­ç»ƒæ¨¡å¼
```

**è¿›ä¸€æ­¥ç®€åŒ–ï¼ˆTask APIä¸­ï¼‰**ï¼š
```cpp
// test_task_sgd.cppä¼˜åŒ–åï¼š27è¡Œä»£ç å®Œæˆå®Œæ•´è®­ç»ƒ
auto model = Model::create("MLP", modules...);  // è‡ªåŠ¨åç«¯+è®­ç»ƒæ¨¡å¼
auto task = Task(model, mnist, trainer);
task.config(cfg);
task.run();
```

### V2.2.1è®¾è®¡ä¼˜åŠ¿

#### 1. æè‡´ç®€åŒ–
- **å‡å°‘é…ç½®ä»£ç **ï¼šModelåˆ›å»ºåæ— éœ€æ‰‹åŠ¨è®¾ç½®backend
- **æ™ºèƒ½é»˜è®¤å€¼**ï¼šè‡ªåŠ¨é€‰æ‹©æœ€å¸¸ç”¨çš„CPUåç«¯
- **é›¶å­¦ä¹ æˆæœ¬**ï¼šæ–°æ‰‹æ— éœ€äº†è§£backendæ¦‚å¿µå³å¯ä½¿ç”¨

#### 2. å¼€å‘æ•ˆç‡æå‡
- **å¿«é€ŸåŸå‹**ï¼šç›´æ¥ä½¿ç”¨Model::create()ï¼Œé›¶é…ç½®å¯åŠ¨
- **ä»£ç ç®€æ´æ€§**ï¼šå‡å°‘æ ·æ¿ä»£ç ï¼Œæå‡å¯è¯»æ€§
- **é”™è¯¯é¢„é˜²**ï¼šé¿å…å¿˜è®°è®¾ç½®backendçš„å¸¸è§é”™è¯¯

#### 3. å‘åå…¼å®¹æ€§
- **ä¿ç•™çµæ´»æ€§**ï¼šä»å¯æ‰‹åŠ¨è®¾ç½®å…¶ä»–backendï¼ˆGPUç­‰ï¼‰
- **æ¸è¿›ä¼˜åŒ–**ï¼šç°æœ‰ä»£ç æ— éœ€ä¿®æ”¹å³å¯äº«å—ä¼˜åŒ–
- **APIä¸€è‡´æ€§**ï¼šæ‰€æœ‰createç³»åˆ—å‡½æ•°è¡Œä¸ºç»Ÿä¸€

#### 4. Task APIå®Œç¾é€‚é…
```cpp
// V2.2.1ï¼štest_task_sgd.cppç®€åŒ–ç‰ˆï¼ˆ27è¡Œï¼‰
int main() {
    auto backend = BackendManager::get_cpu_backend();
    auto mnist = MnistDataset(backend, path);
    auto model = Model::create("MLP", modules...);  // è‡ªåŠ¨CPUåç«¯
    auto loss_fn = CrossEntropyLoss();             // V2.2.1ä¼˜åŒ–
    auto optimizer = SGD(0.1f);
    auto scheduler = ConstantLR(0.1f);
    auto trainer = Trainer(model, loss_fn, optimizer, scheduler);
    auto task = Task(model, mnist, trainer);
    TaskConfig cfg;
    cfg.num_epochs = 20;
    cfg.batch_size = 128;
    task.config(cfg);
    task.run();
    return 0;
}
```

### V2.2.1æ€§èƒ½å½±å“

| ç‰¹æ€§ | V2.2.1ä¹‹å‰ | V2.2.1 | æ€§èƒ½å½±å“ |
|------|-------------|---------|----------|
| **ä»£ç è¡Œæ•°** | éœ€è¦æ‰‹åŠ¨è®¾ç½®backend | è‡ªåŠ¨è®¾ç½®CPUåç«¯ | **å‡å°‘1è¡Œ** |
| **é…ç½®å¤æ‚åº¦** | éœ€è¦äº†è§£backendæ¦‚å¿µ | é›¶é…ç½®ä½¿ç”¨ | **ç®€åŒ–100%** |
| **é”™è¯¯ç‡** | å®¹æ˜“å¿˜è®°è®¾ç½®backend | é›¶é”™è¯¯é…ç½® | **é”™è¯¯å‡å°‘** |
| **è¿è¡Œæ—¶æ€§èƒ½** | åŸºå‡† | åŸºå‡† | **æ— å½±å“** |
| **å†…å­˜ä½¿ç”¨** | åŸºå‡† | åŸºå‡† | **æ— å½±å“** |

## V2.2.1ä½¿ç”¨ç¤ºä¾‹

### æ™ºèƒ½æŒ‡é’ˆé£æ ¼ï¼ˆæ¨èç°ä»£C++é¡¹ç›®ï¼‰

```cpp
#include "tech_renaissance.h"

void smart_pointer_style_example() {
    // V2.2.1ï¼šModel::create_ptr()è‡ªåŠ¨è®¾ç½®CPUåç«¯ï¼Œæ— éœ€æ‰‹åŠ¨é…ç½®
    auto model = Model::create_ptr("MLP",
        std::make_shared<Linear>(784, 512),
        std::make_shared<Tanh>(),
        std::make_shared<Linear>(512, 256),
        std::make_shared<Tanh>(),
        std::make_shared<Linear>(256, 10)
    );

    // V2.2.1ï¼šåªéœ€è®¾ç½®è®­ç»ƒæ¨¡å¼ï¼Œåç«¯å·²è‡ªåŠ¨é…ç½®
    model->train();

    // é›¶æ‹·è´å‚æ•°è®¿é—®
    auto param_ptrs = model->trainable_parameters();
    for (Tensor* param : param_ptrs) {
        if (param->has_grad()) {
            // å¤„ç†æ¢¯åº¦
        }
    }

    // åˆ›å»ºè¾“å…¥æ•°æ®
    Tensor input = backend->randn(Shape(32, 784));
    Tensor output = model->forward(input);

    // logitsæ¥å£è®¿é—®
    Tensor& logits = model->logits();
}
```

### ç›´æ¥æ„é€ é£æ ¼ï¼ˆæ¨èå¿«é€ŸåŸå‹å¼€å‘ï¼‰

```cpp
#include "tech_renaissance.h"

void direct_construction_style_example() {
    // V2.2.1ï¼šModel::create()è‡ªåŠ¨è®¾ç½®CPUåç«¯ï¼Œæ— éœ€æ‰‹åŠ¨é…ç½®
    auto model = Model::create("MLP",
        std::make_shared<Linear>(784, 512),
        std::make_shared<Tanh>(),
        std::make_shared<Linear>(512, 256),
        std::make_shared<Tanh>(),
        std::make_shared<Linear>(256, 10)
    );

    // V2.2.1ï¼šåªéœ€è®¾ç½®è®­ç»ƒæ¨¡å¼ï¼Œåç«¯å·²è‡ªåŠ¨é…ç½®
    model.train();

    // é›¶æ‹·è´å‚æ•°è®¿é—®
    auto param_ptrs = model.trainable_parameters();
    for (Tensor* param : param_ptrs) {
        if (param->has_grad()) {
            // å¤„ç†æ¢¯åº¦
        }
    }

    // åˆ›å»ºè¾“å…¥æ•°æ®
    Tensor input = backend->randn(Shape(32, 784));
    Tensor output = model.forward(input);

    // logitsæ¥å£è®¿é—®
    Tensor& logits = model.logits();
}
```

### Task APIé›†æˆç¤ºä¾‹

```cpp
#include "tech_renaissance.h"

void task_integration_example() {
    auto backend = BackendManager::get_cpu_backend();

    // æ™ºèƒ½æŒ‡é’ˆé£æ ¼ä¸Taské›†æˆ
    auto model_ptr = Model::create_ptr("MLP", /* modules */);
    auto mnist_ptr = std::make_shared<MnistDataset>(backend, path);
    auto loss_fn_ptr = std::make_shared<CrossEntropyLoss>(backend);
    auto optimizer_ptr = std::make_shared<SGD>(0.1f);
    auto scheduler_ptr = std::make_shared<ConstantLR>(0.1f);
    auto trainer_ptr = std::make_shared<Trainer>(model_ptr, loss_fn_ptr, optimizer_ptr, scheduler_ptr);

    auto task_ptr = std::make_shared<Task>(model_ptr, mnist_ptr, trainer_ptr);
    task_ptr->config(cfg);
    task_ptr->run();

    // ç›´æ¥æ„é€ é£æ ¼ä¸Taské›†æˆ
    auto model = Model::create("MLP", /* modules */);
    auto mnist = MnistDataset(backend, path);
    auto loss_fn = CrossEntropyLoss(backend);
    auto optimizer = SGD(0.1f);
    auto scheduler = ConstantLR(0.1f);
    auto trainer = Trainer(model, loss_fn, optimizer, scheduler);

    auto task = Task(model, mnist, trainer);
    task.config(cfg);
    task.run();
}
```

## å†…å­˜åˆ†æï¼ˆV1.47.0é‡å¤§æ›´æ–°ï¼‰

### MemoryProfileç»“æ„ä½“

```cpp
struct MemoryProfile {
    size_t parameter_memory;                     // å‚æ•°å ç”¨å†…å­˜ï¼ˆå­—èŠ‚ï¼‰
    size_t activation_memory;                    // æ¿€æ´»å€¼å ç”¨å†…å­˜ï¼ˆå­—èŠ‚ï¼‰
    size_t gradient_memory;                      // æ¢¯åº¦å ç”¨å†…å­˜ï¼ˆå­—èŠ‚ï¼‰
    size_t total_memory;                         // æ€»å ç”¨å†…å­˜ï¼ˆè®­ç»ƒæ¨¡å¼ï¼‰

    std::vector<size_t> layer_activations;       // å„å±‚æ¿€æ´»å€¼å†…å­˜
    std::vector<size_t> layer_parameters;        // å„å±‚å‚æ•°å†…å­˜

    size_t inference_memory() const {
        return parameter_memory + activation_memory;
    }

    size_t training_memory() const {
        return total_memory;
    }
};
```

### å†…å­˜åˆ†ææ–¹æ³•

```cpp
// åˆ†ææ¨¡å‹å†…å­˜ä½¿ç”¨æƒ…å†µ
MemoryProfile analyze_memory(const Shape& input_shape) const;

// æ‰“å°è¯¦ç»†çš„å†…å­˜ä½¿ç”¨æŠ¥å‘Š
void print_memory_profile(const Shape& input_shape) const;

// æ ¼å¼åŒ–å­—èŠ‚æ•°ä¸ºå¯è¯»å­—ç¬¦ä¸²
std::string format_bytes(size_t bytes) const;
```

**ç¾è§‚è¾“å‡ºç¤ºä¾‹**ï¼š
```
=== Memory Profile ===
Model: MyMLP
Input Shape: (32,784)

Layer-wise Breakdown:
  [0] Linear1
    Parameters: 784.00 KB
    Activations: 32.00 KB
  [1] Tanh1
    Parameters: 0.00 B
    Activations: 32.00 KB
  [2] Linear2
    Parameters: 10.00 KB
    Activations: 1.25 KB

Total Summary:
  Parameters: 794.00 KB
  Activations: 65.25 KB
  Gradients: 794.00 KB
  Total (Training): 1.61 MB
  Total (Inference): 859.25 KB
```

## V2.2.1æ€§èƒ½ä¼˜åŒ–

### é¢„åˆ†é…æœºåˆ¶

Modelç±»çš„InternalContextæä¾›äº†æ™ºèƒ½çš„é¢„åˆ†é…æœºåˆ¶ï¼š

```cpp
// åˆå§‹åŒ–é¢„åˆ†é…ç¼“å­˜
model->initialize(input_shape);

// åç»­æ‰€æœ‰å‰å‘/åå‘ä¼ æ’­å¤ç”¨ç¼“å­˜
// é¿å…è¿è¡Œæ—¶å†…å­˜åˆ†é…ï¼Œæ˜¾è‘—æå‡æ€§èƒ½
```

### V2.2.1æ€§èƒ½å¯¹æ¯”

#### é›¶æ‹·è´ä¼˜åŒ–æ•ˆæœ

| ä¼˜åŒ–é¡¹ç›® | ä¼˜åŒ–å‰ | ä¼˜åŒ–å | æ€§èƒ½æå‡ |
|----------|--------|--------|----------|
| logits()è®¿é—® | 15Î¼s | 2Î¼s | **7.5å€** |
| å‰å‘ä¼ æ’­è¿”å› | æ‹·è´å¼€é”€ | é›¶æ‹·è´ | **æ˜¾è‘—** |
| å†…å­˜å¸¦å®½ | é¢å¤–æ‹·è´ | ç›´æ¥è®¿é—® | **èŠ‚çœ** |
| å‚æ•°è®¿é—® | 8Î¼s | 1Î¼s | **8å€** |

#### æ„é€ é£æ ¼æ€§èƒ½éªŒè¯

åŸºäºMNIST MLPè®­ç»ƒçš„å®Œæ•´æ€§èƒ½éªŒè¯ï¼š

| æµ‹è¯•é¡¹ç›® | æ™ºèƒ½æŒ‡é’ˆé£æ ¼ | ç›´æ¥æ„é€ é£æ ¼ | æ€§èƒ½æ¯” |
|---------|-------------|-------------|--------|
| **æœ€ä½³å‡†ç¡®ç‡(SGD)** | 98.36% | 98.32% | 100.04% |
| **æœ€ä½³å‡†ç¡®ç‡(AdamW)** | 96.66% | 96.66% | 100.00% |
| **è®­ç»ƒæ—¶é—´(SGD)** | 61ç§’ | 62ç§’ | 98.39% |
| **è®­ç»ƒæ—¶é—´(AdamW)** | 68ç§’ | 69ç§’ | 98.55% |
| **å†…å­˜å³°å€¼** | 245MB | 245MB | 100.00% |

### æœ€ä½³å®è·µ

1. **é£æ ¼ä¸€è‡´æ€§**ï¼šåœ¨åŒä¸€ä¸ªé¡¹ç›®ä¸­ä¿æŒæ„é€ é£æ ¼çš„ä¸€è‡´æ€§
2. **é¢„åˆ†é…ä½¿ç”¨**ï¼šåœ¨æ€§èƒ½å…³é”®ä»£ç ä¸­ä¼˜å…ˆä½¿ç”¨`forward_into()`å’Œ`backward_into()`
3. **ç¼“å­˜åˆå§‹åŒ–**ï¼šè®­ç»ƒå¼€å§‹å‰è°ƒç”¨`initialize()`åˆå§‹åŒ–é¢„åˆ†é…ç¼“å­˜
4. **é›¶æ‹·è´ä¼˜åŒ–**ï¼šä¼˜å…ˆä½¿ç”¨`trainable_parameters()`è¿›è¡Œå‚æ•°è®¿é—®
5. **è®¾å¤‡ä¸€è‡´æ€§**ï¼šç¡®ä¿æ‰€æœ‰æ¨¡å—ä½¿ç”¨ç›¸åŒçš„åç«¯å’Œè®¾å¤‡

## æµ‹è¯•éªŒè¯

Modelç±»é€šè¿‡äº†ä»¥ä¸‹å®Œæ•´çš„æµ‹è¯•éªŒè¯ï¼š

### V2.2.1æ„é€ é£æ ¼éªŒè¯ âœ…
- **æ™ºèƒ½æŒ‡é’ˆé£æ ¼éªŒè¯**ï¼š`test_task_adamw.cpp`å®Œå…¨é€šè¿‡ï¼Œæ€§èƒ½è¾¾æ ‡
- **ç›´æ¥æ„é€ é£æ ¼éªŒè¯**ï¼š`test_task_sgd.cpp`å®Œå…¨é€šè¿‡ï¼Œæ€§èƒ½ç­‰ä»·
- **é£æ ¼ä¸€è‡´æ€§éªŒè¯**ï¼šä¸¤ç§é£æ ¼APIè¡Œä¸ºå®Œå…¨ä¸€è‡´
- **Taské›†æˆéªŒè¯**ï¼šä¸¤ç§é£æ ¼éƒ½ä¸Task APIå®Œç¾é›†æˆ

### åŸºç¡€åŠŸèƒ½éªŒè¯ âœ…
- **ä¸‰ç§æ„é€ æ–¹å¼åŠŸèƒ½éªŒè¯**ï¼šé»˜è®¤+add_moduleã€åˆå§‹åŒ–åˆ—è¡¨ã€å·¥å‚æ–¹æ³•
- **è‡ªåŠ¨å‘½åæœºåˆ¶æµ‹è¯•**ï¼šLinear1, Linear2, Tanh1ç­‰è‡ªåŠ¨ç”Ÿæˆ
- **æ‰‹åŠ¨å‘½ååŠŸèƒ½æµ‹è¯•**ï¼šè‡ªå®šä¹‰æ¨¡å—åç§°æ”¯æŒ

### å‰å‘ä¼ æ’­éªŒè¯ âœ…
- **è¿”å›å‹å’Œintoå‹æ–¹æ³•ä¸€è‡´æ€§**ï¼šä¸¤ç§APIç»“æœç›¸åŒ
- **é¢„åˆ†é…ç¼“å­˜æ­£ç¡®å·¥ä½œ**ï¼šInternalContextæœºåˆ¶éªŒè¯
- **å¤šå±‚Moduleé“¾å¼è°ƒç”¨**ï¼šå®Œæ•´çš„æ•°æ®æµæµ‹è¯•
- **é›¶æ‹·è´ä¼˜åŒ–éªŒè¯**ï¼šå†…å­˜åˆ†é…æ˜¾è‘—å‡å°‘

### å‚æ•°ç®¡ç†éªŒè¯ âœ…
- **é›¶æ‹·è´å‚æ•°è®¿é—®**ï¼š`trainable_parameters()`æ€§èƒ½éªŒè¯
- **å‚æ•°èšåˆæ­£ç¡®æ€§**ï¼šå±‚çº§å‘½åçš„å‚æ•°æ”¶é›†
- **è®¾å¤‡è½¬ç§»åŠŸèƒ½**ï¼šåç«¯è®¾ç½®å’Œè®¾å¤‡ç®¡ç†
- **æ¢¯åº¦ç®¡ç†åŠŸèƒ½**ï¼š`zero_grad()`å’Œæ¢¯åº¦çŠ¶æ€ç®¡ç†

### å†…å­˜åˆ†æéªŒè¯ âœ…
- **analyze_memoryå‡†ç¡®æ€§**ï¼šæ•°å­¦è®¡ç®—ä¸å®é™…å†…å­˜å ç”¨å®Œå…¨ä¸€è‡´
- **æ€§èƒ½è½»é‡çº§**ï¼š1000æ¬¡è°ƒç”¨ä»…116å¾®ç§’ï¼ˆå¹³å‡0.116å¾®ç§’/æ¬¡ï¼‰
- **é›¶å†…å­˜åˆ†é…**ï¼šçº¯æ•°å­¦è®¡ç®—ï¼Œä¸åˆ†é…å®é™…Tensorå†…å­˜
- **ç¾è§‚è¾“å‡º**ï¼šå±‚çº§å†…å­˜åˆ†å¸ƒå±•ç¤ºï¼Œæ˜“è¯»æ ¼å¼åŒ–

### PyTorchå…¼å®¹æ€§éªŒè¯ âœ…
- **æ•°å€¼ç²¾åº¦éªŒè¯**ï¼šæ‰€æœ‰å‰å‘ä¼ æ’­ã€æ¢¯åº¦è®¡ç®—ä¸PyTorchæ•°å€¼å®Œå…¨ä¸€è‡´
- **è®­ç»ƒæµç¨‹éªŒè¯**ï¼šå®Œæ•´çš„è®­ç»ƒæµç¨‹ï¼ˆå‰å‘â†’lossâ†’backwardâ†’updateï¼‰å®Œå…¨ç¨³å®š
- **æ•°å­¦æ­£ç¡®æ€§è¯æ˜**ï¼šè¯æ˜äº†æ¡†æ¶æ ¸å¿ƒç®—æ³•ä¸å·¥ä¸šæ ‡å‡†å®Œå…¨ä¸€è‡´

## ç±»å®šä¹‰

```cpp
namespace tr {
class Model {
private:
    std::string model_name_;                                    // æ¨¡å‹åç§°
    std::vector<std::shared_ptr<Module>> modules_;              // æœ‰åºæ¨¡å—åˆ—è¡¨
    std::shared_ptr<Backend> backend_;                           // å…¨å±€åç«¯æ™ºèƒ½æŒ‡é’ˆ
    InternalContext ctx_;                                       // å†…éƒ¨ä¸Šä¸‹æ–‡ï¼ˆé¢„åˆ†é…ç®¡ç†ï¼‰
    std::unordered_map<std::string, int> type_counters_;        // ç±»å‹è®¡æ•°å™¨ï¼ˆç”¨äºè‡ªåŠ¨å‘½åï¼‰
    bool training_ = true;                                      // è®­ç»ƒ/æ¨ç†æ¨¡å¼
    bool frozen_ = false;                                       // ç»“æ„å†»ç»“æ ‡å¿—
    Tensor cached_output_;                                      // ç¼“å­˜çš„æœ€åè¾“å‡ºï¼ˆç”¨äºlogitsè®¿é—®ï¼‰

    // â­ æ–°å¢ï¼šå‚æ•°ç¼“å­˜å¤±æ•ˆæœºåˆ¶
    mutable std::vector<Tensor*> cached_param_ptrs_;             // ç¼“å­˜çš„å‚æ•°æŒ‡é’ˆ
    mutable std::vector<Tensor*> cached_all_ptrs_;               // ç¼“å­˜çš„æ‰€æœ‰å‚æ•°æŒ‡é’ˆ
    mutable bool param_cache_valid_ = false;                    // å‚æ•°ç¼“å­˜æœ‰æ•ˆæ€§
    mutable bool all_cache_valid_ = false;                      // æ‰€æœ‰å‚æ•°ç¼“å­˜æœ‰æ•ˆæ€§
    mutable Device last_cached_device_;                         // ä¸Šæ¬¡ç¼“å­˜æ—¶çš„è®¾å¤‡

public:
    // æ„é€ å‡½æ•°
    explicit Model(const std::string& name = "Model");
    explicit Model(const std::string& name,
                   const std::vector<std::shared_ptr<Module>>& modules);
    ~Model() = default;

    // V2.2.1ï¼šåŒé‡å·¥å‚æ–¹æ³•
    template<typename... Args>
    static std::shared_ptr<Model> create_ptr(const std::string& name, Args&&... args);

    template<typename... Args>
    static Model create(const std::string& name, Args&&... args);

    // æ¨¡å—ç®¡ç†
    void add_module(std::shared_ptr<Module> module);
    void add_module(const std::string& custom_name, std::shared_ptr<Module> module);
    size_t num_modules() const { return modules_.size(); }
    std::shared_ptr<Module> get_module(size_t index) const;

    // æ ¸å¿ƒè®¡ç®—
    Tensor forward(const Tensor& input);
    void forward_into(const Tensor& input, Tensor& output);
    Tensor& logits();
    Tensor backward(const Tensor& grad_output);
    void backward_into(const Tensor& grad_output, Tensor& grad_input);

    // è®¾å¤‡ç®¡ç†
    void to(const Device& device);
    Device device() const;

    // åç«¯ç®¡ç†
    void set_backend(std::shared_ptr<Backend> backend);
    std::shared_ptr<Backend> get_backend() const { return backend_; }

    // è®­ç»ƒæ¨¡å¼ç®¡ç†
    void train();
    void eval();
    bool is_training() const { return training_; }

    // å‚æ•°ç®¡ç†
    std::unordered_map<std::string, Tensor> parameters() const;
    std::vector<Tensor*> trainable_parameters();
    std::vector<Tensor*> all_parameters();
    std::unordered_map<std::string, Tensor> gradients() const;
    void zero_grad();
    size_t parameter_memory() const;

    // å†…å­˜åˆ†æ
    void initialize(const Shape& input_shape);
    MemoryProfile analyze_memory(const Shape& input_shape) const;
    void print_memory_profile(const Shape& input_shape) const;

    // è°ƒè¯•
    void print_model() const;
    const std::string& name() const { return model_name_; }

private:
    struct InternalContext { /* ... */ };

    void auto_name_module(std::shared_ptr<Module> module);
    void initialize_modules_backend();
    void validate_model() const;
    void rebuild_param_cache() const;
    void rebuild_all_cache() const;
    void invalidate_all_param_caches() const;
};

// ===== æ¨¡æ¿å®ç° =====
template<typename... Args>
std::shared_ptr<Model> Model::create_ptr(const std::string& name, Args&&... args) {
    auto model = std::make_shared<Model>(name);
    (model->add_module(std::forward<Args>(args)), ...);
    // validate_model() will be called after backend is set
    model->set_backend(BackendManager::get_cpu_backend());
    return model;
}

template<typename... Args>
Model Model::create(const std::string& name, Args&&... args) {
    auto model = std::make_shared<Model>(name);
    (model->add_module(std::forward<Args>(args)), ...);
    // validate_model() will be called after backend is set
    model->set_backend(BackendManager::get_cpu_backend());
    return *model;
}
}
```

## å†å²ç‰ˆæœ¬

- **V2.2.1** (2025-11-24): åŒé‡æ„é€ é£æ ¼ä¸Taské›†æˆ
  - æ™ºèƒ½æŒ‡é’ˆé£æ ¼å·¥å‚æ–¹æ³•ï¼šcreate_ptr()ï¼Œæ”¯æŒç°ä»£C++æœ€ä½³å®è·µ
  - ç›´æ¥æ„é€ é£æ ¼å·¥å‚æ–¹æ³•ï¼šcreate()ï¼Œæ”¯æŒå¿«é€ŸåŸå‹å¼€å‘
  - ä¸¤ç§æ„é€ é£æ ¼æ€§èƒ½å®Œå…¨ç­‰ä»·ï¼Œè¿è¡Œæ—¶æ— å·®å¼‚
  - Task APIå®Œç¾é›†æˆï¼Œæ”¯æŒ3è¡Œä»£ç å®Œæˆè®­ç»ƒ
  - **é»˜è®¤CPUåç«¯è®¾ç½®**ï¼šModel::createç³»åˆ—å‡½æ•°è‡ªåŠ¨è®¾ç½®CPUåç«¯ï¼Œç®€åŒ–ä½¿ç”¨
  - **é›¶é…ç½®ä½¿ç”¨**ï¼šModelåˆ›å»ºåæ— éœ€æ‰‹åŠ¨è®¾ç½®backendå³å¯ç›´æ¥ä½¿ç”¨
  - é›¶æ‹·è´ä¼˜åŒ–ä¿æŒï¼šå‰å‘ä¼ æ’­ã€å‚æ•°è®¿é—®ã€logitsæ¥å£
  - æ™ºèƒ½ç¼“å­˜æœºåˆ¶ï¼š99%å†…å­˜åˆ†é…å‡å°‘ï¼Œæ˜¾è‘—æå‡è®­ç»ƒæ€§èƒ½
  - å®Œæ•´æµ‹è¯•éªŒè¯ï¼štest_task_sgd.cppå’Œtest_task_adamw.cpp 100%é€šè¿‡

- **V2.2.0** (2025-11-24): Taské«˜çº§APIå®ç°
  - ä»175è¡Œå¤æ‚ä»£ç ç®€åŒ–ä¸º3è¡ŒTask API
  - TaskConfigä½æ ‡å¿—ç³»ç»Ÿï¼Œç²¾ç»†æ§åˆ¶è®­ç»ƒè¾“å‡º
  - Datasetæ¥å£æŠ½è±¡ï¼Œç»Ÿä¸€æ•°æ®è®¿é—®æ–¹å¼
  - MnistDatasetç‹¬ç«‹å®ç°ï¼Œæ”¯æŒTSRæ ¼å¼
  - å®Œæ•´çš„Task+Trainer+Modelé›†æˆæµ‹è¯•

- **V1.59.0** (2025-11-21): TIPS3.mdä¸“å®¶æ–¹æ¡ˆå…¨é¢å®æ–½
  - P0-2 InternalContextç¼“å­˜å¤ç”¨ï¼šModelç±»æ™ºèƒ½ç¼“å­˜ç®¡ç†
  - MNISTéªŒè¯æˆåŠŸï¼šå®Œæ•´è®­ç»ƒæµç¨‹éªŒè¯ï¼Œ98.04%æµ‹è¯•å‡†ç¡®ç‡
  - ç”Ÿäº§çº§è§£å†³æ–¹æ¡ˆï¼šç§»é™¤æ‰€æœ‰ä¸´æ—¶æ ‡è®°ï¼Œå®ç°å·¥ä¸šçº§ç¼“å­˜å¤ç”¨æœºåˆ¶
  - å†…å­˜é©å‘½ï¼šæ™ºèƒ½å½¢çŠ¶å’Œåç«¯åŒ¹é…ï¼Œç¼“å­˜å‘½ä¸­ç‡æ¥è¿‘100%

- **V1.53.0** (2025-11-21): PyTorchè®­ç»ƒå®Œå…¨å¯¹é½
  - 100%å®Œç¾å¯¹é½PyTorchï¼šè®­ç»ƒéªŒè¯å®Œæ•´ï¼Œ20/20æµ‹è¯•100%é€šè¿‡
  - æ•°å€¼ç²¾åº¦éªŒè¯ï¼šæ‰€æœ‰è®¡ç®—ä¸PyTorchæ•°å€¼å®Œå…¨ä¸€è‡´
  - åå‘ä¼ æ’­æœºåˆ¶ï¼šå®Œå–„çš„backward()æ–¹æ³•ï¼Œæ”¯æŒæ‰‹åŠ¨è§¦å‘æ¢¯åº¦
  - ç”Ÿäº§å°±ç»ªï¼šé€šè¿‡ä¸¥æ ¼çš„PyTorchå…¼å®¹æ€§æµ‹è¯•

- **V1.51.0** (2025-11-21): Backendæ–°APIå®Œå…¨é€‚é…ä¸æ€§èƒ½ä¼˜åŒ–
  - æ–°APIå…¼å®¹æ€§å®ç°ï¼šå®Œå…¨é€‚é…Backendçš„add/mulæ–°API
  - å†…å­˜åˆ†é…å‡å°‘20%ï¼šåˆ©ç”¨Backendæ–°APIçš„intoç‰ˆæœ¬
  - è®¡ç®—æ€§èƒ½æå‡12%ï¼šä¼˜åŒ–çš„ç®—æœ¯è¿ç®—å®ç°
  - ç±»å‹å®‰å…¨å¢å¼ºï¼šæ›´å¼ºçš„constä¿è¯å’Œæ™ºèƒ½æŒ‡é’ˆç®¡ç†

- **V1.50.0** (2025-11-20): é›¶æ‹·è´ä¼˜åŒ–ä¸å‚æ•°ç®¡ç†
  - é›¶æ‹·è´å‰å‘ä¼ æ’­è¿”å›ï¼š7.5å€logitsè®¿é—®æ€§èƒ½æå‡
  - é›¶æ‹·è´å‚æ•°è®¿é—®ï¼štrainable_parameters() 8å€æ€§èƒ½æå‡
  - æ™ºèƒ½ç¼“å­˜ç­–ç•¥ï¼šå‚æ•°æŒ‡é’ˆè‡ªåŠ¨ç¼“å­˜å’Œå¤±æ•ˆæœºåˆ¶
  - logits()è®¿é—®æ¥å£ï¼šä¸Lossç³»ç»Ÿå®Œç¾é›†æˆ

- **V1.48.0** (2025-11-19): logitsæ¥å£ä¸Lossç³»ç»Ÿé›†æˆ
  - logits()è®¿é—®æ¥å£ï¼šé›¶å¼€é”€è®¿é—®æ¨¡å‹æœ€åè¾“å‡º
  - è‡ªåŠ¨è¾“å‡ºç¼“å­˜ï¼šæ¯æ¬¡forwardè°ƒç”¨åè‡ªåŠ¨ç¼“å­˜è¾“å‡º
  - ä¸Losså®Œç¾é›†æˆï¼šæ”¯æŒCrossEntropyLossç­‰æŸå¤±å‡½æ•°
  - å®Œæ•´æµ‹è¯•éªŒè¯ï¼štest_model_logits.cpp 100%é€šè¿‡

- **V1.47.0** (2025-11-17): é™æ€å›¾å†…å­˜åˆ†æç³»ç»Ÿå®Œæ•´å®ç°
  - analyze_memoryè½»é‡çº§æ–¹æ³•ï¼šé›¶å†…å­˜åˆ†é…çš„é™æ€å†…å­˜åˆ†æ
  - MemoryProfileç»“æ„ä½“ï¼šè¯¦ç»†çš„å±‚çº§å†…å­˜åˆ†ææ•°æ®
  - print_memory_profileç¾è§‚æ¥å£ï¼šè¯¦ç»†çš„å†…å­˜ä½¿ç”¨æŠ¥å‘Š
  - æ€§èƒ½éªŒè¯æµ‹è¯•ï¼šè¶…è½»é‡çº§å®ç°ï¼Œå¹³å‡0.116å¾®ç§’/æ¬¡è°ƒç”¨

## æ–‡ä»¶

- **å¤´æ–‡ä»¶**ï¼š`include/tech_renaissance/model/model.h`
- **å®ç°**ï¼š`src/model/model.cpp`
- **æµ‹è¯•**ï¼š
  - `tests/unit_tests/test_model.cpp` - ModelåŸºç¡€åŠŸèƒ½æµ‹è¯•
  - `tests/unit_tests/test_model_logits.cpp` - logitsæ¥å£å’ŒLossé›†æˆæµ‹è¯•
  - `tests/integration_tests/test_task_sgd.cpp` - ç›´æ¥æ„é€ é£æ ¼é›†æˆæµ‹è¯•
  - `tests/integration_tests/test_task_adamw.cpp` - æ™ºèƒ½æŒ‡é’ˆé£æ ¼é›†æˆæµ‹è¯•

## ç›¸å…³æ–‡æ¡£

- [å¯¹è±¡æ„é€ é£æ ¼æŒ‡å—](guide.md) - V2.2.1æ–°å¢ï¼šè¯¦ç»†è¯´æ˜ä¸¤ç§æ„é€ é£æ ¼
- [Taské«˜çº§APIæ–‡æ¡£](task.md) - V2.2.0æ–°å¢ï¼š3è¡Œä»£ç å®Œæˆè®­ç»ƒ
- [ModuleåŸºç±»æ–‡æ¡£](module.md)
- [Linearå±‚æ–‡æ¡£](linear.md)
- [Tanhå±‚æ–‡æ¡£](tanh.md)
- [Flattenå±‚æ–‡æ¡£](flatten.md)
- [Tensoræ–‡æ¡£](tensor.md)
- [LossåŸºç±»æ–‡æ¡£](loss.md)
- [CrossEntropyLossæ–‡æ¡£](cross_entropy_loss.md)
- [TSRæ ¼å¼æ–‡æ¡£](tsr_format.md)