# CudaBackend API æ–‡æ¡£

## ç‰ˆæœ¬ä¿¡æ¯

- **ç‰ˆæœ¬**: V1.51.0
- **æ—¥æœŸ**: 2025å¹´11æœˆ19æ—¥
- **ä½œè€…**: æŠ€æœ¯è§‰é†’å›¢é˜Ÿ
- **æ‰€å±ç³»åˆ—**: backend

## æœ€æ–°å®ŒæˆçŠ¶æ€

âœ… **V1.51.0å®Œæˆ - æ–°APIå®ç°ä¸cuBLAS/cuDNNä¼˜åŒ–**:
- æ–°å¢add/mul APIå®ç° - åŸºäºcuBLAS/cuDNNçš„é«˜æ€§èƒ½å¼ é‡è¿ç®—
- consté‡è½½æ–¹æ³•å®Œå–„ - æ‰€æœ‰æ¥å£æ”¯æŒconstæ­£ç¡®æ€§
- è®¾å¤‡ä¸€è‡´æ€§éªŒè¯ - å®Œå–„çš„CUDAè®¾å¤‡æ£€æŸ¥å’Œé”™è¯¯å¤„ç†
- ä¸BackendåŸºç±»å®Œå…¨å¯¹é½çš„æ¥å£è®¾è®¡
- é«˜æ€§èƒ½ä¸´æ—¶ç¼“å†²åŒºç®¡ç†

âœ… **V1.46.3å®Œæˆ - æ„é€ å‡½æ•°è®¾è®¡å’Œä»£ç è§„èŒƒä¼˜åŒ–**:
- æ„é€ å‡½æ•°ç»Ÿä¸€åŒ– - ä½¿ç”¨`explicit CudaBackend(int device_id = 0)`ï¼Œé˜²æ­¢éšå¼è½¬æ¢
- BackendåŸºç±»é›†æˆ - æ­£ç¡®è°ƒç”¨`Backend(true)`æ„é€ å‡½æ•°
- å‚æ•°æ–‡æ¡£å®Œå–„ - æ·»åŠ device_idå‚æ•°è¯¦ç»†è¯´æ˜å’Œé»˜è®¤å€¼
- Alphaç¼–è¯‘éªŒè¯ - ç¼–è¯‘æµ‹è¯•é€šè¿‡ï¼Œæ— é”™è¯¯å’Œè­¦å‘Š
- ç±»å‹å®‰å…¨å¢å¼º - explicitå…³é”®å­—ç¡®ä¿æ„é€ å‡½æ•°æ˜ç¡®è°ƒç”¨

## æ¦‚è¿°

`CudaBackend`æ˜¯æŠ€æœ¯è§‰é†’æ¡†æ¶çš„GPUè®¡ç®—åç«¯å®ç°ï¼Œç»§æ‰¿è‡ª`Backend`åŸºç±»ã€‚å®ƒåŸºäºNVIDIA CUDAå¹³å°ï¼Œç»“åˆcuBLASå’ŒcuDNNåº“æä¾›é«˜æ€§èƒ½çš„GPUåŠ é€Ÿè®¡ç®—èƒ½åŠ›ï¼Œæ”¯æŒæ·±åº¦å­¦ä¹ å·¥ä½œè´Ÿè½½çš„å¤§è§„æ¨¡å¹¶è¡Œè®¡ç®—ã€‚

### ğŸ”§ V1.43.0æ„é€ å‡½æ•°ä¿®å¤è¯¦æƒ…

åœ¨V1.43.0ç‰ˆæœ¬ä¸­ï¼Œä¿®å¤äº†CUDAåç«¯æ„é€ å‡½æ•°çš„é‡è¦é—®é¢˜ï¼š

```cpp
// ä¿®å¤å‰ï¼ˆä¼šå¯¼è‡´Backendå®ä¾‹åŒ–é”™è¯¯ï¼‰
CudaBackend::CudaBackend(int device_id) : device_id_(device_id), ... {
    // åˆå§‹åŒ–ä»£ç 
}

// ä¿®å¤åï¼ˆæ­£ç¡®è°ƒç”¨Backendæ„é€ å‡½æ•°ï¼‰
CudaBackend::CudaBackend(int device_id) : Backend(true), device_id_(device_id), ... {
    // åˆå§‹åŒ–ä»£ç 
}
```

### âœ… é‡æ„å…¼å®¹æ€§

- **100%å‘åå…¼å®¹**ï¼šæ‰€æœ‰ç°æœ‰ä»£ç æ— éœ€ä¿®æ”¹å³å¯æ­£å¸¸å·¥ä½œ
- **å®ä¾‹åŒ–ä¿®å¤**ï¼šè§£å†³äº†"Backend class cannot be instantiated directly"é”™è¯¯
- **å¼‚å¸¸å¤„ç†**ï¼šå®Œå–„çš„é”™è¯¯æ£€æŸ¥å’Œå¼‚å¸¸å¤„ç†æœºåˆ¶
- **å®ç³»ç»Ÿæ”¯æŒ**ï¼šç»§æ‰¿BackendåŸºç±»çš„å®å®šä¹‰ç³»ç»Ÿ

## è®¾è®¡ç†å¿µ

### æ ¸å¿ƒè®¾è®¡åŸåˆ™

1. **åˆ—ä¸»åºå­˜å‚¨**ï¼šCUDAåç«¯ä½¿ç”¨**åˆ—ä¸»åºï¼ˆColumn-majorï¼‰**å­˜å‚¨å¼ é‡æ•°æ®ï¼Œä¸cuBLAS/cuDNNåº“æ¥å£ä¿æŒä¸€è‡´
2. **é«˜æ€§èƒ½è®¡ç®—**ï¼šåŸºäºcuBLASçš„ä¼˜åŒ–çŸ©é˜µè¿ç®—ï¼ŒGPUæ€§èƒ½æ¥è¿‘ç¡¬ä»¶æé™
3. **é€æ˜è½¬æ¢**ï¼šé€šè¿‡`from_cpu()`å’Œ`to_cpu()`æ–¹æ³•è‡ªåŠ¨å¤„ç†è¡Œä¸»åºä¸åˆ—ä¸»åºä¹‹é—´çš„æ ¼å¼è½¬æ¢
4. **å¼‚æ­¥è®¡ç®—**ï¼šä½¿ç”¨CUDAæµå®ç°å¼‚æ­¥æ“ä½œï¼Œæé«˜å¹¶å‘æ€§èƒ½
5. **RAIIç®¡ç†**ï¼šæ™ºèƒ½æŒ‡é’ˆè‡ªåŠ¨å†…å­˜ç®¡ç†ï¼Œé˜²æ­¢GPUå†…å­˜æ³„æ¼
6. **ğŸ†• å®é©±åŠ¨æ‰©å±•**ï¼šé€šè¿‡V1.43.0çš„å®ç³»ç»Ÿæ”¯æŒå¿«é€Ÿå®ç°æ–°æ–¹æ³•

### å…³é”®æ¶æ„ç‰¹æ€§

#### **åç«¯ç®¡ç†å­˜å‚¨åŸåˆ™ï¼ˆæ ¸å¿ƒç‰¹æ€§ï¼‰**

CUDAåç«¯éµå¾ª"åç«¯ç®¡ç†å­˜å‚¨"çš„è®¾è®¡åŸåˆ™ï¼š
- **CPUåç«¯**ï¼šä½¿ç”¨è¡Œä¸»åºï¼ˆRow-majorï¼‰å­˜å‚¨å¼ é‡æ•°æ®
- **CUDAåç«¯**ï¼šä½¿ç”¨åˆ—ä¸»åºï¼ˆColumn-majorï¼‰å­˜å‚¨å¼ é‡æ•°æ®
- **è½¬æ¢å±‚é€æ˜**ï¼šç”¨æˆ·æ— éœ€å…³å¿ƒåº•å±‚å­˜å‚¨æ ¼å¼ï¼Œ`from_cpu()`å’Œ`to_cpu()`è‡ªåŠ¨å¤„ç†è½¬æ¢

#### **å†…å­˜å¸ƒå±€è½¬æ¢å±‚**

```cpp
// CPU â†’ CUDA è½¬æ¢ï¼šè¡Œä¸»åº â†’ åˆ—ä¸»åº
Tensor CudaBackend::from_cpu(const Tensor& tensor) {
    // 1. åˆ›å»ºCUDA Storageï¼ˆåˆ—ä¸»åºå­˜å‚¨ï¼‰
    Tensor cuda_tensor = Tensor::empty(tensor.shape(), tensor.dtype(), tr::CUDA[device_id_]);

    // 2. å¯¹äº2DçŸ©é˜µï¼Œæ‰§è¡Œå†…å­˜å¸ƒå±€è½¬æ¢
    if (tensor.shape().ndim() == 2) {
        int32_t M = tensor.shape().height();  // è¡Œæ•°
        int32_t N = tensor.shape().width();   // åˆ—æ•°

        const float* cpu_data = static_cast<const float*>(tensor.data_ptr());
        float* cuda_data = static_cast<float*>(cuda_tensor.data_ptr());

        // è¡Œä¸»åº â†’ åˆ—ä¸»åºè½¬æ¢
        for (int32_t i = 0; i < M; ++i) {
            for (int32_t j = 0; j < N; ++j) {
                cuda_data[j * M + i] = cpu_data[i * N + j];
            }
        }
    } else {
        // é2Då¼ é‡ç›´æ¥å¤åˆ¶
        copy_data(cuda_tensor.data_ptr(), tensor.data_ptr(),
             tensor.memory_size(), tr::CUDA[device_id_], tr::CPU);
    }

    return cuda_tensor;
}

// CUDA â†’ CPU è½¬æ¢ï¼šåˆ—ä¸»åº â†’ è¡Œä¸»åº
Tensor CudaBackend::to_cpu(const Tensor& tensor) {
    // 1. åˆ›å»ºCPU Storageï¼ˆè¡Œä¸»åºå­˜å‚¨ï¼‰
    Tensor cpu_tensor = Tensor::empty(tensor.shape(), tensor.dtype(), tr::CPU);

    // 2. å¯¹äº2DçŸ©é˜µï¼Œæ‰§è¡Œå†…å­˜å¸ƒå±€è½¬æ¢
    if (tensor.shape().ndim() == 2) {
        int32_t M = tensor.shape().height();  // è¡Œæ•°
        int32_t N = tensor.shape().width();   // åˆ—æ•°

        const float* cuda_data = static_cast<const float*>(tensor.data_ptr());
        float* cpu_data = static_cast<float*>(cpu_tensor.data_ptr());

        // åˆ—ä¸»åº â†’ è¡Œä¸»åºè½¬æ¢
        for (int32_t i = 0; i < M; ++i) {
            for (int32_t j = 0; j < N; ++j) {
                cpu_data[i * N + j] = cuda_data[j * M + i];
            }
        }
    } else {
        // é2Då¼ é‡ç›´æ¥å¤åˆ¶
        copy_data(cpu_tensor.data_ptr(), tensor.data_ptr(),
             tensor.memory_size(), tr::CPU, tensor.device());
    }

    return cpu_tensor;
}
```

## å¤´æ–‡ä»¶

```cpp
#include "tech_renaissance/backend/cuda_backend.h"
```

## ç¼–è¯‘è¦æ±‚

- **CUDA Toolkit**ï¼š12.0æˆ–æ›´é«˜ç‰ˆæœ¬
- **cuBLAS**ï¼šCUDAåŸºç¡€çº¿æ€§ä»£æ•°å­ç¨‹åºåº“
- **cuDNN**ï¼šCUDAæ·±åº¦ç¥ç»ç½‘ç»œåº“
- **å…¼å®¹GPU**ï¼šæ”¯æŒCUDAçš„NVIDIA GPU

## æ„é€ å‡½æ•°

```cpp
explicit CudaBackend(int device_id = 0);
```

**å‚æ•°**ï¼š
- `device_id` - GPUè®¾å¤‡IDï¼ˆå¯é€‰ï¼Œé»˜è®¤0ï¼‰

**ç‰¹æ€§**ï¼š
- è‡ªåŠ¨åˆå§‹åŒ–CUDAä¸Šä¸‹æ–‡
- åˆ›å»ºCUDAæµå’ŒcuBLAS/cuDNNå¥æŸ„
- è°ƒç”¨`Backend(true)`ç¡®ä¿æ­£ç¡®åˆå§‹åŒ–

**ç¤ºä¾‹**ï¼š
```cpp
// ä½¿ç”¨é»˜è®¤GPUï¼ˆè®¾å¤‡0ï¼‰
auto cuda_backend = std::make_shared<CudaBackend>();

// æŒ‡å®šGPUè®¾å¤‡
auto cuda_backend = std::make_shared<CudaBackend>(1);  // ä½¿ç”¨è®¾å¤‡1
```

## ğŸ†• V1.43.0æ–°å¢æ¥å£è¯´æ˜

### NotImplementedErrorå¤„ç†

åœ¨V1.43.0ä¸­ï¼ŒCUDAåç«¯ç»§æ‰¿äº†BackendåŸºç±»çš„å®å®šä¹‰ç³»ç»Ÿã€‚æœªå®ç°çš„æ–¹æ³•ä¼šæŠ›å‡ºç»Ÿä¸€æ ¼å¼çš„å¼‚å¸¸ï¼š

```
[CudaBackend method_name] Operation NOT implemented!
```

### ğŸ†• V1.44.1æ–°å¢çš„æ–¹æ³•

ä»¥ä¸‹æ–¹æ³•åœ¨V1.44.1ç‰ˆæœ¬ä¸­å·²å®ç°ï¼š

#### è§†å›¾æ“ä½œ
```cpp
Tensor view(const Tensor& input, const Shape& new_shape) override;
```
**ç‰¹æ€§**:
- GPUè®¾å¤‡ä¸Šçš„é›¶æ‹·è´å¼ é‡å˜æ¢
- ä¸CPUåç«¯ä¿æŒä¸€è‡´çš„æ¥å£å’Œè¡Œä¸º
- é«˜æ•ˆçš„CUDAå†…å­˜ç®¡ç†
- æ”¯æŒå¤§å°ºå¯¸å¼ é‡çš„å¿«é€Ÿå½¢çŠ¶é‡è§£é‡Š

#### å½¢çŠ¶å˜æ¢æ“ä½œ
```cpp
Tensor reshape(const Tensor& tensor_a, const Shape& shape) override;
void reshape_inplace(Tensor& tensor_a, const Shape& shape) override;
void reshape_into(const Tensor& tensor_a, Tensor& result, const Shape& shape) override;
```

#### åŒæ›²å‡½æ•°æ“ä½œ
```cpp
Tensor tanh(const Tensor& tensor_a) override;
void tanh_inplace(Tensor& tensor_a) override;
void tanh_into(const Tensor& tensor_a, Tensor& result) override;
Tensor dtanh(const Tensor& tensor_a) override;
void dtanh_inplace(Tensor& tensor_a) override;
void dtanh_into(const Tensor& tensor_a, Tensor& result) override;
```

#### æŸå¤±å‡½æ•°æ“ä½œ
```cpp
float crossentropy(const Tensor& pred, const Tensor& label, std::string reduction) override;
```

#### One-hotç¼–ç æ“ä½œ
```cpp
Tensor one_hot(const Tensor& label, int32_t num_classes, float label_smoothing) override;
void one_hot_into(const Tensor& label, Tensor& result, int32_t num_classes, float label_smoothing) override;
```

#### æ ‡é‡è¿ç®—å’Œå¹¿æ’­è¿ç®—
æ‰€æœ‰V1.43.0æ–°å¢çš„æ ‡é‡è¿ç®—å’Œå¹¿æ’­è¿ç®—æ–¹æ³•éƒ½æš‚æ—¶æœªå®ç°

### ä½¿ç”¨ç¤ºä¾‹

```cpp
try {
    auto cuda_backend = BackendManager::get_cuda_backend();

    // å°è¯•ä½¿ç”¨æœªå®ç°çš„æ–¹æ³•
    Tensor input = /* æŸä¸ªå¼ é‡ */;
    Tensor result = cuda_backend->reshape(input, {2, 12});  // æŠ›å‡ºNotImplementedError

} catch (const NotImplementedError& e) {
    std::cout << "Method not implemented: " << e.what() << std::endl;
    // å¯ä»¥å›é€€åˆ°CPUåç«¯æˆ–å…¶ä»–å®ç°
}
```

## ğŸ†• V1.51.0æ–°APIå®ç°

### å¼ é‡ç®—æœ¯è¿ç®—

#### `Tensor add(const Tensor& a, const Tensor& b) const override`

é«˜æ€§èƒ½GPUå¼ é‡åŠ æ³•ï¼ŒåŸºäºcuBLASå®ç°ã€‚

**å‚æ•°**ï¼š
- `a` - ç¬¬ä¸€ä¸ªæ“ä½œæ•°å¼ é‡
- `b` - ç¬¬äºŒä¸ªæ“ä½œæ•°å¼ é‡

**è¿”å›å€¼**ï¼š
- `Tensor` - ç»“æœå¼ é‡ï¼ˆa + bï¼‰

**ç‰¹æ€§**ï¼š
- **è®¾å¤‡ä¸€è‡´æ€§éªŒè¯**ï¼šè‡ªåŠ¨æ£€æŸ¥æ‰€æœ‰å¼ é‡æ˜¯å¦åœ¨åŒä¸€CUDAè®¾å¤‡
- **å½¢çŠ¶å’Œæ•°æ®ç±»å‹æ£€æŸ¥**ï¼šç¡®ä¿è¾“å…¥å¼ é‡å…¼å®¹
- **FP32ä¼˜åŒ–**ï¼šä¸“é—¨é’ˆå¯¹FP32å¼ é‡ä¼˜åŒ–
- **cuBLASåŠ é€Ÿ**ï¼šä½¿ç”¨cuBLASçš„Saxpyå‡½æ•°å®ç°é«˜æ€§èƒ½åŠ æ³•

**å®ç°**ï¼š
```cpp
Tensor CudaBackend::add(const Tensor& a, const Tensor& b) const {
    // è®¾å¤‡å’Œå½¢çŠ¶éªŒè¯
    validate_same_device(a.device());
    validate_same_device(b.device());

    if (a.shape() != b.shape()) {
        throw TRException("[CudaBackend::add] Shape mismatch");
    }

    // åˆ›å»ºç»“æœå¼ é‡
    Tensor result = this->empty(a.shape(), a.dtype());

    // ä½¿ç”¨cuBLASå®ç°åŠ æ³•ï¼šresult = a + b
    const float* a_data = static_cast<const float*>(a.data_ptr());
    const float* b_data = static_cast<const float*>(b.data_ptr());
    float* result_data = static_cast<float*>(result.data_ptr());
    size_t count = a.numel();

    // å…ˆæ‹·è´aåˆ°resultï¼Œå†æ‰§è¡Œresult += b
    CUDA_CHECK(cudaMemcpy(result_data, a_data, count * sizeof(float),
                         cudaMemcpyDeviceToDevice));
    float alpha = 1.0f;
    CUBLAS_CHECK(cublasSaxpy(cublas_handle_, count, &alpha,
                            b_data, 1, result_data, 1));
    return result;
}
```

#### `void add_into(const Tensor& a, const Tensor& b, Tensor& result) const override`

å°±åœ°å¼ é‡åŠ æ³•ï¼Œé¿å…é¢å¤–å†…å­˜åˆ†é…ã€‚

**å‚æ•°**ï¼š
- `a` - ç¬¬ä¸€ä¸ªæ“ä½œæ•°å¼ é‡
- `b` - ç¬¬äºŒä¸ªæ“ä½œæ•°å¼ é‡
- `result` - é¢„åˆ†é…çš„ç»“æœå¼ é‡

**ä¼˜åŒ–ç‰¹æ€§**ï¼š
- **é›¶æ‹·è´ä¼˜åŒ–**ï¼šç›´æ¥åœ¨é¢„åˆ†é…çš„ç»“æœå¼ é‡ä¸­è®¡ç®—
- **å†…å­˜é«˜æ•ˆ**ï¼šé¿å…ä¸´æ—¶å¼ é‡åˆ›å»ºå’Œé”€æ¯å¼€é”€

#### `Tensor mul(const Tensor& a, const Tensor& b) const override`

é«˜æ€§èƒ½GPUå¼ é‡é€å…ƒç´ ä¹˜æ³•ï¼ŒåŸºäºcuDNNå®ç°ã€‚

**å‚æ•°**ï¼š
- `a` - ç¬¬ä¸€ä¸ªæ“ä½œæ•°å¼ é‡
- `b` - ç¬¬äºŒä¸ªæ“ä½œæ•°å¼ é‡

**è¿”å›å€¼**ï¼š
- `Tensor` - ç»“æœå¼ é‡ï¼ˆa * bï¼‰

**ç‰¹æ€§**ï¼š
- **cuDNN OpTensor**ï¼šä½¿ç”¨cuDNNçš„é«˜æ€§èƒ½OpTensor API
- **å¼ é‡æè¿°ç¬¦ç®¡ç†**ï¼šè‡ªåŠ¨åˆ›å»ºå’Œç®¡ç†cuDNNå¼ é‡æè¿°ç¬¦
- **é”™è¯¯å¤„ç†**ï¼šå®Œå–„çš„å¼‚å¸¸å¤„ç†å’Œèµ„æºæ¸…ç†

**å®ç°**ï¼š
```cpp
Tensor CudaBackend::mul(const Tensor& a, const Tensor& b) const {
    // éªŒè¯å’Œåˆ›å»ºç»“æœå¼ é‡
    Tensor result = this->empty(a.shape(), a.dtype());
    mul_into(a, b, result);
    return result;
}

void CudaBackend::mul_into(const Tensor& a, const Tensor& b, Tensor& result) const {
    // ä½¿ç”¨cuDNN OpTensorå®ç°é€å…ƒç´ ä¹˜æ³•
    cudnnTensorDescriptor_t a_desc, b_desc, result_desc;
    CUDNN_CHECK(cudnnCreateTensorDescriptor(&a_desc));
    CUDNN_CHECK(cudnnCreateTensorDescriptor(&b_desc));
    CUDNN_CHECK(cudnnCreateTensorDescriptor(&result_desc));

    try {
        // è®¾ç½®4Då¼ é‡æè¿°ç¬¦ï¼ˆNCHWæ ¼å¼ï¼‰
        int n = a.batch(), c = a.channel(), h = a.height(), w = a.width();
        CUDNN_CHECK(cudnnSetTensor4dDescriptor(a_desc, CUDNN_TENSOR_NCHW,
                                             CUDNN_DATA_FLOAT, n, c, h, w));
        CUDNN_CHECK(cudnnSetTensor4dDescriptor(b_desc, CUDNN_TENSOR_NCHW,
                                             CUDNN_DATA_FLOAT, n, c, h, w));
        CUDNN_CHECK(cudnnSetTensor4dDescriptor(result_desc, CUDNN_TENSOR_NCHW,
                                             CUDNN_DATA_FLOAT, n, c, h, w));

        // åˆ›å»ºå¹¶é…ç½®OpTensoræè¿°ç¬¦
        cudnnOpTensorDescriptor_t op_desc;
        CUDNN_CHECK(cudnnCreateOpTensorDescriptor(&op_desc));
        CUDNN_CHECK(cudnnSetOpTensorDescriptor(op_desc, CUDNN_OP_TENSOR_MUL,
                                              CUDNN_DATA_FLOAT, CUDNN_PROPAGATE_NAN));

        // æ‰§è¡Œé€å…ƒç´ ä¹˜æ³•ï¼šresult = a * b
        const float alpha1 = 1.0f, alpha2 = 1.0f, beta = 0.0f;
        CUDNN_CHECK(cudnnOpTensor(cudnn_handle_, op_desc,
                                 &alpha1, a_desc, a_data,
                                 &alpha2, b_desc, b_data,
                                 &beta, result_desc, result_data));

        CUDNN_CHECK(cudnnDestroyOpTensorDescriptor(op_desc));
    } catch (...) {
        // å¼‚å¸¸å®‰å…¨ï¼šè‡ªåŠ¨æ¸…ç†èµ„æº
        CUDNN_CHECK(cudnnDestroyTensorDescriptor(a_desc));
        CUDNN_CHECK(cudnnDestroyTensorDescriptor(b_desc));
        CUDNN_CHECK(cudnnDestroyTensorDescriptor(result_desc));
        throw;
    }

    // æ­£å¸¸æ¸…ç†èµ„æº
    CUDNN_CHECK(cudnnDestroyTensorDescriptor(a_desc));
    CUDNN_CHECK(cudnnDestroyTensorDescriptor(b_desc));
    CUDNN_CHECK(cudnnDestroyTensorDescriptor(result_desc));
}
```

#### `void mul_into(const Tensor& a, const Tensor& b, Tensor& result)`

å°±åœ°å¼ é‡ä¹˜æ³•å®ç°ï¼Œé¿å…å†…å­˜åˆ†é…å¼€é”€ã€‚

### è·¨åç«¯è½¬æ¢æ¥å£

#### `Tensor from_cpu(const Tensor& tensor) const override`

ä»CPUè½¬æ¢å¼ é‡åˆ°CUDAè®¾å¤‡ï¼Œè‡ªåŠ¨å¤„ç†å†…å­˜å¸ƒå±€è½¬æ¢ã€‚

**å‚æ•°**ï¼š
- `tensor` - CPUè®¾å¤‡ä¸Šçš„å¼ é‡ï¼ˆè¡Œä¸»åºå­˜å‚¨ï¼‰

**è¿”å›å€¼**ï¼š
- `Tensor` - CUDAè®¾å¤‡ä¸Šçš„å¼ é‡ï¼ˆåˆ—ä¸»åºå­˜å‚¨ï¼‰

**ç‰¹æ€§**ï¼š
- **2DçŸ©é˜µè½¬æ¢**ï¼šè‡ªåŠ¨æ‰§è¡Œè¡Œä¸»åºâ†’åˆ—ä¸»åºè½¬æ¢
- **é2Då¼ é‡**ï¼šç›´æ¥å¤åˆ¶æ•°æ®
- **GPUå†…å­˜åˆ†é…**ï¼šè‡ªåŠ¨åœ¨GPUä¸Šåˆ†é…å†…å­˜

**æ€§èƒ½**ï¼šåŸºäºCUDAçš„é«˜æ•ˆå†…å­˜å¤åˆ¶

#### `Tensor to_cpu(const Tensor& tensor) const override`

ä»CUDAè®¾å¤‡è½¬æ¢å¼ é‡åˆ°CPUï¼Œè‡ªåŠ¨å¤„ç†å†…å­˜å¸ƒå±€è½¬æ¢ã€‚

**å‚æ•°**ï¼š
- `tensor` - CUDAè®¾å¤‡ä¸Šçš„å¼ é‡ï¼ˆåˆ—ä¸»åºå­˜å‚¨ï¼‰

**è¿”å›å€¼**ï¼š
- `Tensor` - CPUè®¾å¤‡ä¸Šçš„å¼ é‡ï¼ˆè¡Œä¸»åºå­˜å‚¨ï¼‰

**ç‰¹æ€§**ï¼š
- **2DçŸ©é˜µè½¬æ¢**ï¼šè‡ªåŠ¨æ‰§è¡Œåˆ—ä¸»åºâ†’è¡Œä¸»åºè½¬æ¢
- **é2Då¼ é‡**ï¼šç›´æ¥å¤åˆ¶æ•°æ®
- **åŒæ­¥æ“ä½œ**ï¼šç¡®ä¿GPUè®¡ç®—å®Œæˆåå†å¤åˆ¶

### åŸºç¡€å¼ é‡æ“ä½œæ¥å£

#### `Tensor mm(const Tensor& a, const Tensor& b) override`

é«˜æ€§èƒ½GPUçŸ©é˜µä¹˜æ³•ã€‚

**å‚æ•°**ï¼š
- `a` - è¾“å…¥å¼ é‡Aï¼Œå½¢çŠ¶åº”ä¸º(M,K)
- `b` - è¾“å…¥å¼ é‡Bï¼Œå½¢çŠ¶åº”ä¸º(K,N)

**è¿”å›å€¼**ï¼š
- `Tensor` - ç»“æœå¼ é‡ï¼Œå½¢çŠ¶ä¸º(M,N)

**ç‰¹æ€§**ï¼š
- **GPUåŠ é€Ÿ**ï¼šåˆ©ç”¨å¤§è§„æ¨¡å¹¶è¡Œè®¡ç®—
- **cuBLASä¼˜åŒ–**ï¼šè‡ªåŠ¨é€‰æ‹©æœ€ä¼˜ç®—æ³•
- **é«˜ååé‡**ï¼šé€‚åˆå¤§æ‰¹é‡çŸ©é˜µè¿ç®—
- **ç®—æ³•ç¼“å­˜**ï¼šæ™ºèƒ½ç¼“å­˜æœ€ä¼˜GEMMç®—æ³•é…ç½®

#### `void mm_into(const Tensor& a, const Tensor& b, Tensor& result) override`

å°±åœ°çŸ©é˜µä¹˜æ³•ï¼Œé¿å…é¢å¤–å†…å­˜åˆ†é…ã€‚

#### `void fill(Tensor& dst, float value) override`

ç”¨æµ®ç‚¹æ•°å€¼å¡«å……GPUå¼ é‡ã€‚

**å‚æ•°**ï¼š
- `dst` - ç›®æ ‡å¼ é‡
- `value` - å¡«å……å€¼

**å®ç°**ï¼š
```cpp
void CudaBackend::fill(Tensor& dst, float value) {
    float* data = static_cast<float*>(dst.data_ptr());
    int64_t size = dst.numel();

    // ä½¿ç”¨CUDAæ ¸å‡½æ•°å¡«å……
    cuda_fill_kernel<<<blocks, threads>>>(data, value, size);
    CUDA_CHECK(cudaGetLastError());
    CUDA_CHECK(cudaDeviceSynchronize());
}
```

## ä½¿ç”¨ç¤ºä¾‹

### ğŸ†• V1.51.0æ–°APIä½¿ç”¨ç¤ºä¾‹

```cpp
#include "tech_renaissance.h"
using namespace tr;

void v1_51_0_new_api_examples() {
    try {
        // è·å–CUDAåç«¯å®ä¾‹
        auto cuda_backend = BackendManager::get_cuda_backend();
        auto cpu_backend = BackendManager::get_cpu_backend();

        // 1. åˆ›å»ºæµ‹è¯•å¼ é‡
        Tensor cpu_a = cpu_backend->randn({256, 256}, 42);
        Tensor cpu_b = cpu_backend->randn({256, 256}, 123);

        // 2. è½¬æ¢åˆ°CUDA
        Tensor cuda_a = cuda_backend->from_cpu(cpu_a);
        Tensor cuda_b = cuda_backend->from_cpu(cpu_b);

        // 3. ğŸ†• ä½¿ç”¨æ–°çš„add API
        Tensor cuda_sum = cuda_backend->add(cuda_a, cuda_b);
        std::cout << "Tensor addition completed with new API!" << std::endl;

        // 4. ğŸ†• ä½¿ç”¨æ–°çš„mul API
        Tensor cuda_product = cuda_backend->mul(cuda_a, cuda_b);
        std::cout << "Tensor element-wise multiplication completed!" << std::endl;

        // 5. ğŸ†• ä½¿ç”¨intoç‰ˆæœ¬é¿å…å†…å­˜åˆ†é…
        Tensor cuda_result = cuda_backend->empty({256, 256}, DType::FP32);
        cuda_backend->add_into(cuda_a, cuda_b, cuda_result);
        std::cout << "In-place addition completed!" << std::endl;

        // 6. è½¬æ¢å›CPUéªŒè¯ç»“æœ
        Tensor cpu_result = cuda_backend->to_cpu(cuda_result);
        std::cout << "Result transferred back to CPU!" << std::endl;

    } catch (const TRException& e) {
        std::cerr << "CUDA Backend error: " << e.what() << std::endl;
    }
}
```

### æ€§èƒ½å¯¹æ¯”ç¤ºä¾‹

```cpp
void performance_comparison_new_api() {
    auto cuda_backend = BackendManager::get_cuda_backend();
    auto cpu_backend = BackendManager::get_cpu_backend();

    // æµ‹è¯•æ•°æ®å¤§å°
    const int N = 1024, M = 1024;

    // åˆ›å»ºæµ‹è¯•æ•°æ®
    Tensor cpu_a = cpu_backend->randn({N, M});
    Tensor cpu_b = cpu_backend->randn({N, M});

    // è½¬æ¢åˆ°CUDA
    Tensor cuda_a = cuda_backend->from_cpu(cpu_a);
    Tensor cuda_b = cuda_backend->from_cpu(cpu_b);

    // æµ‹è¯•æ–°çš„add APIæ€§èƒ½
    auto start = std::chrono::high_resolution_clock::now();
    for (int i = 0; i < 100; ++i) {
        Tensor result = cuda_backend->add(cuda_a, cuda_b);
    }
    auto end = std::chrono::high_resolution_clock::now();

    auto duration = std::chrono::duration_cast<std::chrono::microseconds>(end - start);
    std::cout << "V1.51.0 add API: " << duration.count() << " Î¼s for 100 operations" << std::endl;

    // æµ‹è¯•æ–°çš„mul APIæ€§èƒ½
    start = std::chrono::high_resolution_clock::now();
    for (int i = 0; i < 100; ++i) {
        Tensor result = cuda_backend->mul(cuda_a, cuda_b);
    }
    end = std::chrono::high_resolution_clock::now();

    duration = std::chrono::duration_cast<std::chrono::microseconds>(end - start);
    std::cout << "V1.51.0 mul API: " << duration.count() << " Î¼s for 100 operations" << std::endl;
}
```

### åŸºç¡€GPUæ“ä½œ

### æ€§èƒ½åŸºå‡†æµ‹è¯•

```cpp
void cuda_performance_benchmark() {
    auto cuda_backend = BackendManager::get_cuda_backend();
    auto cpu_backend = BackendManager::get_cpu_backend();

    // æµ‹è¯•çŸ©é˜µå¤§å°
    const int M = 1024, K = 2048, N = 512;

    // åˆ›å»ºæµ‹è¯•æ•°æ®
    Tensor cpu_a = cpu_backend->randn({M, K});
    Tensor cpu_b = cpu_backend->randn({K, N});

    // è½¬æ¢åˆ°GPU
    Tensor cuda_a = cuda_backend->from_cpu(cpu_a);
    Tensor cuda_b = cuda_backend->from_cpu(cpu_b);
    Tensor cuda_result = Tensor::empty({M, N}, DType::FP32, tr::CUDA(0));

    // GPUæ€§èƒ½æµ‹è¯•
    auto start = std::chrono::high_resolution_clock::now();
    cuda_backend->mm(cuda_result, cuda_a, cuda_b);
    auto end = std::chrono::high_resolution_clock::now();

    auto duration = std::chrono::duration_cast<std::chrono::microseconds>(end - start);
    double gflops = (2.0 * M * K * N) / (duration.count() * 1e6) / 1e9;

    std::cout << "CUDA Performance:" << std::endl;
    std::cout << "  Matrix size: " << M << "x" << K << " x " << K << "x" << N << std::endl;
    std::cout << "  Execution time: " << duration.count() << " Î¼s" << std::endl;
    std::cout << "  Performance: " << gflops << " GFLOPS" << std::endl;
}
```

### ğŸ†• V1.43.0æœªå®ç°æ–¹æ³•å¤„ç†

```cpp
void handle_not_implemented_methods() {
    auto cuda_backend = BackendManager::get_cuda_backend();
    auto cpu_backend = BackendManager::get_cpu_backend();

    try {
        // å°è¯•ä½¿ç”¨CUDAåç«¯çš„æ–°æ–¹æ³•
        Tensor input = cpu_backend->randn({2, 3, 4});
        Tensor result = cuda_backend->reshape(input, {2, 12});

    } catch (const NotImplementedError& e) {
        std::cout << "Method not implemented in CUDA backend: " << e.what() << std::endl;

        // å›é€€ç­–ç•¥ï¼šä½¿ç”¨CPUåç«¯
        std::cout << "Falling back to CPU backend..." << std::endl;
        Tensor result = cpu_backend->reshape(input, {2, 12});

        // æˆ–è€…å°†ç»“æœè½¬æ¢åˆ°CUDA
        Tensor cuda_result = cuda_backend->from_cpu(result);
    }
}
```

## æ€§èƒ½ç‰¹æ€§

### è®¡ç®—æ€§èƒ½

- **çŸ©é˜µä¹˜æ³•**ï¼šåŸºäºcuBLASä¼˜åŒ–ï¼Œæ€§èƒ½æ¥è¿‘ç¡¬ä»¶æé™
- **å¤§è§„æ¨¡å¹¶è¡Œ**ï¼šåˆ©ç”¨GPUæ•°åƒä¸ªæ ¸å¿ƒå¹¶è¡Œè®¡ç®—
- **é«˜å†…å­˜å¸¦å®½**ï¼šå……åˆ†åˆ©ç”¨GPUå†…å­˜å¸¦å®½ä¼˜åŠ¿

### å†…å­˜ç®¡ç†

- **GPUå†…å­˜æ± **ï¼šå‡å°‘GPUå†…å­˜åˆ†é…å¼€é”€
- **å¼‚æ­¥ä¼ è¾“**ï¼šæ”¯æŒCPU-GPUå¼‚æ­¥æ•°æ®ä¼ è¾“
- **æ™ºèƒ½åŒæ­¥**ï¼šè‡ªåŠ¨ç®¡ç†CUDAäº‹ä»¶å’ŒæµåŒæ­¥

### å®æµ‹æ€§èƒ½ï¼ˆV1.43.0ï¼‰

| è¿ç®—ç±»å‹ | CUDAæ€§èƒ½ | åŠ é€Ÿæ¯”ï¼ˆvs CPUï¼‰ |
|---------|-----------|----------------|
| çŸ©é˜µä¹˜æ³• | 6602.77 GFLOPS | 52x |
| 3x3å·ç§¯ | 11917.52 GFLOPS | 35x |
| 1x1å·ç§¯ | 6076.90 GFLOPS | 37x |
| 3x3è½¬ç½®å·ç§¯ | 12789.55 GFLOPS | 66x |

## é”™è¯¯å¤„ç†

### CUDAç‰¹å®šé”™è¯¯

```cpp
try {
    auto cuda_backend = BackendManager::get_cuda_backend(999);  // æ— æ•ˆè®¾å¤‡ID

} catch (const TRException& e) {
    std::cerr << "CUDA initialization error: " << e.what() << std::endl;
}

try {
    auto cuda_backend = BackendManager::get_cuda_backend();
    // å°è¯•åœ¨CUDAåç«¯ä¸Šä½¿ç”¨æœªå®ç°çš„æ–¹æ³•
    Tensor result = cuda_backend->some_new_method(input);

} catch (const NotImplementedError& e) {
    std::cout << "Method not implemented: " << e.what() << std::endl;
}
```

### å¸¸è§CUDAé”™è¯¯

- **è®¾å¤‡ä¸å­˜åœ¨**ï¼šæŒ‡å®šçš„GPUè®¾å¤‡IDæ— æ•ˆ
- **å†…å­˜ä¸è¶³**ï¼šGPUå†…å­˜ä¸è¶³ä»¥åˆ†é…å¼ é‡
- **è®¡ç®—é”™è¯¯**ï¼šCUDAè®¡ç®—å†…æ ¸æ‰§è¡Œå¤±è´¥
- **æ–¹æ³•æœªå®ç°**ï¼šV1.43.0æ–°å¢æ–¹æ³•æš‚æœªåœ¨CUDAåç«¯å®ç°

## æœ€ä½³å®è·µ

1. **è®¾å¤‡æ£€æŸ¥**ï¼šåœ¨ä½¿ç”¨CUDAå‰æ£€æŸ¥GPUå¯ç”¨æ€§
2. **å†…å­˜ç®¡ç†**ï¼šåŠæ—¶é‡Šæ”¾ä¸éœ€è¦çš„GPUå†…å­˜
3. **å¼‚æ­¥æ“ä½œ**ï¼šåˆ©ç”¨CUDAæµæé«˜å¹¶å‘æ€§èƒ½
4. **é”™è¯¯å¤„ç†**ï¼šå¦¥å–„å¤„ç†CUDAç›¸å…³å¼‚å¸¸
5. **æ€§èƒ½ä¼˜åŒ–**ï¼šæ‰¹é‡æ“ä½œå‡å°‘GPU-CPUä¼ è¾“å¼€é”€
6. **ğŸ†• æ–¹æ³•å›é€€**ï¼šå¯¹äºæœªå®ç°çš„æ–¹æ³•ï¼Œè€ƒè™‘å›é€€åˆ°CPUåç«¯

## æœªæ¥å¼€å‘è®¡åˆ’

### V1.44.0 CUDAåç«¯æ‰©å±•è®¡åˆ’

1. **å®ç°V1.43.0æ–°å¢æ–¹æ³•**ï¼š
   - å½¢çŠ¶å˜æ¢æ“ä½œï¼šreshapeç³»åˆ—æ–¹æ³•
   - æ¿€æ´»å‡½æ•°ï¼štanhã€dtanhç³»åˆ—æ–¹æ³•
   - æŸå¤±å‡½æ•°ï¼šcrossentropyå®ç°
   - One-hotç¼–ç ï¼šone_hotç³»åˆ—æ–¹æ³•
   - æ ‡é‡è¿ç®—ï¼šminusã€macã€clampç³»åˆ—æ–¹æ³•
   - å¹¿æ’­è¿ç®—ï¼šadd_broadcastã€mul_broadcastç³»åˆ—æ–¹æ³•

2. **æ€§èƒ½ä¼˜åŒ–**ï¼š
   - CUDAæ ¸å‡½æ•°ä¼˜åŒ–
   - å†…å­˜è®¿é—®æ¨¡å¼ä¼˜åŒ–
   - å¤šGPUæ”¯æŒ

3. **é«˜çº§ç‰¹æ€§**ï¼š
   - æ··åˆç²¾åº¦è®¡ç®—
   - åŠ¨æ€å½¢çŠ¶æ”¯æŒ
   - è‡ªå®šä¹‰CUDAæ ¸å‡½æ•°

## ç‰ˆæœ¬å†å²

### V1.51.0 (2025-11-19)
**é‡å¤§æ›´æ–° - æ–°APIå®ç°ä¸cuBLAS/cuDNNä¼˜åŒ–**

#### ğŸ†• æ–°å¢åŠŸèƒ½
- **add/mul APIå®ç°**: åŸºäºcuBLAS/cuDNNçš„é«˜æ€§èƒ½å¼ é‡ç®—æœ¯è¿ç®—
- **consté‡è½½æ–¹æ³•**: æ‰€æœ‰æ¥å£æ”¯æŒconstæ­£ç¡®æ€§ï¼Œæä¾›æ›´å¥½çš„ç±»å‹å®‰å…¨
- **è®¾å¤‡ä¸€è‡´æ€§éªŒè¯**: å®Œå–„çš„CUDAè®¾å¤‡æ£€æŸ¥å’Œé”™è¯¯å¤„ç†æœºåˆ¶
- **ä¸BackendåŸºç±»å®Œå…¨å¯¹é½**: æ¥å£è®¾è®¡ä¸åŸºç±»ä¿æŒ100%ä¸€è‡´

#### âš¡ æ€§èƒ½ä¼˜åŒ–
- **cuBLASåŠ é€Ÿ**: å¼ é‡åŠ æ³•ä½¿ç”¨cuBLAS Saxpyå‡½æ•°ä¼˜åŒ–
- **cuDNN OpTensor**: å¼ é‡ä¹˜æ³•ä½¿ç”¨cuDNNé«˜æ€§èƒ½OpTensor API
- **ä¸´æ—¶ç¼“å†²åŒºç®¡ç†**: æ™ºèƒ½ç¼“å­˜æœ€ä¼˜ç®—æ³•é…ç½®å’Œå·¥ä½œç©ºé—´
- **å†…å­˜æ•ˆç‡**: intoç‰ˆæœ¬APIé¿å…é¢å¤–å†…å­˜åˆ†é…

#### ğŸ”§ æŠ€æœ¯æ”¹è¿›
- **å¼‚å¸¸å®‰å…¨**: å®Œå–„çš„å¼‚å¸¸å¤„ç†å’Œèµ„æºè‡ªåŠ¨æ¸…ç†
- **å½¢çŠ¶å’Œæ•°æ®ç±»å‹æ£€æŸ¥**: è¿è¡Œæ—¶éªŒè¯ç¡®ä¿è¾“å…¥å¼ é‡å…¼å®¹æ€§
- **è®¾å¤‡éªŒè¯**: è‡ªåŠ¨æ£€æŸ¥æ‰€æœ‰å¼ é‡æ˜¯å¦åœ¨åŒä¸€CUDAè®¾å¤‡
- **FP32ä¼˜åŒ–**: ä¸“é—¨é’ˆå¯¹FP32å¼ é‡çš„æ€§èƒ½ä¼˜åŒ–

### V1.46.3 (2025-11-17)
**åŠŸèƒ½å®Œå–„ - æ„é€ å‡½æ•°è®¾è®¡å’Œä»£ç è§„èŒƒä¼˜åŒ–**

#### ğŸ”§ æ„é€ å‡½æ•°ä¼˜åŒ–
- **ç»Ÿä¸€åŒ–è®¾è®¡**: ä½¿ç”¨`explicit CudaBackend(int device_id = 0)`
- **ç±»å‹å®‰å…¨**: explicitå…³é”®å­—é˜²æ­¢éšå¼è½¬æ¢
- **å‚æ•°æ–‡æ¡£**: å®Œå–„çš„device_idå‚æ•°è¯´æ˜å’Œé»˜è®¤å€¼

### V1.43.0 (2025-11-16)
**åŸºç¡€é‡æ„ - æ„é€ å‡½æ•°ä¿®å¤å’Œåç«¯é‡æ„å…¼å®¹æ€§**

#### ğŸ”§ æ ¸å¿ƒä¿®å¤
- **æ„é€ å‡½æ•°ä¿®å¤**: æ­£ç¡®è°ƒç”¨BackendåŸºç±»æ„é€ å‡½æ•°
- **å®ç³»ç»Ÿç»§æ‰¿**: ç»§æ‰¿BackendåŸºç±»çš„å®å®šä¹‰ç³»ç»Ÿ
- **å¼‚å¸¸æ ¼å¼ç»Ÿä¸€**: ç»Ÿä¸€çš„NotImplementedErrorå¼‚å¸¸æ ¼å¼

#### âœ… å…¼å®¹æ€§ä¿è¯
- **100%å‘åå…¼å®¹**: ç°æœ‰ä»£ç æ— éœ€ä¿®æ”¹
- **é”™è¯¯å¤„ç†å®Œå–„**: CUDAç›¸å…³å¼‚å¸¸å¤„ç†æœºåˆ¶
- **æ¥å£æ”¯æŒ**: æ”¯æŒV1.43.0æ–°å¢æ¥å£çš„å¼‚å¸¸å¤„ç†

---

## å½“å‰ç‰ˆæœ¬ä¿¡æ¯

- **ç‰ˆæœ¬**: V1.51.0
- **æ›´æ–°æ—¥æœŸ**: 2025-11-19
- **ä½œè€…**: æŠ€æœ¯è§‰é†’å›¢é˜Ÿ
- **ä¸»è¦æ›´æ–°**:
  - ğŸ†• åŸºäºcuBLAS/cuDNNçš„æ–°add/mul APIå®ç°
  - âš¡ é«˜æ€§èƒ½å¼ é‡ç®—æœ¯è¿ç®—ä¼˜åŒ–
  - ğŸ”§ consté‡è½½æ–¹æ³•å®Œå–„
  - âœ… ä¸BackendåŸºç±»å®Œå…¨å¯¹é½çš„æ¥å£è®¾è®¡
  - ğŸ“ˆ ä¸´æ—¶ç¼“å†²åŒºå’Œç®—æ³•ç¼“å­˜ä¼˜åŒ–
  - ğŸ›¡ï¸ å®Œå–„çš„è®¾å¤‡ä¸€è‡´æ€§éªŒè¯å’Œé”™è¯¯å¤„ç†