# CudaBackend API æ–‡æ¡£

## æ¦‚è¿°

`CudaBackend`æ˜¯æŠ€æœ¯è§‰é†’æ¡†æ¶çš„GPUè®¡ç®—åç«¯å®ç°ï¼Œç»§æ‰¿è‡ª`Backend`åŸºç±»ã€‚å®ƒåŸºäºNVIDIA CUDAå¹³å°ï¼Œç»“åˆcuBLASå’ŒcuDNNåº“æä¾›é«˜æ€§èƒ½çš„GPUåŠ é€Ÿè®¡ç®—èƒ½åŠ›ï¼Œæ”¯æŒæ·±åº¦å­¦ä¹ å·¥ä½œè´Ÿè½½çš„å¤§è§„æ¨¡å¹¶è¡Œè®¡ç®—ã€‚

**ç‰ˆæœ¬**: V1.43.0
**æ›´æ–°æ—¥æœŸ**: 2025-11-16
**ä½œè€…**: æŠ€æœ¯è§‰é†’å›¢é˜Ÿ

## ğŸ†• V1.43.0é‡å¤§æ›´æ–°

### ğŸ”§ æ„é€ å‡½æ•°ä¿®å¤

åœ¨V1.43.0ç‰ˆæœ¬ä¸­ï¼Œä¿®å¤äº†CUDAåç«¯æ„é€ å‡½æ•°çš„é‡è¦é—®é¢˜ï¼š

```cpp
// ä¿®å¤å‰ï¼ˆä¼šå¯¼è‡´Backendå®ä¾‹åŒ–é”™è¯¯ï¼‰
CudaBackend::CudaBackend(int device_id) : device_id_(device_id), ... {
    // åˆå§‹åŒ–ä»£ç 
}

// ä¿®å¤åï¼ˆæ­£ç¡®è°ƒç”¨Backendæ„é€ å‡½æ•°ï¼‰
CudaBackend::CudaBackend(int device_id) : Backend(true), device_id_(device_id), ... {
    // åˆå§‹åŒ–ä»£ç 
}
```

### âœ… é‡æ„å…¼å®¹æ€§

- **100%å‘åå…¼å®¹**ï¼šæ‰€æœ‰ç°æœ‰ä»£ç æ— éœ€ä¿®æ”¹å³å¯æ­£å¸¸å·¥ä½œ
- **å®ä¾‹åŒ–ä¿®å¤**ï¼šè§£å†³äº†"Backend class cannot be instantiated directly"é”™è¯¯
- **å¼‚å¸¸å¤„ç†**ï¼šå®Œå–„çš„é”™è¯¯æ£€æŸ¥å’Œå¼‚å¸¸å¤„ç†æœºåˆ¶
- **å®ç³»ç»Ÿæ”¯æŒ**ï¼šç»§æ‰¿BackendåŸºç±»çš„å®å®šä¹‰ç³»ç»Ÿ

## è®¾è®¡ç†å¿µ

### æ ¸å¿ƒè®¾è®¡åŸåˆ™

1. **åˆ—ä¸»åºå­˜å‚¨**ï¼šCUDAåç«¯ä½¿ç”¨**åˆ—ä¸»åºï¼ˆColumn-majorï¼‰**å­˜å‚¨å¼ é‡æ•°æ®ï¼Œä¸cuBLAS/cuDNNåº“æ¥å£ä¿æŒä¸€è‡´
2. **é«˜æ€§èƒ½è®¡ç®—**ï¼šåŸºäºcuBLASçš„ä¼˜åŒ–çŸ©é˜µè¿ç®—ï¼ŒGPUæ€§èƒ½æ¥è¿‘ç¡¬ä»¶æé™
3. **é€æ˜è½¬æ¢**ï¼šé€šè¿‡`from_cpu()`å’Œ`to_cpu()`æ–¹æ³•è‡ªåŠ¨å¤„ç†è¡Œä¸»åºä¸åˆ—ä¸»åºä¹‹é—´çš„æ ¼å¼è½¬æ¢
4. **å¼‚æ­¥è®¡ç®—**ï¼šä½¿ç”¨CUDAæµå®ç°å¼‚æ­¥æ“ä½œï¼Œæé«˜å¹¶å‘æ€§èƒ½
5. **RAIIç®¡ç†**ï¼šæ™ºèƒ½æŒ‡é’ˆè‡ªåŠ¨å†…å­˜ç®¡ç†ï¼Œé˜²æ­¢GPUå†…å­˜æ³„æ¼
6. **ğŸ†• å®é©±åŠ¨æ‰©å±•**ï¼šé€šè¿‡V1.43.0çš„å®ç³»ç»Ÿæ”¯æŒå¿«é€Ÿå®ç°æ–°æ–¹æ³•

### å…³é”®æ¶æ„ç‰¹æ€§

#### **åç«¯ç®¡ç†å­˜å‚¨åŸåˆ™ï¼ˆæ ¸å¿ƒç‰¹æ€§ï¼‰**

CUDAåç«¯éµå¾ª"åç«¯ç®¡ç†å­˜å‚¨"çš„è®¾è®¡åŸåˆ™ï¼š
- **CPUåç«¯**ï¼šä½¿ç”¨è¡Œä¸»åºï¼ˆRow-majorï¼‰å­˜å‚¨å¼ é‡æ•°æ®
- **CUDAåç«¯**ï¼šä½¿ç”¨åˆ—ä¸»åºï¼ˆColumn-majorï¼‰å­˜å‚¨å¼ é‡æ•°æ®
- **è½¬æ¢å±‚é€æ˜**ï¼šç”¨æˆ·æ— éœ€å…³å¿ƒåº•å±‚å­˜å‚¨æ ¼å¼ï¼Œ`from_cpu()`å’Œ`to_cpu()`è‡ªåŠ¨å¤„ç†è½¬æ¢

#### **å†…å­˜å¸ƒå±€è½¬æ¢å±‚**

```cpp
// CPU â†’ CUDA è½¬æ¢ï¼šè¡Œä¸»åº â†’ åˆ—ä¸»åº
Tensor CudaBackend::from_cpu(const Tensor& tensor) {
    // 1. åˆ›å»ºCUDA Storageï¼ˆåˆ—ä¸»åºå­˜å‚¨ï¼‰
    Tensor cuda_tensor = Tensor::empty(tensor.shape(), tensor.dtype(), tr::CUDA[device_id_]);

    // 2. å¯¹äº2DçŸ©é˜µï¼Œæ‰§è¡Œå†…å­˜å¸ƒå±€è½¬æ¢
    if (tensor.shape().ndim() == 2) {
        int32_t M = tensor.shape().height();  // è¡Œæ•°
        int32_t N = tensor.shape().width();   // åˆ—æ•°

        const float* cpu_data = static_cast<const float*>(tensor.data_ptr());
        float* cuda_data = static_cast<float*>(cuda_tensor.data_ptr());

        // è¡Œä¸»åº â†’ åˆ—ä¸»åºè½¬æ¢
        for (int32_t i = 0; i < M; ++i) {
            for (int32_t j = 0; j < N; ++j) {
                cuda_data[j * M + i] = cpu_data[i * N + j];
            }
        }
    } else {
        // é2Då¼ é‡ç›´æ¥å¤åˆ¶
        copy_data(cuda_tensor.data_ptr(), tensor.data_ptr(),
             tensor.memory_size(), tr::CUDA[device_id_], tr::CPU);
    }

    return cuda_tensor;
}

// CUDA â†’ CPU è½¬æ¢ï¼šåˆ—ä¸»åº â†’ è¡Œä¸»åº
Tensor CudaBackend::to_cpu(const Tensor& tensor) {
    // 1. åˆ›å»ºCPU Storageï¼ˆè¡Œä¸»åºå­˜å‚¨ï¼‰
    Tensor cpu_tensor = Tensor::empty(tensor.shape(), tensor.dtype(), tr::CPU);

    // 2. å¯¹äº2DçŸ©é˜µï¼Œæ‰§è¡Œå†…å­˜å¸ƒå±€è½¬æ¢
    if (tensor.shape().ndim() == 2) {
        int32_t M = tensor.shape().height();  // è¡Œæ•°
        int32_t N = tensor.shape().width();   // åˆ—æ•°

        const float* cuda_data = static_cast<const float*>(tensor.data_ptr());
        float* cpu_data = static_cast<float*>(cpu_tensor.data_ptr());

        // åˆ—ä¸»åº â†’ è¡Œä¸»åºè½¬æ¢
        for (int32_t i = 0; i < M; ++i) {
            for (int32_t j = 0; j < N; ++j) {
                cpu_data[i * N + j] = cuda_data[j * M + i];
            }
        }
    } else {
        // é2Då¼ é‡ç›´æ¥å¤åˆ¶
        copy_data(cpu_tensor.data_ptr(), tensor.data_ptr(),
             tensor.memory_size(), tr::CPU, tensor.device());
    }

    return cpu_tensor;
}
```

## å¤´æ–‡ä»¶

```cpp
#include "tech_renaissance/backend/cuda_backend.h"
```

## ç¼–è¯‘è¦æ±‚

- **CUDA Toolkit**ï¼š12.0æˆ–æ›´é«˜ç‰ˆæœ¬
- **cuBLAS**ï¼šCUDAåŸºç¡€çº¿æ€§ä»£æ•°å­ç¨‹åºåº“
- **cuDNN**ï¼šCUDAæ·±åº¦ç¥ç»ç½‘ç»œåº“
- **å…¼å®¹GPU**ï¼šæ”¯æŒCUDAçš„NVIDIA GPU

## æ„é€ å‡½æ•°

```cpp
explicit CudaBackend(int device_id = 0);
```

**å‚æ•°**ï¼š
- `device_id` - GPUè®¾å¤‡IDï¼ˆå¯é€‰ï¼Œé»˜è®¤0ï¼‰

**ç‰¹æ€§**ï¼š
- è‡ªåŠ¨åˆå§‹åŒ–CUDAä¸Šä¸‹æ–‡
- åˆ›å»ºCUDAæµå’ŒcuBLAS/cuDNNå¥æŸ„
- è°ƒç”¨`Backend(true)`ç¡®ä¿æ­£ç¡®åˆå§‹åŒ–

**ç¤ºä¾‹**ï¼š
```cpp
// ä½¿ç”¨é»˜è®¤GPUï¼ˆè®¾å¤‡0ï¼‰
auto cuda_backend = std::make_shared<CudaBackend>();

// æŒ‡å®šGPUè®¾å¤‡
auto cuda_backend = std::make_shared<CudaBackend>(1);  // ä½¿ç”¨è®¾å¤‡1
```

## ğŸ†• V1.43.0æ–°å¢æ¥å£è¯´æ˜

### NotImplementedErrorå¤„ç†

åœ¨V1.43.0ä¸­ï¼ŒCUDAåç«¯ç»§æ‰¿äº†BackendåŸºç±»çš„å®å®šä¹‰ç³»ç»Ÿã€‚æœªå®ç°çš„æ–¹æ³•ä¼šæŠ›å‡ºç»Ÿä¸€æ ¼å¼çš„å¼‚å¸¸ï¼š

```
[CudaBackend method_name] Operation NOT implemented!
```

### ğŸ†• V1.44.1æ–°å¢çš„æ–¹æ³•

ä»¥ä¸‹æ–¹æ³•åœ¨V1.44.1ç‰ˆæœ¬ä¸­å·²å®ç°ï¼š

#### è§†å›¾æ“ä½œ
```cpp
Tensor view(const Tensor& input, const Shape& new_shape) override;
```
**ç‰¹æ€§**:
- GPUè®¾å¤‡ä¸Šçš„é›¶æ‹·è´å¼ é‡å˜æ¢
- ä¸CPUåç«¯ä¿æŒä¸€è‡´çš„æ¥å£å’Œè¡Œä¸º
- é«˜æ•ˆçš„CUDAå†…å­˜ç®¡ç†
- æ”¯æŒå¤§å°ºå¯¸å¼ é‡çš„å¿«é€Ÿå½¢çŠ¶é‡è§£é‡Š

#### å½¢çŠ¶å˜æ¢æ“ä½œ
```cpp
Tensor reshape(const Tensor& tensor_a, const Shape& shape) override;
void reshape_inplace(Tensor& tensor_a, const Shape& shape) override;
void reshape_into(const Tensor& tensor_a, Tensor& result, const Shape& shape) override;
```

#### åŒæ›²å‡½æ•°æ“ä½œ
```cpp
Tensor tanh(const Tensor& tensor_a) override;
void tanh_inplace(Tensor& tensor_a) override;
void tanh_into(const Tensor& tensor_a, Tensor& result) override;
Tensor dtanh(const Tensor& tensor_a) override;
void dtanh_inplace(Tensor& tensor_a) override;
void dtanh_into(const Tensor& tensor_a, Tensor& result) override;
```

#### æŸå¤±å‡½æ•°æ“ä½œ
```cpp
float crossentropy(const Tensor& pred, const Tensor& label, std::string reduction) override;
```

#### One-hotç¼–ç æ“ä½œ
```cpp
Tensor one_hot(const Tensor& label, int32_t num_classes, float label_smoothing) override;
void one_hot_into(const Tensor& label, Tensor& result, int32_t num_classes, float label_smoothing) override;
```

#### æ ‡é‡è¿ç®—å’Œå¹¿æ’­è¿ç®—
æ‰€æœ‰V1.43.0æ–°å¢çš„æ ‡é‡è¿ç®—å’Œå¹¿æ’­è¿ç®—æ–¹æ³•éƒ½æš‚æ—¶æœªå®ç°

### ä½¿ç”¨ç¤ºä¾‹

```cpp
try {
    auto cuda_backend = BackendManager::get_cuda_backend();

    // å°è¯•ä½¿ç”¨æœªå®ç°çš„æ–¹æ³•
    Tensor input = /* æŸä¸ªå¼ é‡ */;
    Tensor result = cuda_backend->reshape(input, {2, 12});  // æŠ›å‡ºNotImplementedError

} catch (const NotImplementedError& e) {
    std::cout << "Method not implemented: " << e.what() << std::endl;
    // å¯ä»¥å›é€€åˆ°CPUåç«¯æˆ–å…¶ä»–å®ç°
}
```

## å·²å®ç°çš„æ ¸å¿ƒæ¥å£

### è·¨åç«¯è½¬æ¢æ¥å£

#### `Tensor from_cpu(const Tensor& tensor) const override`

ä»CPUè½¬æ¢å¼ é‡åˆ°CUDAè®¾å¤‡ï¼Œè‡ªåŠ¨å¤„ç†å†…å­˜å¸ƒå±€è½¬æ¢ã€‚

**å‚æ•°**ï¼š
- `tensor` - CPUè®¾å¤‡ä¸Šçš„å¼ é‡ï¼ˆè¡Œä¸»åºå­˜å‚¨ï¼‰

**è¿”å›å€¼**ï¼š
- `Tensor` - CUDAè®¾å¤‡ä¸Šçš„å¼ é‡ï¼ˆåˆ—ä¸»åºå­˜å‚¨ï¼‰

**ç‰¹æ€§**ï¼š
- **2DçŸ©é˜µè½¬æ¢**ï¼šè‡ªåŠ¨æ‰§è¡Œè¡Œä¸»åºâ†’åˆ—ä¸»åºè½¬æ¢
- **é2Då¼ é‡**ï¼šç›´æ¥å¤åˆ¶æ•°æ®
- **GPUå†…å­˜åˆ†é…**ï¼šè‡ªåŠ¨åœ¨GPUä¸Šåˆ†é…å†…å­˜

**æ€§èƒ½**ï¼šåŸºäºCUDAçš„é«˜æ•ˆå†…å­˜å¤åˆ¶

#### `Tensor to_cpu(const Tensor& tensor) const override`

ä»CUDAè®¾å¤‡è½¬æ¢å¼ é‡åˆ°CPUï¼Œè‡ªåŠ¨å¤„ç†å†…å­˜å¸ƒå±€è½¬æ¢ã€‚

**å‚æ•°**ï¼š
- `tensor` - CUDAè®¾å¤‡ä¸Šçš„å¼ é‡ï¼ˆåˆ—ä¸»åºå­˜å‚¨ï¼‰

**è¿”å›å€¼**ï¼š
- `Tensor` - CPUè®¾å¤‡ä¸Šçš„å¼ é‡ï¼ˆè¡Œä¸»åºå­˜å‚¨ï¼‰

**ç‰¹æ€§**ï¼š
- **2DçŸ©é˜µè½¬æ¢**ï¼šè‡ªåŠ¨æ‰§è¡Œåˆ—ä¸»åºâ†’è¡Œä¸»åºè½¬æ¢
- **é2Då¼ é‡**ï¼šç›´æ¥å¤åˆ¶æ•°æ®
- **åŒæ­¥æ“ä½œ**ï¼šç¡®ä¿GPUè®¡ç®—å®Œæˆåå†å¤åˆ¶

### åŸºç¡€å¼ é‡æ“ä½œæ¥å£

#### `void mm(Tensor& result, const Tensor& a, const Tensor& b) override`

é«˜æ€§èƒ½GPUçŸ©é˜µä¹˜æ³•ã€‚

**å‚æ•°**ï¼š
- `result` - ç»“æœå¼ é‡ï¼Œå½¢çŠ¶åº”ä¸º(M,N)
- `a` - è¾“å…¥å¼ é‡Aï¼Œå½¢çŠ¶åº”ä¸º(M,K)
- `b` - è¾“å…¥å¼ é‡Bï¼Œå½¢çŠ¶åº”ä¸º(K,N)

**å®ç°**ï¼š
```cpp
void CudaBackend::mm(Tensor& result, const Tensor& a, const Tensor& b) {
    const float* a_data = static_cast<const float*>(a.data_ptr());
    const float* b_data = static_cast<const float*>(b.data_ptr());
    float* result_data = static_cast<float*>(result.data_ptr());

    int32_t M = a.height();  // è¡Œæ•°
    int32_t K = a.width();   // åˆ—æ•°
    int32_t N = b.width();   // Bçš„åˆ—æ•°

    // cuBLASçŸ©é˜µä¹˜æ³•ï¼ˆåˆ—ä¸»åºå­˜å‚¨ï¼‰
    const float alpha = 1.0f;
    const float beta = 0.0f;

    CUBLAS_CHECK(cublasSgemm(
        cublas_handle_,
        CUBLAS_OP_N, CUBLAS_OP_N,  // æ— è½¬ç½®
        N, M, K,                   // ç»“æœç»´åº¦
        &alpha,
        b_data, N,                 // BçŸ©é˜µï¼Œleading dimension = N
        a_data, K,                 // AçŸ©é˜µï¼Œleading dimension = K
        &beta,
        result_data, N             // ç»“æœçŸ©é˜µï¼Œleading dimension = N
    ));
}
```

**æ€§èƒ½ç‰¹æ€§**ï¼š
- **GPUåŠ é€Ÿ**ï¼šåˆ©ç”¨å¤§è§„æ¨¡å¹¶è¡Œè®¡ç®—
- **cuBLASä¼˜åŒ–**ï¼šè‡ªåŠ¨é€‰æ‹©æœ€ä¼˜ç®—æ³•
- **é«˜ååé‡**ï¼šé€‚åˆå¤§æ‰¹é‡çŸ©é˜µè¿ç®—

#### `void fill(Tensor& dst, float value) override`

ç”¨æµ®ç‚¹æ•°å€¼å¡«å……GPUå¼ é‡ã€‚

**å‚æ•°**ï¼š
- `dst` - ç›®æ ‡å¼ é‡
- `value` - å¡«å……å€¼

**å®ç°**ï¼š
```cpp
void CudaBackend::fill(Tensor& dst, float value) {
    float* data = static_cast<float*>(dst.data_ptr());
    int64_t size = dst.numel();

    // ä½¿ç”¨CUDAæ ¸å‡½æ•°å¡«å……
    cuda_fill_kernel<<<blocks, threads>>>(data, value, size);
    CUDA_CHECK(cudaGetLastError());
    CUDA_CHECK(cudaDeviceSynchronize());
}
```

#### `void add(Tensor& result, const Tensor& a, const Tensor& b) override`

GPUå¼ é‡é€å…ƒç´ åŠ æ³•ã€‚

**å‚æ•°**ï¼š
- `result` - ç»“æœå¼ é‡
- `a` - ç¬¬ä¸€ä¸ªæ“ä½œæ•°å¼ é‡
- `b` - ç¬¬äºŒä¸ªæ“ä½œæ•°å¼ é‡

**ç‰¹æ€§**ï¼š
- **GPUå¹¶è¡Œ**ï¼šåˆ©ç”¨æ•°åƒä¸ªGPUæ ¸å¿ƒå¹¶è¡Œè®¡ç®—
- **å†…å­˜é«˜æ•ˆ**ï¼šå°±åœ°æ“ä½œï¼Œå‡å°‘å†…å­˜åˆ†é…

## ä½¿ç”¨ç¤ºä¾‹

### åŸºç¡€GPUæ“ä½œ

```cpp
#include "tech_renaissance.h"
using namespace tr;

void basic_cuda_operations() {
    try {
        // è·å–CUDAåç«¯å®ä¾‹
        auto cuda_backend = BackendManager::get_cuda_backend();
        auto cpu_backend = BackendManager::get_cpu_backend();

        // 1. åœ¨CPUä¸Šåˆ›å»ºéšæœºå¼ é‡
        Tensor cpu_a = cpu_backend->randn({1024, 2048}, 42);
        Tensor cpu_b = cpu_backend->randn({2048, 512}, 123);

        // 2. è½¬æ¢åˆ°CUDAï¼ˆè‡ªåŠ¨å†…å­˜å¸ƒå±€è½¬æ¢ï¼‰
        Tensor cuda_a = cuda_backend->from_cpu(cpu_a);
        Tensor cuda_b = cuda_backend->from_cpu(cpu_b);

        // 3. åˆ›å»ºç»“æœå¼ é‡
        Tensor cuda_result = Tensor::empty({1024, 512}, DType::FP32, tr::CUDA(0));

        // 4. GPUçŸ©é˜µä¹˜æ³•ï¼ˆé«˜æ€§èƒ½ï¼‰
        cuda_backend->mm(cuda_result, cuda_a, cuda_b);

        // 5. è½¬æ¢å›CPUéªŒè¯ç»“æœ
        Tensor cpu_result = cuda_backend->to_cpu(cuda_result);

        std::cout << "CUDA matrix multiplication completed!" << std::endl;

    } catch (const TRException& e) {
        std::cerr << "CUDA Backend error: " << e.what() << std::endl;
    }
}
```

### æ€§èƒ½åŸºå‡†æµ‹è¯•

```cpp
void cuda_performance_benchmark() {
    auto cuda_backend = BackendManager::get_cuda_backend();
    auto cpu_backend = BackendManager::get_cpu_backend();

    // æµ‹è¯•çŸ©é˜µå¤§å°
    const int M = 1024, K = 2048, N = 512;

    // åˆ›å»ºæµ‹è¯•æ•°æ®
    Tensor cpu_a = cpu_backend->randn({M, K});
    Tensor cpu_b = cpu_backend->randn({K, N});

    // è½¬æ¢åˆ°GPU
    Tensor cuda_a = cuda_backend->from_cpu(cpu_a);
    Tensor cuda_b = cuda_backend->from_cpu(cpu_b);
    Tensor cuda_result = Tensor::empty({M, N}, DType::FP32, tr::CUDA(0));

    // GPUæ€§èƒ½æµ‹è¯•
    auto start = std::chrono::high_resolution_clock::now();
    cuda_backend->mm(cuda_result, cuda_a, cuda_b);
    auto end = std::chrono::high_resolution_clock::now();

    auto duration = std::chrono::duration_cast<std::chrono::microseconds>(end - start);
    double gflops = (2.0 * M * K * N) / (duration.count() * 1e6) / 1e9;

    std::cout << "CUDA Performance:" << std::endl;
    std::cout << "  Matrix size: " << M << "x" << K << " x " << K << "x" << N << std::endl;
    std::cout << "  Execution time: " << duration.count() << " Î¼s" << std::endl;
    std::cout << "  Performance: " << gflops << " GFLOPS" << std::endl;
}
```

### ğŸ†• V1.43.0æœªå®ç°æ–¹æ³•å¤„ç†

```cpp
void handle_not_implemented_methods() {
    auto cuda_backend = BackendManager::get_cuda_backend();
    auto cpu_backend = BackendManager::get_cpu_backend();

    try {
        // å°è¯•ä½¿ç”¨CUDAåç«¯çš„æ–°æ–¹æ³•
        Tensor input = cpu_backend->randn({2, 3, 4});
        Tensor result = cuda_backend->reshape(input, {2, 12});

    } catch (const NotImplementedError& e) {
        std::cout << "Method not implemented in CUDA backend: " << e.what() << std::endl;

        // å›é€€ç­–ç•¥ï¼šä½¿ç”¨CPUåç«¯
        std::cout << "Falling back to CPU backend..." << std::endl;
        Tensor result = cpu_backend->reshape(input, {2, 12});

        // æˆ–è€…å°†ç»“æœè½¬æ¢åˆ°CUDA
        Tensor cuda_result = cuda_backend->from_cpu(result);
    }
}
```

## æ€§èƒ½ç‰¹æ€§

### è®¡ç®—æ€§èƒ½

- **çŸ©é˜µä¹˜æ³•**ï¼šåŸºäºcuBLASä¼˜åŒ–ï¼Œæ€§èƒ½æ¥è¿‘ç¡¬ä»¶æé™
- **å¤§è§„æ¨¡å¹¶è¡Œ**ï¼šåˆ©ç”¨GPUæ•°åƒä¸ªæ ¸å¿ƒå¹¶è¡Œè®¡ç®—
- **é«˜å†…å­˜å¸¦å®½**ï¼šå……åˆ†åˆ©ç”¨GPUå†…å­˜å¸¦å®½ä¼˜åŠ¿

### å†…å­˜ç®¡ç†

- **GPUå†…å­˜æ± **ï¼šå‡å°‘GPUå†…å­˜åˆ†é…å¼€é”€
- **å¼‚æ­¥ä¼ è¾“**ï¼šæ”¯æŒCPU-GPUå¼‚æ­¥æ•°æ®ä¼ è¾“
- **æ™ºèƒ½åŒæ­¥**ï¼šè‡ªåŠ¨ç®¡ç†CUDAäº‹ä»¶å’ŒæµåŒæ­¥

### å®æµ‹æ€§èƒ½ï¼ˆV1.43.0ï¼‰

| è¿ç®—ç±»å‹ | CUDAæ€§èƒ½ | åŠ é€Ÿæ¯”ï¼ˆvs CPUï¼‰ |
|---------|-----------|----------------|
| çŸ©é˜µä¹˜æ³• | 6602.77 GFLOPS | 52x |
| 3x3å·ç§¯ | 11917.52 GFLOPS | 35x |
| 1x1å·ç§¯ | 6076.90 GFLOPS | 37x |
| 3x3è½¬ç½®å·ç§¯ | 12789.55 GFLOPS | 66x |

## é”™è¯¯å¤„ç†

### CUDAç‰¹å®šé”™è¯¯

```cpp
try {
    auto cuda_backend = BackendManager::get_cuda_backend(999);  // æ— æ•ˆè®¾å¤‡ID

} catch (const TRException& e) {
    std::cerr << "CUDA initialization error: " << e.what() << std::endl;
}

try {
    auto cuda_backend = BackendManager::get_cuda_backend();
    // å°è¯•åœ¨CUDAåç«¯ä¸Šä½¿ç”¨æœªå®ç°çš„æ–¹æ³•
    Tensor result = cuda_backend->some_new_method(input);

} catch (const NotImplementedError& e) {
    std::cout << "Method not implemented: " << e.what() << std::endl;
}
```

### å¸¸è§CUDAé”™è¯¯

- **è®¾å¤‡ä¸å­˜åœ¨**ï¼šæŒ‡å®šçš„GPUè®¾å¤‡IDæ— æ•ˆ
- **å†…å­˜ä¸è¶³**ï¼šGPUå†…å­˜ä¸è¶³ä»¥åˆ†é…å¼ é‡
- **è®¡ç®—é”™è¯¯**ï¼šCUDAè®¡ç®—å†…æ ¸æ‰§è¡Œå¤±è´¥
- **æ–¹æ³•æœªå®ç°**ï¼šV1.43.0æ–°å¢æ–¹æ³•æš‚æœªåœ¨CUDAåç«¯å®ç°

## æœ€ä½³å®è·µ

1. **è®¾å¤‡æ£€æŸ¥**ï¼šåœ¨ä½¿ç”¨CUDAå‰æ£€æŸ¥GPUå¯ç”¨æ€§
2. **å†…å­˜ç®¡ç†**ï¼šåŠæ—¶é‡Šæ”¾ä¸éœ€è¦çš„GPUå†…å­˜
3. **å¼‚æ­¥æ“ä½œ**ï¼šåˆ©ç”¨CUDAæµæé«˜å¹¶å‘æ€§èƒ½
4. **é”™è¯¯å¤„ç†**ï¼šå¦¥å–„å¤„ç†CUDAç›¸å…³å¼‚å¸¸
5. **æ€§èƒ½ä¼˜åŒ–**ï¼šæ‰¹é‡æ“ä½œå‡å°‘GPU-CPUä¼ è¾“å¼€é”€
6. **ğŸ†• æ–¹æ³•å›é€€**ï¼šå¯¹äºæœªå®ç°çš„æ–¹æ³•ï¼Œè€ƒè™‘å›é€€åˆ°CPUåç«¯

## æœªæ¥å¼€å‘è®¡åˆ’

### V1.44.0 CUDAåç«¯æ‰©å±•è®¡åˆ’

1. **å®ç°V1.43.0æ–°å¢æ–¹æ³•**ï¼š
   - å½¢çŠ¶å˜æ¢æ“ä½œï¼šreshapeç³»åˆ—æ–¹æ³•
   - æ¿€æ´»å‡½æ•°ï¼štanhã€dtanhç³»åˆ—æ–¹æ³•
   - æŸå¤±å‡½æ•°ï¼šcrossentropyå®ç°
   - One-hotç¼–ç ï¼šone_hotç³»åˆ—æ–¹æ³•
   - æ ‡é‡è¿ç®—ï¼šminusã€macã€clampç³»åˆ—æ–¹æ³•
   - å¹¿æ’­è¿ç®—ï¼šadd_broadcastã€mul_broadcastç³»åˆ—æ–¹æ³•

2. **æ€§èƒ½ä¼˜åŒ–**ï¼š
   - CUDAæ ¸å‡½æ•°ä¼˜åŒ–
   - å†…å­˜è®¿é—®æ¨¡å¼ä¼˜åŒ–
   - å¤šGPUæ”¯æŒ

3. **é«˜çº§ç‰¹æ€§**ï¼š
   - æ··åˆç²¾åº¦è®¡ç®—
   - åŠ¨æ€å½¢çŠ¶æ”¯æŒ
   - è‡ªå®šä¹‰CUDAæ ¸å‡½æ•°

## ç‰ˆæœ¬ä¿¡æ¯

- **ç‰ˆæœ¬**: V1.43.0
- **æ›´æ–°æ—¥æœŸ**: 2025-11-16
- **ä½œè€…**: æŠ€æœ¯è§‰é†’å›¢é˜Ÿ
- **ä¸»è¦æ›´æ–°**:
  - ğŸ”§ ä¿®å¤æ„é€ å‡½æ•°Backendå®ä¾‹åŒ–é—®é¢˜
  - ğŸ†• ç»§æ‰¿BackendåŸºç±»çš„å®å®šä¹‰ç³»ç»Ÿ
  - ğŸ†• ç»Ÿä¸€çš„NotImplementedErrorå¼‚å¸¸æ ¼å¼
  - âœ… 100%å‘åå…¼å®¹ï¼Œç°æœ‰ä»£ç æ— éœ€ä¿®æ”¹
  - âœ… å®Œå–„çš„CUDAé”™è¯¯å¤„ç†å’Œå¼‚å¸¸ç®¡ç†
  - âœ… æ”¯æŒV1.43.0æ–°å¢æ¥å£çš„å¼‚å¸¸å¤„ç†æœºåˆ¶