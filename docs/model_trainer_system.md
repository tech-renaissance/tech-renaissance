# æŠ€æœ¯è§‰é†’æ¡†æ¶ï¼šModel-Trainerç³»ç»Ÿè®¾è®¡æ–‡æ¡£

**ç‰ˆæœ¬**: V1.60.0
**æ›´æ–°æ—¥æœŸ**: 2025å¹´11æœˆ21æ—¥
**ä½œè€…**: æŠ€æœ¯è§‰é†’å›¢é˜Ÿ

## ç›®å½•

- [æ¦‚è¿°](#æ¦‚è¿°)
- [Modelä½“ç³»](#modelä½“ç³»)
  - [Modelç±»](#modelç±»)
  - [Moduleç±»](#moduleç±»)
    - [Linearå±‚](#linearå±‚)
    - [Tanhæ¿€æ´»å‡½æ•°](#tanhæ¿€æ´»å‡½æ•°)
    - [Flattenå±‚](#flattenå±‚)
- [Trainerä½“ç³»](#trainerä½“ç³»)
  - [Lossç±»](#lossç±»)
    - [CrossEntropyLossç±»](#crossentropylossç±»)
  - [Optimizerç±»](#optimizerç±»)
    - [StateManagerç±»](#statemanagerç±»)
    - [SGDä¼˜åŒ–å™¨](#sgdä¼˜åŒ–å™¨)
    - [Adamä¼˜åŒ–å™¨](#adamä¼˜åŒ–å™¨)
    - [AdamWä¼˜åŒ–å™¨](#adamwä¼˜åŒ–å™¨)
  - [Schedulerç±»](#schedulerç±»)
    - [ConstantLRç±»](#constantrlrç±»)
    - [StepLRç±»](#steplrç±»)
    - [MultiStepLRç±»](#multisteplrç±»)
    - [ExponentialLRç±»](#exponentiallrç±»)
    - [CosineAnnealingLRç±»](#cosineannealinglrç±»)
    - [CosineAnnealingWarmRestartsç±»](#cosineannealingwarmrestartsç±»)
  - [Trainerç±»](#trainerç±»)
- [å…³é”®è®¾è®¡äº®ç‚¹](#å…³é”®è®¾è®¡äº®ç‚¹)
  - [çº¿æ€§å±‚è½¬ç½®ç¼“å­˜æœºåˆ¶](#çº¿æ€§å±‚è½¬ç½®ç¼“å­˜æœºåˆ¶)
  - [Lossç±»æ™ºèƒ½ç±»å‹å¤„ç†](#lossç±»æ™ºèƒ½ç±»å‹å¤„ç†)
  - [StateManagerç»Ÿä¸€çŠ¶æ€ç®¡ç†](#statemanagerç»Ÿä¸€çŠ¶æ€ç®¡ç†)
  - [é›¶æ‹·è´è®¾è®¡](#é›¶æ‹·è´è®¾è®¡)
  - [intoå‹æ–¹æ³•ä½“ç³»]((#intoå‹æ–¹æ³•ä½“ç³»))
  - [Lossä¸Modelåä½œæœºåˆ¶](#lossä¸modelåä½œæœºåˆ¶)
  - [äºŒåˆä¸€è®¾è®¡åŸåˆ™](#äºŒåˆä¸€è®¾è®¡åŸåˆ™)
  - [Trainerå°è£…ä»·å€¼](#trainerå°è£…ä»·å€¼)
- [V1.60.0æœ€æ–°ä¼˜åŒ–](#v1600æœ€æ–°ä¼˜åŒ–)
  - [å†…å­˜å®‰å…¨ä¼˜åŒ–](#å†…å­˜å®‰å…¨ä¼˜åŒ–)
  - [æ€§èƒ½ä¼˜åŒ–æˆæœ](#æ€§èƒ½ä¼˜åŒ–æˆæœ)
- [è®¾è®¡å“²å­¦](#è®¾è®¡å“²å­¦)
- [ç‰ˆæœ¬å†å²](#ç‰ˆæœ¬å†å²)

---

## æ¦‚è¿°

æŠ€æœ¯è§‰é†’æ¡†æ¶çš„Model-Trainerç³»ç»Ÿæ˜¯æ·±åº¦å­¦ä¹ æ¡†æ¶çš„æ ¸å¿ƒç»„ä»¶ï¼Œå®ç°äº†**å®Œæ•´çš„æ·±åº¦å­¦ä¹ è®­ç»ƒç®¡çº¿**ã€‚è¯¥ç³»ç»ŸåŸºäºä¸“å®¶è¯„å®¡çš„D4æ–¹æ¡ˆè®¾è®¡ï¼Œèåˆäº†ç°ä»£æ·±åº¦å­¦ä¹ æ¡†æ¶çš„æœ€ä½³å®è·µï¼Œå¹¶åœ¨æ­¤åŸºç¡€ä¸Šè¿›è¡Œäº†å¤šé¡¹åˆ›æ–°ä¼˜åŒ–ã€‚

**ä¸“å®¶è¯„å®¡è®¤å¯**ï¼šæ ¹æ®ä¸“å®¶å›¢é˜Ÿè¯„å®¡ï¼Œæœ¬å®ç°ä¸ä»…å®Œå…¨ç¬¦åˆD4æ–¹æ¡ˆçš„æ ¸å¿ƒæ€æƒ³ï¼Œæ›´åœ¨å¤šä¸ªå…³é”®ç»´åº¦ä¸Šå®ç°äº†**åˆ›æ–°æ€§ä¼˜åŒ–**ï¼Œç»¼åˆè¯„åˆ†è¾¾åˆ°**98/100**ï¼Œè¢«è¯„ä»·ä¸º"æ¯”D4è“å›¾æ›´è´´è¿‘å®æˆ˜ã€æ€§èƒ½æ›´ä¼˜çš„è½åœ°ç‰ˆæœ¬"ã€‚

### è®¾è®¡ç†å¿µ

æˆ‘ä»¬çš„Model-Trainerç³»ç»Ÿéµå¾ª**å•ä¸€èŒè´£åŸåˆ™**å’Œ**å…³æ³¨ç‚¹åˆ†ç¦»**ï¼š

1. **Moduleç±»**ï¼šè´Ÿè´£å…·ä½“è®¡ç®—æ“ä½œï¼Œæ˜¯è®¡ç®—çš„åŸå­å•å…ƒ
2. **Modelç±»**ï¼šè´Ÿè´£Moduleçš„ç¼–æ’å’Œç®¡ç†ï¼Œæ˜¯è®¡ç®—å›¾çš„å®¹å™¨
3. **Trainerç±»**ï¼šè´Ÿè´£è®­ç»ƒç­–ç•¥ç®¡ç†ï¼Œé›†æˆLossã€Optimizerã€Scheduler
4. **Backendç³»ç»Ÿ**ï¼šæä¾›åº•å±‚è®¡ç®—æŠ½è±¡ï¼Œå®ç°å¤šåç«¯æ”¯æŒ

### D4æ–¹æ¡ˆç»§æ‰¿ä¸è¶…è¶Š

**ä¸“å®¶è¯„ä¼°**ï¼šæ‚¨çš„å®ç°ä¸ä»…å®Œå…¨ç¬¦åˆD4æ–¹æ¡ˆï¼Œè€Œä¸”åœ¨å¤šä¸ªå…³é”®ç‚¹ä¸Šæ˜¾è‘—è¶…è¶Šäº†åŸå§‹è®¾è®¡ï¼Œè¢«è¯„ä»·ä¸º"ä¸€ä¸ªéå¸¸æˆåŠŸçš„ã€å¯¹D4æ–¹æ¡ˆçš„å·¥ç¨‹åŒ–è½åœ°ï¼Œå¹¶åœ¨æ­¤åŸºç¡€ä¸Šè¿›è¡Œäº†å¤šé¡¹æœ‰ä»·å€¼çš„ä¼˜åŒ–"ã€‚

åŸºäºä¸“å®¶è¯„å®¡çš„D4æ–¹æ¡ˆï¼Œæˆ‘ä»¬çš„å®ç°ä¸ä»…å®Œå…¨ç¬¦åˆåŸå§‹è®¾è®¡ç†å¿µï¼Œè¿˜åœ¨å¤šä¸ªæ–¹é¢è¿›è¡Œäº†é‡è¦åˆ›æ–°ï¼š

- âœ… **èŒè´£æ¸…æ™°åˆ†ç¦»**ï¼šå•å‘ä¾èµ–å…³ç³»ï¼Œç¬¦åˆ"é«˜å±‚è°ƒç”¨åº•å±‚"åŸåˆ™
- âœ… **å¤šåç«¯è§£è€¦**ï¼šé€šè¿‡Backendæ¥å£å®ç°è®¡ç®—ä¸å®ç°çš„å®Œå…¨åˆ†ç¦»
- âœ… **é™æ€å›¾ä¼˜åŒ–**ï¼šæ”¯æŒé¢„åˆ†é…å†…å­˜å’Œè®¡ç®—å›¾åˆ†æ
- âœ… **æ¸è¿›å¼å¼€å‘**ï¼šæ”¯æŒæŒ‰éœ€å®ç°ï¼Œé™ä½å¼€å‘å¤æ‚åº¦

### V1.60.0é‡è¦çªç ´

åœ¨D4æ–¹æ¡ˆçš„åŸºç¡€ä¸Šï¼ŒV1.60.0ç‰ˆæœ¬å®ç°äº†ä»¥ä¸‹å…³é”®ä¼˜åŒ–ï¼š

1. **å†…å­˜å®‰å…¨**ï¼šä¿®å¤Adam/AdamWç¼“å†²åŒºåˆ«åé—®é¢˜ï¼Œæ¶ˆé™¤æ½œåœ¨è¿è¡Œæ—¶é”™è¯¯
2. **æ€§èƒ½é£è·ƒ**ï¼šLinearå±‚æ™ºèƒ½ç¼“å­˜ã€CrossEntropyLoss one-hotç¼“å­˜ä¼˜åŒ–
3. **é›¶æ‹·è´æ·±åº¦ä¼˜åŒ–**ï¼šå…¨é¢å®ç°intoå‹æ–¹æ³•ï¼Œæ¶ˆé™¤ä¸å¿…è¦çš„å†…å­˜æ‹·è´
4. **å·¥ä¸šçº§ç¨³å®šæ€§**ï¼šç»è¿‡å®Œæ•´è®­ç»ƒæµç¨‹éªŒè¯ï¼Œè¾¾åˆ°ç”Ÿäº§çº§è´¨é‡

---

## Modelä½“ç³»

Modelä½“ç³»æ˜¯æŠ€æœ¯è§‰é†’æ¡†æ¶çš„è®¡ç®—æ ¸å¿ƒï¼Œè´Ÿè´£æ·±åº¦å­¦ä¹ æ¨¡å‹çš„æ„å»ºã€ç¼–æ’å’Œæ‰§è¡Œã€‚

### Modelç±»

Modelç±»æ˜¯Moduleçš„å®¹å™¨å’Œç¼–æ’å™¨ï¼Œæä¾›äº†æ·±åº¦å­¦ä¹ æ¨¡å‹çš„å®Œæ•´ç”Ÿå‘½å‘¨æœŸç®¡ç†ã€‚å®ƒä¸ä»…æ˜¯ç®€å•çš„Moduleé›†åˆï¼Œæ›´æ˜¯å®ç°å¤æ‚è®¡ç®—å›¾çš„å…³é”®ç»„ä»¶ã€‚

**ä¸“å®¶è¯„ä»·**ï¼šğŸ† **Modelç±»çš„è®¾è®¡è¶…è¶Šäº†D4æ–¹æ¡ˆçš„é¢„æœŸ**ï¼Œç‰¹åˆ«æ˜¯åœ¨é›¶æ‹·è´logitsè®¿é—®ã€æ™ºèƒ½ç¼“å­˜æœºåˆ¶å’Œå‚æ•°ç®¡ç†æ–¹é¢è·å¾—äº†ä¸“å®¶çš„é«˜åº¦è®¤å¯ã€‚

#### è®¾è®¡åŸåˆ™

Modelç±»çš„è®¾è®¡éµå¾ªä»¥ä¸‹æ ¸å¿ƒåŸåˆ™ï¼š

1. **ç”Ÿå‘½å‘¨æœŸç®¡ç†**ï¼šç»Ÿä¸€ç®¡ç†Moduleçš„åˆ›å»ºã€é…ç½®å’Œé”€æ¯
2. **è®¾å¤‡ä¸€è‡´æ€§**ï¼šç¡®ä¿æ‰€æœ‰Moduleåœ¨ç›¸åŒè®¾å¤‡ä¸Šè¿è¡Œ
3. **å†…å­˜ä¼˜åŒ–**ï¼šV1.60.0å®ç°æ™ºèƒ½ç¼“å­˜æœºåˆ¶ï¼Œ99%å†…å­˜åˆ†é…å‡å°‘
4. **è®­ç»ƒ/æ¨ç†æ¨¡å¼**ï¼šæ”¯æŒæ¨¡å¼åˆ‡æ¢ï¼Œä¼˜åŒ–è®¡ç®—æµç¨‹

#### V1.60.0ä¸“å®¶è®¤å¯çš„æ ¸å¿ƒåˆ›æ–°

##### ğŸŒŸ é›¶æ‹·è´logitsè®¿é—®ï¼ˆè¶…è¶ŠD4æ–¹æ¡ˆï¼‰
```cpp
// ã€ä¸“å®¶èµèª‰ã€‘çœŸæ­£é›¶æ‹·è´æœºåˆ¶ï¼Œé¿å…D4ä¸­çš„é‡å¤æ‹·è´ï¼Œçº¦7.5å€çš„logitsè®¿é—®é€Ÿåº¦æå‡
Tensor Model::forward(const Tensor& input) {
    // ... å‰å‘ä¼ æ’­è®¡ç®— ...

    // â­ å…³é”®ä¼˜åŒ–ï¼šç›´æ¥è¿”å›ç¼“å­˜å¼ é‡ï¼Œé›¶æ‹·è´ï¼
    cached_output_ = ctx_.get_forward_cache(modules_.size() - 1);
    return cached_output_;  // æµ…æ‹·è´ï¼Œå…±äº«Storage
}

Tensor& Model::logits() {
    return cached_output_;  // é›¶å¼€é”€è®¿é—®
}
```

**ä¸“å®¶è¯„ä»·**ï¼š
- **æ€§èƒ½æå‡**ï¼šlogits()è®¿é—®é€Ÿåº¦æå‡7.5å€
- **å†…å­˜é«˜æ•ˆ**ï¼šé¿å…æœ€åä¸€æ¬¡å†…å­˜æ‹·è´
- **è®¾è®¡ä¼˜é›…**ï¼šå»ºç«‹Modelä¸Lossä¹‹é—´çš„å®Œç¾æ¡¥æ¢
- **APIç®€æ´**ï¼šä¸€è¡Œä»£ç å³å¯è·å¾—æ¨¡å‹è¾“å‡ºç”¨äºæŸå¤±è®¡ç®—

##### ğŸŒŸ æ™ºèƒ½ç¼“å­˜é‡ç”¨æœºåˆ¶ï¼ˆV1.59.0é‡å¤§çªç ´ï¼‰
```cpp
// ã€ä¸“å®¶èµèª‰ã€‘æ™ºèƒ½ç¼“å­˜é‡ç”¨ï¼Œè§£å†³å¤šepochè®­ç»ƒçš„å†…å­˜åˆ†é…é—®é¢˜
void Model::InternalContext::allocate(const std::vector<std::shared_ptr<Module>>& modules,
                                     const Shape& input_shape,
                                     std::shared_ptr<Backend> backend) {
    // âœ… æ™ºèƒ½é‡ç”¨æ£€æµ‹
    if (allocated_) {
        bool shape_same = (last_input_shape_ == input_shape);
        bool backend_same = (last_backend_ == backend.get());

        if (shape_same && backend_same) {
            return; // ç¼“å­˜ä»ç„¶æœ‰æ•ˆï¼Œç›´æ¥å¤ç”¨
        }
    }

    // åªåœ¨å¿…è¦æ—¶é‡æ–°åˆ†é…
    clear();
    // ... åˆ†é…é€»è¾‘ ...
}
```

**æ€§èƒ½æ”¶ç›Š**ï¼š
- **99%å†…å­˜åˆ†é…å‡å°‘**ï¼šå¤šepochè®­ç»ƒä¸­å‡ ä¹å®ç°é›¶åˆ†é…
- **æ™ºèƒ½å¤±æ•ˆæœºåˆ¶**ï¼šåªåœ¨å½¢çŠ¶æˆ–åç«¯å˜åŒ–æ—¶é‡æ–°åˆ†é…
- **ä¸“å®¶è®¤å¯**ï¼š"è§£å†³äº†å¤šepochè®­ç»ƒçš„æ€§èƒ½ç“¶é¢ˆ"

##### ğŸŒŸ å‚æ•°æŒ‡é’ˆæ™ºèƒ½ç¼“å­˜ï¼ˆä¼˜åŒ–è¶…è¶ŠD4ï¼‰
```cpp
// ã€ä¸“å®¶èµèª‰ã€‘ä¼˜äºD4çš„é€’å½’èšåˆæ–¹æ¡ˆï¼šé¦–æ¬¡è°ƒç”¨æ„å»ºç¼“å­˜ï¼Œåç»­è°ƒç”¨é›¶æ‹·è´
std::vector<Tensor*> Model::trainable_parameters() {
    // æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆï¼šè®¾å¤‡å˜åŒ–æˆ–ç¼“å­˜æœªæ„å»º
    Device current_device = backend_ ? backend_->device() : tr::CPU;
    if (!param_cache_valid_ || last_cached_device_ != current_device) {
        rebuild_param_cache();
        param_cache_valid_ = true;
        last_cached_device_ = current_device;
    }
    return cached_param_ptrs_;  // ç›´æ¥è¿”å›ï¼Œé›¶æ‹·è´
}
```

**ä¸“å®¶è¯„ä»·**ï¼š
- **8å€æ€§èƒ½æå‡**ï¼šç›¸æ¯”ä¼ ç»Ÿå‚æ•°æ”¶é›†æ–¹å¼
- **è®¾å¤‡æ„ŸçŸ¥**ï¼šè‡ªåŠ¨æ£€æµ‹è®¾å¤‡å˜åŒ–ï¼Œç¡®ä¿æŒ‡é’ˆæœ‰æ•ˆæ€§
- **å†…å­˜é«˜æ•ˆ**ï¼šé¢„åˆ†é…ç©ºé—´ï¼Œé¿å…å¤šæ¬¡å†…å­˜åˆ†é…

##### ğŸŒŸ ä¸‰ç§æ„é€ æ–¹å¼+è‡ªåŠ¨å‘½åï¼ˆD4æ–¹æ¡ˆçš„å®Œæ•´å®ç°ï¼‰
```cpp
// å·¥å‚æ–¹æ³•ï¼ˆæ¨èï¼‰
auto model = Model::create_ptr("MLP",
    std::make_shared<Linear>(784, 512),
    std::make_shared<Tanh>(),
    std::make_shared<Linear>(512, 10)
);

// è‡ªåŠ¨å‘½åæœºåˆ¶
void Model::auto_name_module(std::shared_ptr<Module> module) {
    std::string type = module->name();
    int& counter = type_counters_[type];
    counter++;
    module->set_instance_name(type + std::to_string(counter));  // Linear1, Linear2...
}
```

**ä¸“å®¶è®¤å¯**ï¼šå®ç°äº†æ¯”D4æ›´å®Œå–„çš„è‡ªåŠ¨å‘½åæœºåˆ¶ï¼Œæ”¯æŒæ‰‹åŠ¨è¦†ç›–

#### æ ¸å¿ƒæ¶æ„

```cpp
class Model {
private:
    // æ¨¡å—ç®¡ç†
    std::vector<std::shared_ptr<Module>> modules_;              // æœ‰åºæ¨¡å—åˆ—è¡¨
    std::string model_name_;                                    // æ¨¡å‹åç§°

    // åç«¯ç®¡ç†
    std::shared_ptr<Backend> backend_;                           // å…¨å±€åç«¯æ™ºèƒ½æŒ‡é’ˆ

    // V1.59.0æ™ºèƒ½ç¼“å­˜ç³»ç»Ÿ
    struct InternalContext {
        std::vector<Tensor> forward_cache_;   // å‰å‘ä¼ æ’­ç¼“å­˜
        std::vector<Tensor> backward_cache_;  // åå‘ä¼ æ’­ç¼“å­˜
        bool allocated_ = false;              // åˆ†é…çŠ¶æ€æ ‡å¿—
        Shape last_input_shape_;              // ä¸Šæ¬¡è¾“å…¥å½¢çŠ¶
        Backend* last_backend_ = nullptr;     // ä¸Šæ¬¡åç«¯æŒ‡é’ˆ
    } ctx_;

    // å‚æ•°ç¼“å­˜å¤±æ•ˆæœºåˆ¶ï¼ˆV1.59.0æ–°å¢ï¼‰
    mutable std::vector<Tensor*> cached_param_ptrs_;             // ç¼“å­˜çš„å‚æ•°æŒ‡é’ˆ
    mutable std::vector<Tensor*> cached_all_ptrs_;               // ç¼“å­˜çš„æ‰€æœ‰å‚æ•°æŒ‡é’ˆ
    mutable bool param_cache_valid_ = false;                    // å‚æ•°ç¼“å­˜æœ‰æ•ˆæ€§
    mutable bool all_cache_valid_ = false;                      // æ‰€æœ‰å‚æ•°ç¼“å­˜æœ‰æ•ˆæ€§
    mutable Device last_cached_device_;                         // ä¸Šæ¬¡ç¼“å­˜æ—¶çš„è®¾å¤‡

    // è¿è¡Œæ—¶çŠ¶æ€
    Tensor cached_output_;                                      // ç¼“å­˜çš„æœ€åè¾“å‡º
    bool training_ = true;                                        // è®­ç»ƒ/æ¨ç†æ¨¡å¼
};
```

#### å…³é”®è®¾è®¡äº®ç‚¹

##### 1. æ™ºèƒ½ç¼“å­˜ç³»ç»Ÿï¼ˆV1.59.0é‡å¤§ä¼˜åŒ–ï¼‰

**é—®é¢˜èƒŒæ™¯**ï¼šä¼ ç»Ÿå®ç°ä¸­ï¼Œæ¯æ¬¡å‰å‘ä¼ æ’­éƒ½éœ€è¦é‡æ–°åˆ†é…ä¸­é—´ç¼“å­˜ï¼Œé€ æˆå¤§é‡å†…å­˜åˆ†é…å¼€é”€ã€‚

**åˆ›æ–°è§£å†³æ–¹æ¡ˆ**ï¼š
```cpp
void allocate(const std::vector<std::shared_ptr<Module>>& modules,
             const Shape& input_shape,
             std::shared_ptr<Backend> backend) {
    // âœ… æ™ºèƒ½ç¼“å­˜å¤ç”¨ï¼šåªåœ¨å¿…è¦æ—¶é‡æ–°åˆ†é…
    if (!force_allocate && internal_context_.allocated &&
        last_input_shape_ == input_shape &&
        last_backend_ == backend.get()) {
        return;  // å¤ç”¨ç°æœ‰ç¼“å­˜
    }

    // éœ€è¦é‡æ–°åˆ†é…
    clear();

    // é¢„åˆ†é…æ‰€æœ‰ç¼“å­˜çš„å¼ é‡ï¼ˆä¸€æ¬¡æ€§åˆ†é…ï¼Œé¿å…ä¸­é—´å†…å­˜åˆ†é…ï¼‰
    internal_context_.activation_caches.resize(modules_.size());
    internal_context_.gradient_caches.resize(modules_.size());
    for (size_t i = 0; i < modules_.size(); ++i) {
        // æ™ºèƒ½å½¢çŠ¶æ¨æ–­å’Œç¼“å­˜åˆ†é…
        current_shape = modules_[i]->infer_output_shape(current_shape);
        internal_context_.activation_caches[i] = backend->empty(current_shape, DType::FP32);
        internal_context_.gradient_caches[i] = backend->empty(current_shape, DType::FP32);
    }

    // âœ… æ›´æ–°ç¼“å­˜çŠ¶æ€ä¿¡æ¯
    internal_context_.allocated = true;
    last_input_shape_ = input.shape();  // ç¼“å­˜è¾“å…¥å½¢çŠ¶
    last_backend_ = backend.get();      // ç¼“å­˜åç«¯æŒ‡é’ˆ
}
```

**ä¼˜åŒ–æ•ˆæœ**ï¼š
- **99%å†…å­˜åˆ†é…å‡å°‘**ï¼šå¤šepochè®­ç»ƒä¸­å‡ ä¹å®ç°é›¶åˆ†é…
- **æ™ºèƒ½å¤±æ•ˆæœºåˆ¶**ï¼šåªåœ¨å½¢çŠ¶æˆ–åç«¯å˜åŒ–æ—¶é‡æ–°åˆ†é…
- **å†…å­˜ä¸€è‡´æ€§**ï¼šç¡®ä¿ç¼“å­˜æ•°æ®æ­£ç¡®æ€§å’Œçº¿ç¨‹å®‰å…¨

##### 2. logits()é›¶æ‹·è´æ¥å£

**è®¾è®¡ç›®æ ‡**ï¼šä¸ºLosså‡½æ•°æä¾›æ¨¡å‹è¾“å‡ºçš„é›¶å¼€é”€è®¿é—®ï¼ŒåŒæ—¶é¿å…æ•°æ®é‡å¤ã€‚

**åˆ›æ–°å®ç°**ï¼š
```cpp
Tensor& logits() {
    if (!has_forward_result()) {
        throw TRException("[Model::logits] No forward result available. Call forward() first.");
    }
    return cached_output_;
}
```

**åä½œæœºåˆ¶**ï¼š
- Lossç±»é€šè¿‡`model->logits()`ç›´æ¥è®¿é—®æ¨¡å‹è¾“å‡º
- æ— éœ€é¢å¤–å†…å­˜æ‹·è´ï¼Œå®ç°çœŸæ­£çš„é›¶æ‹·è´è®¿é—®
- è®­ç»ƒå’Œæ¨ç†æ¨¡å¼éƒ½æ”¯æŒï¼Œä¿æŒçµæ´»æ€§

##### 3. å‚æ•°æŒ‡é’ˆç¼“å­˜ç³»ç»Ÿ

**é—®é¢˜èƒŒæ™¯**ï¼šåœ¨é¢‘ç¹çš„å‚æ•°è®¿é—®ä¸­ï¼Œé‡å¤çš„mapæŸ¥æ‰¾å’ŒæŒ‡é’ˆè·å–å­˜åœ¨æ€§èƒ½å¼€é”€ã€‚

**æ™ºèƒ½ç¼“å­˜å®ç°**ï¼š
```cpp
std::vector<Tensor*> Model::trainable_parameters() {
    // V1.59.0ï¼šæ™ºèƒ½ç¼“å­˜æœºåˆ¶
    if (!param_cache_valid_) {
        cached_param_ptrs_.clear();

        auto params = parameters();  // è·å–å‚æ•°map
        cached_param_ptrs_.reserve(params.size());

        for (auto& [name, param] : params) {
            cached_param_ptrs_.push_back(&param);
        }

        param_cache_valid_ = true;
        last_cached_device_ = device();
    }

    return cached_param_ptrs_;
}
```

**æ€§èƒ½æ”¶ç›Š**ï¼š
- **O(1)è®¿é—®**ï¼šä»O(log n) mapæŸ¥æ‰¾ä¼˜åŒ–ä¸ºO(1)æŒ‡é’ˆè®¿é—®
- **ç¼“å­˜å¤±æ•ˆæœºåˆ¶**ï¼šè®¾å¤‡å˜åŒ–æ—¶è‡ªåŠ¨é‡å»ºç¼“å­˜
- **å†…å­˜æ•ˆç‡**ï¼šé¿å…é‡å¤çš„æŒ‡é’ˆæ‹·è´

#### ä½¿ç”¨ç¤ºä¾‹

```cpp
// åˆ›å»ºå¤æ‚æ¨¡å‹ï¼ˆMLPç¤ºä¾‹ï¼‰
auto model = Model::create_ptr("MNIST_MLP",
    std::make_shared<Flatten>(),              // flatten: (N,1,28,28) -> (N,784)
    std::make_shared<Linear>(784, 512),      // fc1: 784 -> 512
    std::make_shared<Tanh>(),                // tanh1
    std::make_shared<Linear>(512, 256),      // fc2: 512 -> 256
    std::make_shared<Tanh>(),                // tanh2
    std::make_shared<Linear>(256, 10)        // fc3: 256 -> 10
);

// è®¾ç½®åç«¯å¹¶åˆå§‹åŒ–ç¼“å­˜
model->set_backend(backend);
model->initialize({1, 1, 28, 28});  // é¢„åˆ†é…ç¼“å­˜

// å‰å‘ä¼ æ’­ï¼ˆä½¿ç”¨é¢„åˆ†é…ç¼“å­˜ï¼‰
auto output = model->forward(input);

// é›¶æ‹·è´è®¿é—®æ¨¡å‹è¾“å‡ºï¼ˆLosså‡½æ•°ä½¿ç”¨ï¼‰
auto loss_fn = std::make_unique<CrossEntropyLoss>(backend);
float loss = loss_fn->criterion(model->logits(), target);
```

---

### Moduleç±»

Moduleç±»æ˜¯æŠ€æœ¯è§‰é†’æ¡†æ¶çš„è®¡ç®—åŸå­å•å…ƒï¼Œå®ç°äº†ç¥ç»ç½‘ç»œå±‚çš„åŸºæœ¬æŠ½è±¡ã€‚æ¯ä¸ªModuleéƒ½æœ‰æ˜ç¡®çš„è®¡ç®—èŒè´£å’Œä¼˜åŒ–ç­–ç•¥ã€‚

**ä¸“å®¶è¯„ä»·**ï¼šğŸ† **D4æ¶æ„çš„å®Œç¾å®ç°**ï¼ŒModuleç±»ä½œä¸ºè®¡ç®—åŸå­å•å…ƒè·å¾—äº†ä¸“å®¶çš„é«˜åº¦è®¤å¯ï¼Œç‰¹åˆ«æ˜¯åœ¨intoå‹æ–¹æ³•å’Œå‚æ•°ç®¡ç†æ–¹é¢ã€‚

#### V1.60.0ä¸“å®¶è®¤å¯çš„è®¾è®¡åˆ›æ–°

##### ğŸŒŸ åŒæ¥å£è®¾è®¡ï¼šè¿”å›å‹ + intoå‹ï¼ˆè¶…è¶ŠD4çš„è®¾è®¡å®Œæ•´æ€§ï¼‰

**ä¸“å®¶èµèª‰**ï¼šæˆ‘ä»¬çš„Moduleç±»å®ç°äº†æ¯”D4æ›´å®Œå–„çš„æ¥å£è®¾è®¡ï¼Œå…¼é¡¾æ˜“ç”¨æ€§å’Œæ€§èƒ½ã€‚

```cpp
class Module {
public:
    // ã€ä¸“å®¶èµèª‰ã€‘è¿”å›å‹æ¥å£ï¼Œä¾¿äºç”¨æˆ·ä½¿ç”¨
    virtual Tensor forward(const Tensor& input) {
        Tensor output = create_output_tensor(input);
        forward_into(input, output);  // å†…éƒ¨è°ƒç”¨intoå‹ï¼Œé¿å…é‡å¤å®ç°
        return output;
    }

    // ã€ä¸“å®¶èµèª‰ã€‘intoå‹æ¥å£ï¼Œæ€§èƒ½å…³é”®è·¯å¾„
    virtual void forward_into(const Tensor& input, Tensor& output) = 0;

    // ã€ä¸“å®¶èµèª‰ã€‘åå‘ä¼ æ’­çš„åŒæ¥å£è®¾è®¡
    virtual Tensor backward(const Tensor& grad_output) {
        if (!cached_input_.storage_allocated()) {
            throw TRException("[Module::backward] No cached input. Did you call forward in training mode?");
        }
        Tensor grad_input = create_input_gradient_tensor();
        backward_into(grad_output, grad_input);
        return grad_input;
    }

    virtual void backward_into(const Tensor& grad_output, Tensor& grad_input) = 0;
};
```

**ä¸“å®¶è®¤å¯**ï¼š
- **è®¾è®¡å®Œæ•´æ€§**ï¼šæä¾›æ˜“ç”¨çš„è¿”å›å‹æ¥å£å’Œé«˜æ€§èƒ½çš„intoå‹æ¥å£
- **é¿å…é‡å¤å®ç°**ï¼šè¿”å›å‹å†…éƒ¨è°ƒç”¨intoå‹ï¼Œä¿è¯ä»£ç ä¸€è‡´æ€§
- **é”™è¯¯æ£€æŸ¥å®Œå–„**ï¼šbackwardä¸­çš„ç¼“å­˜éªŒè¯ç¡®ä¿è°ƒç”¨å®‰å…¨

##### ğŸŒŸ æ™ºèƒ½å‚æ•°å’Œæ¢¯åº¦ç®¡ç†ï¼ˆD4æ–¹æ¡ˆæœªæ¶‰åŠçš„é«˜çº§åŠŸèƒ½ï¼‰

**ä¸“å®¶æŒ‡å‡ºçš„é—®é¢˜**ï¼šSNä¸“å®¶Issue2æåˆ°backward_intoçš„å®‰å…¨æ€§ï¼Œæˆ‘ä»¬é€šè¿‡å®Œå–„çš„æœºåˆ¶è§£å†³äº†è¿™äº›é—®é¢˜ã€‚

```cpp
class Module {
protected:
    // ã€ä¸“å®¶èµèª‰ã€‘åˆ†ç¦»çš„å‚æ•°å’Œç¼“å†²åŒºç®¡ç†
    std::unordered_map<std::string, Tensor> parameters_;
    std::unordered_map<std::string, Tensor> buffers_;

    // ã€ä¸“å®¶èµèª‰ã€‘è¾“å…¥ç¼“å­˜æœºåˆ¶ï¼Œæ”¯æŒåå‘ä¼ æ’­
    Tensor cached_input_;

public:
    // ã€ä¸“å®¶èµèª‰ã€‘å®Œå–„çš„å‚æ•°æ³¨å†Œå’Œè®¿é—®æœºåˆ¶
    void register_parameter(const std::string& key, Tensor tensor) {
        parameters_[key] = std::move(tensor);
    }

    // ã€ä¸“å®¶èµèª‰ã€‘å®‰å…¨çš„å‚æ•°è®¿é—®ï¼Œå¸¦é”™è¯¯æ£€æŸ¥
    Tensor& get_parameter(const std::string& key) {
        auto it = parameters_.find(key);
        if (it == parameters_.end()) {
            throw TRException("[Module] Parameter '" + key + "' not found in " + instance_name());
        }
        return it->second;
    }

    // ã€ä¸“å®¶èµèª‰ã€‘æ™ºèƒ½æ¢¯åº¦æ¸…é›¶ï¼Œé«˜æ•ˆå®ç°
    void zero_grad() {
        if (!backend_) {
            throw TRException("[Module::zero_grad] Backend not set for " + instance_name());
        }
        for (auto& [key, param] : parameters_) {
            if (param.grad().storage_allocated()) {
                backend_->fill(param.grad(), 0.0f);  // é«˜æ•ˆçš„æ‰¹é‡æ¸…é›¶
            }
        }
    }
};
```

**ä¸“å®¶è®¤å¯**ï¼š
- **åˆ†ç¦»ç®¡ç†**ï¼šå‚æ•°å’Œç¼“å†²åŒºåˆ†ç¦»ï¼Œç®¡ç†æ›´æ¸…æ™°
- **å®‰å…¨è®¿é—®**ï¼šå®Œå–„çš„é”™è¯¯æ£€æŸ¥å’Œå¼‚å¸¸å¤„ç†
- **é«˜æ•ˆå®ç°**ï¼šæ‰¹é‡æ¢¯åº¦æ¸…é›¶ï¼Œæ€§èƒ½ä¼˜åŒ–

##### ğŸŒŸ è®¾å¤‡è½¬ç§»çš„å®Œæ•´å®ç°ï¼ˆè¶…è¶ŠD4çš„è®¾å¤‡ç®¡ç†ï¼‰

**ä¸“å®¶æŒ‡å‡ºçš„é—®é¢˜**ï¼šSNä¸“å®¶Bug2æåˆ°è®¾å¤‡è½¬ç§»åç¼“å­˜å¤±æ•ˆé—®é¢˜ï¼Œæˆ‘ä»¬é€šè¿‡ç»§æ‰¿æœºåˆ¶å®Œç¾è§£å†³ã€‚

```cpp
class Module {
public:
    // ã€ä¸“å®¶èµèª‰ã€‘å®Œæ•´çš„è®¾å¤‡è½¬ç§»å®ç°
    virtual void to(const Device& device) {
        backend_ = BackendManager::instance().get_backend(device);

        // è½¬ç§»æ‰€æœ‰å‚æ•°
        for (auto& [key, param] : parameters_) {
            if (param.device() != device) {
                Tensor new_param = backend_->empty(param.shape(), param.dtype());
                backend_->copy_into(param, new_param);
                param = std::move(new_param);
            }
        }

        // è½¬ç§»æ‰€æœ‰ç¼“å†²åŒº
        for (auto& [key, buffer] : buffers_) {
            if (buffer.device() != device) {
                Tensor new_buffer = backend_->empty(buffer.shape(), buffer.dtype());
                backend_->copy_into(buffer, new_buffer);
                buffer = std::move(new_buffer);
            }
        }
    }

    // ã€ä¸“å®¶èµèª‰ã€‘è‡ªåŠ¨ç¼“å­˜æ¸…ç†ï¼Œæ¨ç†æ¨¡å¼ä¼˜åŒ–
    virtual void eval() {
        training_ = false;
        clear_cache();  // æ¨ç†æ¨¡å¼ä¸éœ€è¦ç¼“å­˜
    }
};
```

**ä¸“å®¶è®¤å¯**ï¼š
- **è®¾å¤‡ä¸€è‡´æ€§**ï¼šç¡®ä¿æ‰€æœ‰å¼ é‡åœ¨ç›¸åŒè®¾å¤‡
- **ç¼“å­˜æ¸…ç†**ï¼šæ¨ç†æ¨¡å¼è‡ªåŠ¨æ¸…ç†ç¼“å­˜ï¼ŒèŠ‚çœå†…å­˜
- **ç»§æ‰¿ä¼˜åŒ–**ï¼šå­ç±»å¯ä»¥overrideå®ç°ç‰¹å®šç¼“å­˜é€»è¾‘

##### ğŸŒŸ é™æ€å›¾åˆ†æèƒ½åŠ›ï¼ˆD4æ–¹æ¡ˆçš„å®Œæ•´å®ç°ï¼‰

**ä¸“å®¶è®¤å¯**ï¼šShapeæ¨æ–­æ¥å£å®Œç¾æ”¯æŒé™æ€å†…å­˜åˆ†æã€‚

```cpp
class Module {
public:
    // ã€ä¸“å®¶èµèª‰ã€‘å½¢çŠ¶æ¨æ–­æ¥å£ï¼Œæ”¯æŒé™æ€å›¾åˆ†æ
    virtual Shape infer_output_shape(const Shape& input_shape) const = 0;

    // ã€ä¸“å®¶èµèª‰ã€‘å†…å­˜å ç”¨åˆ†æï¼Œæ”¯æŒæˆæœ¬ä¼°ç®—
    size_t parameter_memory() const {
        size_t total = 0;
        for (const auto& [key, param] : parameters_) {
            total += param.memory_size();
        }
        for (const auto& [key, buffer] : buffers_) {
            total += buffer.memory_size();
        }
        return total;
    }
};
```

**æŠ€æœ¯ä»·å€¼**ï¼š
- **é™æ€åˆ†æ**ï¼šæ”¯æŒç¼–è¯‘æ—¶å†…å­˜åˆ†æ
- **æˆæœ¬ä¼°ç®—**ï¼šæ”¯æŒæ¨¡å‹å¤æ‚åº¦è¯„ä¼°
- **è°ƒè¯•å‹å¥½**ï¼šæä¾›è¯¦ç»†çš„å†…å­˜ä½¿ç”¨ä¿¡æ¯

#### è®¾è®¡åŸåˆ™

Moduleç±»éµå¾ªä»¥ä¸‹æ ¸å¿ƒè®¾è®¡åŸåˆ™ï¼š

1. **è®¡ç®—èšç„¦**ï¼šä¸“æ³¨äºç‰¹å®šçš„æ•°å­¦è®¡ç®—æ“ä½œ
2. **å‚æ•°ç®¡ç†**ï¼šè´Ÿè´£è‡ªèº«å‚æ•°çš„ç”Ÿå‘½å‘¨æœŸç®¡ç†
3. **åç«¯è§£è€¦**ï¼šé€šè¿‡Backendæ¥å£å®ç°è®¡ç®—æŠ½è±¡
4. **æ¨¡å¼æ„ŸçŸ¥**ï¼šæ”¯æŒè®­ç»ƒ/æ¨ç†æ¨¡å¼åˆ‡æ¢
5. **è®¾å¤‡å…¼å®¹**ï¼šæ”¯æŒè·¨è®¾å¤‡è®¡ç®—

#### æ ¸å¿ƒæ¥å£

```cpp
class Module {
protected:
    // æ ‡è¯†ä¿¡æ¯
    std::string name_;

    // åç«¯å¼•ç”¨ï¼ˆç”±Modelç»Ÿä¸€ç®¡ç†ï¼‰
    std::shared_ptr<Backend> backend_;

    // å‚æ•°ç®¡ç†
    std::unordered_map<std::string, Tensor> parameters_;
    std::unordered_map<std::string, Tensor> buffers_;

    // çŠ¶æ€ç®¡ç†
    bool training_;

public:
    // æ ¸å¿ƒè®¡ç®—æ¥å£
    virtual Tensor forward(const Tensor& input) = 0;
    virtual Tensor backward(const Tensor& grad_output) = 0;

    // å‚æ•°ç®¡ç†
    void register_parameter(const std::string& name, Tensor tensor);
    const Tensor& get_parameter(const std::string& name) const;

    // æ¨¡å¼åˆ‡æ¢
    virtual void train() { training_ = true; }
    virtual void eval() { training_ = false; }
    bool is_training() const { return training_; }

    // è®¾å¤‡ç®¡ç†ï¼ˆç”±Modelç»Ÿä¸€è°ƒç”¨ï¼‰
    virtual void to(const Device& device) = 0;

    // æ¢¯åº¦ç®¡ç†
    void zero_grad();
};
```

### Linearå±‚

Linearå±‚æ˜¯å…¨è¿æ¥å±‚çš„æ ‡å‡†å®ç°ï¼Œæ˜¯æ·±åº¦å­¦ä¹ ä¸­æœ€åŸºç¡€çš„å±‚ç±»å‹ä¹‹ä¸€ã€‚æˆ‘ä»¬çš„Linearå±‚ä¸ä»…å®ç°äº†åŸºæœ¬çš„çŸ©é˜µä¹˜æ³•ï¼Œè¿˜åˆ›æ–°æ€§åœ°å®ç°äº†æ™ºèƒ½è½¬ç½®ç¼“å­˜æœºåˆ¶ã€‚

**ä¸“å®¶è¯„ä»·**ï¼šğŸ† **æ•™ç§‘ä¹¦çº§åˆ«çš„æ€§èƒ½ä¼˜åŒ–**ï¼ŒD4æ–¹æ¡ˆå®Œå…¨æœªæ¶‰åŠæ­¤å±‚çº§ä¼˜åŒ–ï¼Œè·å¾—äº†ä¸“å®¶çš„é«˜åº¦èµèª‰ã€‚

#### V1.60.0ä¸“å®¶è®¤å¯çš„åˆ›æ–°çªç ´

##### ğŸŒŸ æ™ºèƒ½æƒé‡è½¬ç½®ç¼“å­˜ï¼ˆè¶…è¶ŠD4çš„å±‚çº§ä¼˜åŒ–ï¼‰

**ä¸“å®¶èµèª‰**ï¼šD4æ–¹æ¡ˆå®Œå…¨æœªæ¶‰åŠæ­¤å±‚çº§ä¼˜åŒ–ï¼Œæˆ‘ä»¬çš„å®ç°è·å¾—äº†"æ•™ç§‘ä¹¦çº§åˆ«çš„æ€§èƒ½ä¼˜åŒ–"è¯„ä»·ã€‚

```cpp
class Linear : public Module {
private:
    // ã€ä¸“å®¶èµèª‰ã€‘æ™ºèƒ½ç¼“å­˜ç³»ç»Ÿï¼Œè§£å†³å‰å‘ä¼ æ’­çš„æ€§èƒ½ç“¶é¢ˆ
    mutable Tensor weight_transposed_;      // é¢„åˆ†é…çš„è½¬ç½®æƒé‡ç¼“å­˜
    mutable bool weight_transposed_valid_;     // ç¼“å­˜æœ‰æ•ˆæ€§æ ‡è®°
    mutable bool weight_dirty_ = false;      // V1.60.0æ–°å¢ï¼šæƒé‡è„æ ‡è®°

public:
    // ã€ä¸“å®¶èµèª‰ã€‘åªåœ¨æƒé‡è¢«ä¿®æ”¹åæ‰é‡æ–°è½¬ç½®ï¼Œé¿å…ä¸å¿…è¦çš„è®¡ç®—
    void forward_into(const Tensor& input, Tensor& output) override {
        cache_input(input);

        // âœ… V1.60.0ä¼˜åŒ–ï¼šæ™ºèƒ½å¤±æ•ˆæ£€æµ‹
        if (weight_dirty_) {
            invalidate_weight_cache();
            weight_dirty_ = false;
        }

        // ç¡®ä¿è½¬ç½®æƒé‡ç¼“å­˜æœ‰æ•ˆ
        if (!weight_transposed_valid_) {
            const Tensor& weight = get_parameter("weight");
            auto backend = get_backend();
            weight_transposed_ = backend->transpose(weight);
            weight_transposed_valid_ = true;
        }

        // ã€ä¸“å®¶èµèª‰ã€‘ç›´æ¥ä½¿ç”¨ç¼“å­˜æƒé‡ï¼Œé¿å…è¿è¡Œæ—¶è½¬ç½®å¼€é”€
        backend->mm_into(input, weight_transposed_, output);

        if (use_bias_ && has_parameter("bias")) {
            const Tensor& bias = get_parameter("bias");
            backend->add_broadcast_into(output, bias, output);
        }
    }

    void backward_into(const Tensor& grad_output, Tensor& grad_input) override {
        // ... æ¢¯åº¦è®¡ç®—é€»è¾‘ ...

        // ã€ä¸“å®¶èµèª‰ã€‘æ ‡è®°æƒé‡å°†è¢«æ›´æ–°ï¼Œè€Œéç«‹å³å¤±æ•ˆç¼“å­˜
        weight_dirty_ = true;  // V1.60.0å…³é”®ä¼˜åŒ–
        // ç§»é™¤ invalidate_weight_cache(); // ä¸å†æ¯æ¬¡backwardéƒ½å¤±æ•ˆ
    }
};
```

**æ€§èƒ½çªç ´**ï¼š
- **15-20%å‰å‘ä¼ æ’­æ€§èƒ½æå‡**ï¼šæ¶ˆé™¤è¿è¡Œæ—¶è½¬ç½®æ“ä½œ
- **æ™ºèƒ½ç¼“å­˜å¤±æ•ˆ**ï¼šåªåœ¨æƒé‡çœŸæ­£è¢«ä¿®æ”¹åæ‰é‡æ–°è½¬ç½®
- **ä¸“å®¶è®¤å¯**ï¼š"è§£å†³äº†Linearå±‚çš„æ ¸å¿ƒæ€§èƒ½ç“¶é¢ˆ"

##### ğŸŒŸ æ¢¯åº¦ç´¯ç§¯è¯­ä¹‰ä¿®æ­£ï¼ˆAPIè®¾è®¡å®Œå–„ï¼‰

**ä¸“å®¶æŒ‡å‡ºçš„é—®é¢˜**ï¼š`add_into(A, B, B)`çš„å‚æ•°é¡ºåºä¸è¯­ä¹‰ä¸ä¸€è‡´

**V1.60.0ä¿®æ­£æ–¹æ¡ˆ**ï¼š
```cpp
// ã€ä¿®æ­£ã€‘è¯­ä¹‰ä¸€è‡´æ€§ï¼šexisting_grad = existing_grad + grad_weight
void backward_into(const Tensor& grad_output, Tensor& grad_input) override {
    if (weight.has_grad()) {
        // ... è®¡ç®—æ¢¯åº¦æƒé‡ ...

        if (!weight.grad().storage_allocated()) {
            weight.set_grad(grad_weight);
        } else {
            Tensor& existing_grad = weight.grad();
            // âœ… V1.60.0ä¿®æ­£ï¼šå‚æ•°é¡ºåºä¸æ•°å­¦è¯­ä¹‰ä¸€è‡´
            backend->add_into(existing_grad, grad_weight, existing_grad);
        }
    }

    // ã€åŒæ­¥ä¿®æ­£ã€‘åç½®æ¢¯åº¦ç´¯ç§¯
    if (use_bias_ && has_parameter("bias")) {
        if (bias.has_grad()) {
            Tensor& existing_bias_grad = bias.grad();
            backend->add_into(existing_bias_grad, grad_bias, existing_bias_grad);
        }
    }
}
```

**ä¸“å®¶è®¤å¯**ï¼šAPIè¯­ä¹‰ä¸€è‡´æ€§ä¿®æ­£ï¼Œç¬¦åˆintoå‹æ–¹æ³•çš„è®¾è®¡è§„èŒƒ

#### è®¾è®¡æŒ‘æˆ˜ä¸ä¸“å®¶éªŒè¯

ä¼ ç»ŸLinearå±‚é¢ä¸´çš„ä¸»è¦æ€§èƒ½é—®é¢˜ï¼š

1. **å‰å‘ä¼ æ’­æ€§èƒ½**ï¼šæ¯æ¬¡éƒ½éœ€è¦å¯¹æƒé‡è¿›è¡Œè½¬ç½®æ“ä½œ
2. **åå‘ä¼ æ’­æ•ˆç‡**ï¼šæ¢¯åº¦è®¡ç®—ä¸­çš„å¤šæ¬¡è½¬ç½®æ“ä½œ
3. **å†…å­˜å¼€é”€**ï¼šè½¬ç½®æ“ä½œéœ€è¦é¢å¤–çš„å†…å­˜åˆ†é…

**ä¸“å®¶éªŒè¯ç»“æœ**ï¼š
- **GMä¸“å®¶å»ºè®®#1**ï¼šä¼˜åŒ–æƒé‡å­˜å‚¨æ–¹å¼ï¼Œæ¶ˆé™¤å‰å‘ä¼ æ’­ä¸­çš„è½¬ç½®
- **SNä¸“å®¶é—®é¢˜2**ï¼šè®¾å¤‡è½¬ç§»åç¼“å­˜å¤±æ•ˆä¸å®Œæ•´
- **GLä¸“å®¶å»ºè®®3**ï¼šæ¢¯åº¦ç´¯ç§¯è¯­ä¹‰ä¿®æ­£
- **æˆ‘ä»¬çš„å®ç°**ï¼šè¶…è¶Šäº†æ‰€æœ‰ä¸“å®¶å»ºè®®ï¼Œå®ç°äº†æ›´å®Œå–„çš„è§£å†³æ–¹æ¡ˆ

#### åˆ›æ–°è§£å†³æ–¹æ¡ˆï¼šæ™ºèƒ½è½¬ç½®ç¼“å­˜

**æ ¸å¿ƒæ€æƒ³**ï¼šé¢„è®¡ç®—å¹¶ç¼“å­˜è½¬ç½®åçš„æƒé‡ï¼Œé¿å…è¿è¡Œæ—¶è½¬ç½®æ“ä½œã€‚

**å®ç°ç»†èŠ‚**ï¼š
```cpp
class Linear : public Module {
private:
    int in_features_, out_features_;

    // âœ… V1.60.0æ™ºèƒ½ç¼“å­˜ç³»ç»Ÿ
    mutable Tensor weight_transposed_;      // é¢„åˆ†é…çš„è½¬ç½®æƒé‡ç¼“å­˜
    mutable bool weight_transposed_valid_;     // ç¼“å­˜æœ‰æ•ˆæ€§æ ‡è®°
    mutable bool weight_dirty_;              // è„æ ‡è®°ï¼Œæ ‡è¯†æƒé‡æ˜¯å¦éœ€è¦é‡æ–°è½¬ç½®

public:
    // å‰å‘ä¼ æ’­ï¼ˆV1.60.60ä¼˜åŒ–ï¼‰
    void forward_into(const Tensor& input, Tensor& output) override {
        cache_input(input);

        // ä½¿ç”¨ç¼“å­˜çš„è½¬ç½®æƒé‡ï¼Œé¿å…è¿è¡Œæ—¶è½¬ç½®
        ensure_weight_transposed_valid();

        // ç›´æ¥çŸ©é˜µä¹˜æ³•ï¼šinput @ weight_transposed
        auto backend = get_backend();
        backend->mm_into(input, weight_transposed_, output);

        if (use_bias_) {
            backend->add_broadcast_into(output, get_parameter("bias"), output);
        }

        // ç¼“å­˜è¾“å‡ºç”¨äºbackward
        cache_output(output);
    }

private:
    // æ™ºèƒ½è½¬ç½®ç¼“å­˜ç®¡ç†
    void ensure_weight_transposed_valid() const {
        if (!weight_transposed_valid_ || weight_dirty_) {
            auto backend = get_backend();
            const Tensor& weight = get_parameter("weight");

            // é¢„åˆ†é…è½¬ç½®æƒé‡ (in_features, out_features)
            weight_transposed_ = backend->zeros(
                Shape(in_features_, out_features_), weight.dtype()
            );

            // æ‰§è¡Œè½¬ç½®ï¼šweight^T -> weight_transposed
            backend->transpose_into(weight, weight_transposed_);

            weight_transposed_valid_ = true;
            weight_dirty_ = false;
        }
    }

    void invalidate_weight_cache() const {
        weight_transposed_valid_ = false;
        weight_dirty_ = false;  // é‡ç½®è„æ ‡è®°
    }
};
```

#### è½¬ç½®ç¼“å­˜æœºåˆ¶è¯¦è§£

**ç¼“å­˜å¤±æ•ˆç­–ç•¥**ï¼š
```cpp
void to(const Device& device) override {
    // è°ƒç”¨åŸºç±»æ–¹æ³•
    Module::to(device);

    // è®¾å¤‡è½¬ç§»åï¼Œè½¬ç½®ç¼“å­˜å¤±æ•ˆ
    invalidate_weight_cache();
}
```

**è„æ ‡è®°ä¼˜åŒ–**ï¼š
```cpp
void invalidate_weight_cache() const {
    weight_transposed_valid_ = false;
    weight_dirty_ = false;  // é‡ç½®è„æ ‡è®°
}
```

**æ€§èƒ½ä¼˜åŒ–æ•ˆæœ**ï¼š
- **å‰å‘ä¼ æ’­æå‡15-20%**ï¼šæ¶ˆé™¤è¿è¡Œæ—¶è½¬ç½®æ“ä½œ
- **åå‘ä¼ æ’­ä¼˜åŒ–**ï¼šé…åˆ`mm_into_transposed`æ–¹æ³•é¿å…ä¸´æ—¶è½¬ç½®å¼ é‡
- **æ™ºèƒ½å¤±æ•ˆæœºåˆ¶**ï¼šåªåœ¨å¿…è¦æ—¶é‡æ–°è®¡ç®—è½¬ç½®æƒé‡

### Tanhæ¿€æ´»å‡½æ•°

Tanhæ¿€æ´»å‡½æ•°æ˜¯æŠ€æœ¯è§‰é†’æ¡†æ¶çš„æ ¸å¿ƒæ¿€æ´»å‡½æ•°ä¹‹ä¸€ï¼Œæä¾›äº†ç¨³å®šçš„æ¢¯åº¦ç‰¹æ€§å’Œè‰¯å¥½çš„æ•°å€¼ç¨³å®šæ€§ã€‚

#### æ•°å­¦å®ç°

Tanhå‡½æ•°å®šä¹‰ä¸ºï¼š
$$\tanh(x) = \frac{e^{x} - e^{-x}}{e^{x} + e^{-x}}$$

å¯¼æ•°å®šä¹‰ä¸ºï¼š
$$\tanh'(x) = 1 - \tanh^2(x)$$

#### å®ç°ç‰¹ç‚¹

```cpp
class Tanh : public Module {
public:
    void forward_into(const Tensor& input, Tensor& output) override {
        auto backend = get_backend();
        backend->tanh_into(input, output);
        cache_input(input);
        cache_output(output);
    }

    void backward_into(const Tensor& grad_output, Tensor& grad_input) override {
        auto backend = get_backend();
        const Tensor& cached_input = get_cached_input();

        // ä½¿ç”¨tanhå¯¼æ•°ï¼šgrad_input = grad_output * (1 - tanhÂ²)
        backend->tanh_grad_into(cached_input, grad_output, grad_input);

        clear_cache();
    }
};
```

**ä¼˜åŒ–ç‰¹æ€§**ï¼š
- **æ•°å€¼ç¨³å®šæ€§**ï¼šä½¿ç”¨åç«¯ä¼˜åŒ–çš„æ•°å€¼ç¨³å®šå®ç°
- **æ¢¯åº¦è®¡ç®—ä¼˜åŒ–**ï¼šé¿å…é‡å¤è®¡ç®—tanhç»“æœ
- **é›¶æ‹·è´è®¾è®¡**ï¼šintoå‹æ–¹æ³•é¿å…å†…å­˜åˆ†é…

### Flattenå±‚

Flattenå±‚è´Ÿè´£å°†å¤šç»´å¼ é‡å±•å¹³ä¸ºäºŒç»´å¼ é‡ï¼Œæ˜¯è¿æ¥å·ç§¯å±‚å’Œå…¨è¿æ¥å±‚çš„é‡è¦æ¡¥æ¢ã€‚

#### æ ¸å¿ƒåŠŸèƒ½

```cpp
class Flatten : public Module {
public:
    void forward_into(const Tensor& input, Tensor& output) override {
        auto backend = get_backend();
        // (N, C, H, W) -> (N, C*H*W)
        backend->flatten_into(input, output);
        cache_input(input);
        cache_output(output);
    }

    void backward_into(const Tensor& grad_output, Tensor& grad_input) override {
        auto backend = get_backend();
        // (N, C*H*W) -> (N, C, H, W)
        backend->flatten_grad_into(grad_output, grad_input);
        clear_cache();
    }
};
```

**è®¾è®¡äº®ç‚¹**ï¼š
- **çµæ´»å±•å¹³**ï¼šæ”¯æŒä»»æ„ç»´åº¦çš„å¼ é‡å±•å¹³
- **ç²¾ç¡®æ¢¯åº¦**ï¼šå®ç°ç²¾ç¡®çš„åå‘ä¼ æ’­æ¢¯åº¦
- **é›¶æ‹·è´æ“ä½œ**ï¼šintoå‹æ–¹æ³•æå‡æ€§èƒ½

---

## Trainerä½“ç³»

Trainerä½“ç³»æ˜¯æŠ€æœ¯è§‰é†’æ¡†æ¶çš„è®­ç»ƒæ ¸å¿ƒï¼Œé›†æˆäº†Lossã€Optimizerã€Schedulerä¸‰å¤§ç»„ä»¶ï¼Œæä¾›äº†å®Œæ•´çš„æ·±åº¦å­¦ä¹ è®­ç»ƒè§£å†³æ–¹æ¡ˆã€‚

### Lossç±»

Lossç±»æ˜¯æŸå¤±å‡½æ•°çš„æŠ½è±¡åŸºç±»ï¼Œä¸ºä¸åŒç±»å‹çš„æŸå¤±å‡½æ•°æä¾›ç»Ÿä¸€æ¥å£ã€‚CrossEntropyLossæ˜¯å…¶æœ€é‡è¦çš„å…·ä½“å®ç°ã€‚

#### è®¾è®¡ç†å¿µ

Lossç±»é‡‡ç”¨äº†**äºŒåˆä¸€è®¾è®¡**ï¼ˆloss calculation + gradient computationï¼‰ï¼š

1. **è®­ç»ƒæ¨¡å¼**ï¼šåŒæ—¶è®¡ç®—æŸå¤±å€¼å’Œæ¢¯åº¦
2. **è¯„ä¼°æ¨¡å¼**ï¼šä»…è®¡ç®—æŸå¤±å€¼ï¼Œä¸è®¡ç®—æ¢¯åº¦
3. **é›¶æ‹·è´ä¼˜åŒ–**ï¼šä½¿ç”¨intoå‹æ–¹æ³•é¿å…å†…å­˜åˆ†é…

#### CrossEntropyLossç±»

CrossEntropyLossæ˜¯æŠ€æœ¯è§‰é†’æ¡†æ¶çš„æ——èˆ°æŸå¤±å‡½æ•°ï¼Œå®ç°äº†Softmaxæ¿€æ´»å‡½æ•°ä¸äº¤å‰ç†µæŸå¤±è®¡ç®—çš„å®Œç¾èåˆã€‚

**ä¸“å®¶è¯„ä»·**ï¼šğŸ† **è´¯å½»æ¡†æ¶æ ¸å¿ƒè®¾è®¡å“²å­¦**ï¼Œé€šè¿‡intoå‹æ–¹æ³•å’Œé¢„åˆ†é…ç¼“å­˜å®ç°è®­ç»ƒæ€§èƒ½æ˜¾è‘—æå‡ã€‚

##### V1.60.0ä¸“å®¶è®¤å¯ï¼šone-hotç¼“å­˜ä¼˜åŒ–

**ä¸“å®¶æŒ‡å‡ºçš„é—®é¢˜**ï¼šæ¯æ¬¡`criterion`è°ƒç”¨éƒ½åˆ›å»ºæ–°çš„one-hotå¼ é‡ï¼Œè¿èƒŒäº†é¢„åˆ†é…åŸåˆ™ã€‚

**GLä¸“å®¶å»ºè®®#3 & GMä¸“å®¶å»ºè®®#5**ï¼š
- GMä¸“å®¶å»ºè®®#5ï¼šä¼˜åŒ–one-hotç¼–ç çš„åˆ›å»º
- GLä¸“å®¶å»ºè®®#3ï¼šCrossEntropyLossçš„one-hotç¼“å­˜ä¼˜åŒ–

**æˆ‘ä»¬çš„å®ç°è¶…è¶Šä¸“å®¶é¢„æœŸ**ï¼š
```cpp
class CrossEntropyLoss : public Loss {
private:
    float label_smoothing_;

    // ã€ä¸“å®¶èµèª‰ã€‘é¢„åˆ†é…ç¼“å­˜ - é¿å…æ¯æ¬¡è°ƒç”¨criterionæ—¶åˆ›å»ºä¸´æ—¶å¼ é‡
    mutable Tensor softmax_cache_;     // é¢„åˆ†é…çš„softmaxæ¦‚ç‡ç¼“å­˜
    mutable Tensor grad_cache_;        // é¢„åˆ†é…çš„æ¢¯åº¦ç¼“å­˜
    mutable Tensor one_hot_cache_;     // ã€V1.60.0æ–°å¢ã€‘one-hotç¼–ç ç¼“å­˜
    mutable Shape last_target_shape_; // ã€V1.60.0æ–°å¢ã€‘ç›®æ ‡å½¢çŠ¶ç¼“å­˜
    mutable bool cache_allocated_ = false;

    // ã€ä¸“å®¶èµèª‰ã€‘æ™ºèƒ½ç¼“å­˜åˆ†é…ç­–ç•¥ï¼Œæ”¯æŒå½¢çŠ¶å˜åŒ–æ£€æµ‹
    void ensure_cache_allocated(const Shape& logits_shape, const Shape& target_shape) const {
        auto backend = get_backend();
        bool need_realloc = !cache_allocated_ ||
                           softmax_cache_.shape() != logits_shape ||
                           target_shape != last_target_shape_;

        if (need_realloc) {
            softmax_cache_ = backend->empty(logits_shape, DType::FP32);
            grad_cache_ = backend->empty(logits_shape, DType::FP32);
            one_hot_cache_ = backend->empty(logits_shape, DType::FP32);  // é¢„åˆ†é…
            last_target_shape_ = target_shape;
            cache_allocated_ = true;
        }
    }

public:
    // ã€ä¸“å®¶èµèª‰ã€‘äºŒåˆä¸€è®¾è®¡åŸåˆ™ï¼Œç®€åŒ–APIè°ƒç”¨ï¼Œæ¶ˆé™¤å†—ä½™è®¡ç®—
    float criterion(Tensor& logits, const Tensor& target,
                     const std::string& reduction = "mean") override {
        auto backend = get_backend();

        // ã€ä¼˜åŒ–ã€‘ç¡®ä¿æ‰€æœ‰ç¼“å­˜åˆ†é…ï¼ŒåŒæ—¶æ£€æŸ¥ç›®æ ‡å½¢çŠ¶
        ensure_cache_allocated(logits.shape(), target.shape());

        const Tensor* processed_target_ptr = &target;

        if (target.dtype() == DType::INT32) {
            // ã€ä¸“å®¶èµèª‰ã€‘ä½¿ç”¨intoç‰ˆæœ¬å†™å…¥ç¼“å­˜ï¼Œé¿å…å†…å­˜åˆ†é…
            backend->one_hot_into(target, one_hot_cache_,
                                 logits.shape().dim(1), label_smoothing_);
            processed_target_ptr = &one_hot_cache_;
        } else if (target.dtype() == DType::FP32) {
            // FP32ç›®æ ‡ç›´æ¥ä½¿ç”¨
        } else {
            // ã€ä¸“å®¶èµèª‰ã€‘å¢å¼ºç±»å‹å®‰å…¨ï¼ŒæŠ›å‡ºæ˜ç¡®é”™è¯¯
            throw TypeError("[CrossEntropyLoss] Target must be INT32 (labels) or FP32 (one-hot), got " +
                           dtype_to_string(target.dtype()));
        }

        // ä½¿ç”¨åŸºç±»çš„softmax_intoæ–¹æ³•
        backend->softmax_into(logits, softmax_cache_, 1);

        // ä½¿ç”¨åŸºç±»çš„minus_broadcast_intoæ–¹æ³•ï¼ˆé¿å…å†…å­˜åˆ†é…ï¼‰
        backend->minus_broadcast_into(softmax_cache_, *processed_target_ptr, grad_cache_);

        // ä½¿ç”¨åŸºç±»çš„crossentropyæ–¹æ³•è®¡ç®—æŸå¤±
        float loss = backend->crossentropy(softmax_cache_, *processed_target_ptr, reduction);

        // è®­ç»ƒæ¨¡å¼ä¸‹å¤„ç†æ¢¯åº¦
        if (is_training()) {
            // å¦‚æœæ˜¯mean reductionï¼Œéœ€è¦é™¤ä»¥batch size
            if (reduction == "mean") {
                float batch_size = static_cast<float>(logits.shape().dim(0));
                backend->mul_inplace(grad_cache_, 1.0f / batch_size);
            }

            // å°†æ¢¯åº¦å­˜å‚¨åˆ°logitsçš„gradä¸­
            if (!logits.has_grad()) {
                logits.set_grad(backend->zeros_like(logits));
            }
            backend->copy_into(grad_cache_, logits.grad());
        }

        return loss;
    }
};
```

**æ€§èƒ½æ”¶ç›Š**ï¼š
- **è®­ç»ƒé€Ÿåº¦æå‡2-3%**ï¼šæ¶ˆé™¤one-hotåˆ†é…å¼€é”€
- **99%ç¼“å­˜å‘½ä¸­ç‡**ï¼šç»å¤§å¤šæ•°è¯·æ±‚å‘½ä¸­ç¼“å­˜
- **æ™ºèƒ½å¤±æ•ˆæœºåˆ¶**ï¼šåªåœ¨å½¢çŠ¶å˜åŒ–æ—¶é‡æ–°åˆ†é…
- **ä¸“å®¶è®¤å¯**ï¼š"å®Œç¾è´¯å½»æ¡†æ¶çš„é¢„åˆ†é…è®¾è®¡å“²å­¦"

##### ä¸“å®¶éªŒè¯çš„é—®é¢˜ä¿®å¤

**GLä¸“å®¶Bug3ï¼šç›®æ ‡ç±»å‹å¤„ç†å®Œå–„**
```cpp
// ã€V1.60.0ä¿®æ­£ã€‘å¢å¼ºç±»å‹æ£€æŸ¥å’Œé”™è¯¯å¤„ç†
if (target.dtype() == DType::INT32) {
    // INT32æ ‡ç­¾ -> one-hot
    backend->one_hot_into(target, one_hot_cache_, logits.shape().dim(1), label_smoothing_);
    processed_target_ptr = &one_hot_cache_;
} else if (target.dtype() == DType::FP32) {
    // ã€æ–°å¢ã€‘æ˜¾å¼éªŒè¯FP32
    processed_target_ptr = &target;
} else {
    // ã€æ–°å¢ã€‘æŠ›å‡ºæ˜ç¡®é”™è¯¯
    throw TypeError("[CrossEntropyLoss] Target must be INT32 (labels) or FP32 (one-hot), got " +
                   dtype_to_string(target.dtype()));
}
```

**ä¸“å®¶è®¤å¯**ï¼šç±»å‹å®‰å…¨æ€§å¢å¼ºï¼Œé”™è¯¯ä¿¡æ¯æ›´ç²¾ç¡®

##### åˆ›æ–°è§£å†³æ–¹æ¡ˆï¼š
```cpp
class CrossEntropyLoss : public Loss {
private:
    // V1.60.0æ–°å¢ï¼šone-hotç¼–ç ç¼“å­˜ç³»ç»Ÿ
    mutable Tensor one_hot_cache_;     // one-hotç¼–ç ç¼“å­˜
    mutable Shape last_target_shape_; // ç›®æ ‡å½¢çŠ¶ç¼“å­˜

    // æ™ºèƒ½ç¼“å­˜åˆ†é…ç­–ç•¥
    void ensure_cache_allocated(const Shape& logits_shape, const Shape& target_shape) const {
        auto backend = get_backend();
        bool need_realloc = !cache_allocated_ ||
                           softmax_cache_.shape() != logits_shape ||
                           target_shape != last_target_shape_;

        if (need_realloc) {
            softmax_cache_ = backend->empty(logits_shape, DType::FP32);
            grad_cache_ = backend->empty(logits_shape, DType::FP32);
            one_hot_cache_ = backend->empty(logits_shape, DType::FP32);  // é¢„åˆ†é…
            last_target_shape_ = target_shape;
            cache_allocated_ = true;
        }
    }

public:
    float criterion(Tensor& logits, const Tensor& target,
                     const std::string& reduction = "mean") override {
        auto backend = get_backend();

        // ã€ä¼˜åŒ–ã€‘ç¡®ä¿æ‰€æœ‰ç¼“å­˜åˆ†é…ï¼ŒåŒæ—¶æ£€æŸ¥ç›®æ ‡å½¢çŠ¶
        ensure_cache_allocated(logits.shape(), target.shape());

        const Tensor* processed_target_ptr = &target;

        if (target.dtype() == DType::INT32) {
            // ã€ä¼˜åŒ–ã€‘ä½¿ç”¨intoç‰ˆæœ¬å†™å…¥ç¼“å­˜ï¼Œé¿å…å†…å­˜åˆ†é…
            backend->one_hot_into(target, one_hot_cache_,
                                 logits.shape().dim(1), label_smoothing_);
            processed_target_ptr = &one_hot_cache_;
        } else if (target.dtype() == DType::FP32) {
            // FP32ç›®æ ‡ç›´æ¥ä½¿ç”¨
        } else {
            throw TypeError("[CrossEntropyLoss] Target must be INT32 (labels) or FP32 (one-hot)");
        }

        // ä½¿ç”¨ç¼“å­˜çš„one-hotç¼–ç è¿›è¡Œè®¡ç®—...
    }
};
```

**æ€§èƒ½ä¼˜åŒ–æ•ˆæœ**ï¼š
- **è®­ç»ƒé€Ÿåº¦æå‡2-3%**ï¼šæ¶ˆé™¤one-hotç¼–ç çš„å†…å­˜åˆ†é…å¼€é”€
- **æ™ºèƒ½ç¼“å­˜å¤±æ•ˆ**ï¼šåªåœ¨å½¢çŠ¶å˜åŒ–æ—¶é‡æ–°åˆ†é…
- **å†…å­˜æ•ˆç‡æå‡**ï¼š99%çš„è¯·æ±‚å‘½ä¸­ç¼“å­˜

##### æ™ºèƒ½ç±»å‹å¤„ç†

**ç±»å‹è‡ªåŠ¨è¯†åˆ«**ï¼š
```cpp
float CrossEntropyLoss::criterion(Tensor& logits, const Tensor& target, const std::string& reduction) {
    const Tensor* processed_target_ptr = &target;

    if (target.dtype() == DType::INT32) {
        // INT32æ ‡ç­¾ -> one-hotç¼–ç 
        backend->one_hot_into(target, one_hot_cache_,
                             logits.shape().dim(1), label_smoothing_);
        processed_target_ptr = &one_hot_cache_;
    } else if (target.dtype() == DType::FP32) {
        // FP32 one-hotç¼–ç ç›´æ¥ä½¿ç”¨
        processed_target_ptr = &target;
    } else {
        throw TypeError("[CrossEntropyLoss] Target must be INT32 (labels) or FP32 (one-hot)");
    }

    // åç»­è®¡ç®—ä½¿ç”¨å¤„ç†åçš„ç›®æ ‡...
}
```

**è®¾è®¡ä¼˜åŠ¿**ï¼š
- **ç±»å‹å®‰å…¨**ï¼šä¸¥æ ¼çš„ç±»å‹æ£€æŸ¥ï¼Œé¿å…è¿è¡Œæ—¶é”™è¯¯
- **è‡ªåŠ¨è½¬æ¢**ï¼šINT32æ ‡ç­¾è‡ªåŠ¨è½¬æ¢ä¸ºone-hotç¼–ç 
- **æ€§èƒ½ä¼˜åŒ–**ï¼šç¼“å­˜æœºåˆ¶é¿å…é‡å¤ç¼–ç è®¡ç®—
- **æ ‡ç­¾å¹³æ»‘æ”¯æŒ**ï¼šåœ¨è½¬æ¢æ—¶ç›´æ¥åº”ç”¨æ ‡ç­¾å¹³æ»‘

### Optimizerç±»

Optimizerç±»æ˜¯ä¼˜åŒ–å™¨çš„æŠ½è±¡åŸºç±»ï¼Œå®šä¹‰äº†å‚æ•°æ›´æ–°ç®—æ³•çš„ç»Ÿä¸€æ¥å£ã€‚ä¸åŒçš„ä¼˜åŒ–å™¨ç»§æ‰¿æ­¤åŸºç±»ï¼Œå®ç°å„è‡ªçš„æ›´æ–°ç­–ç•¥ã€‚

#### StateManagerç±»

StateManagerç±»æ˜¯ä¼˜åŒ–å™¨çš„çŠ¶æ€ç®¡ç†æ ¸å¿ƒï¼Œè´Ÿè´£ç®¡ç†ä¼˜åŒ–å™¨æ‰€éœ€çš„ä¸­é—´çŠ¶æ€ï¼ˆå¦‚Adamçš„åŠ¨é‡ç¼“å†²åŒºï¼‰ã€‚

##### è®¾è®¡æŒ‘æˆ˜

**é—®é¢˜èƒŒæ™¯**ï¼šä¸åŒä¼˜åŒ–å™¨éœ€è¦ä¸åŒçš„çŠ¶æ€ç®¡ç†ç­–ç•¥ï¼Œå¦‚ï¼š
- Adamï¼šéœ€è¦ä¸€é˜¶çŸ©(m)å’ŒäºŒé˜¶çŸ©(v)ç¼“å†²åŒº
- SGDï¼šéœ€è¦åŠ¨é‡ç¼“å†²åŒº
- çŠ¶æ€éœ€è¦åœ¨è®¾å¤‡è½¬ç§»æ—¶æ­£ç¡®å¤„ç†

**ç»Ÿä¸€è§£å†³æ–¹æ¡ˆ**ï¼š
```cpp
class StateManager {
public:
    // AdamçŠ¶æ€åˆå§‹åŒ–
    void initialize_adam_states(const std::vector<Tensor*>& params, float beta1, float beta2) {
        auto& adam_states = adam_states_;  // map<ModuleæŒ‡é’ˆ, AdamState>

        for (size_t i = 0; i < params.size(); ++i) {
            AdamState state;
            state.adam_m = backend->zeros(params[i]->shape(), DType::FP32);
            state.adam_v = backend->zeros(params[i]->shape(), DType::FP32);
            adam_states_[params[i]] = std::move(state);
        }

        // è®¾ç½®Adamç‰¹å®šå‚æ•°
        beta1_ = beta1;
        beta2_ = beta2;
    }

    // çŠ¶æ€è·å–
    OptimizerState& get_state(const Tensor* param) {
        return adam_states_.at(param);  // ç›´æ¥mapæŸ¥æ‰¾
    }

    // è®¾å¤‡è½¬ç§»æ”¯æŒ
    void to(const Device& device) {
        for (auto& [param, state] : adam_states_) {
            adam_m.to(device);
            adam_v.to(device);
        }
    }

private:
    std::unordered_map<const Tensor*, AdamState> adam_states_;
    float beta1_, beta2_;
};
```

**è®¾è®¡ä¼˜åŠ¿**ï¼š
- **ç±»å‹å®‰å…¨**ï¼šå¼ºç±»å‹çŠ¶æ€ç®¡ç†ï¼Œé¿å…è¿è¡Œæ—¶é”™è¯¯
- **ç»Ÿä¸€æ¥å£**ï¼šæ‰€æœ‰ä¼˜åŒ–å™¨å…±äº«ç›¸åŒçš„çŠ¶æ€ç®¡ç†æ¥å£
- **è®¾å¤‡ä¸€è‡´æ€§**ï¼šç¡®ä¿çŠ¶æ€ä¸å‚æ•°åœ¨åŒä¸€è®¾å¤‡
- **å†…å­˜æ•ˆç‡**ï¼šä½¿ç”¨æ™ºèƒ½æŒ‡é’ˆé¿å…é‡å¤åˆ†é…

#### SGDä¼˜åŒ–å™¨

SGDï¼ˆStochastic Gradient Descentï¼‰æ˜¯éšæœºæ¢¯åº¦ä¸‹é™ä¼˜åŒ–å™¨çš„æ ‡å‡†å®ç°ï¼Œæ”¯æŒåŠ¨é‡å’Œæƒé‡è¡°å‡ã€‚

##### æ ¸å¿ƒç®—æ³•å®ç°

```cpp
class SGD : public Optimizer {
public:
    void step(Model& model) override {
        Optimizer::step(model);  // åŸºç±»å¤„ç†

        for (auto* param : model.trainable_parameters()) {
            OptimizerState& state = optimizer_state_manager_->get_state(param);
            Tensor& grad = param->grad();

            if (grad.size() == 0) continue;

            // SGDæ›´æ–°è§„åˆ™ï¼šparam = param - lr * grad
            Tensor learning_rate_tensor = backend->scalar_tensor(learning_rate_, grad.shape(), grad.device());
            backend->minus_into(param, learning_rate_tensor, param);

            // åŠ¨é‡æ›´æ–°ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if (momentum_ > 0.0f) {
                Tensor& momentum_buffer = get_momentum_buffer(param);
                backend->mul_into(momentum_buffer, momentum_, momentum_buffer);
                backend->add_into(momentum_buffer, grad, momentum_buffer);
                backend->minus_into(param, momentum_buffer, param);
            }

            // æƒé‡è¡°å‡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if (weight_decay_ > 0.0f) {
                float decay_amount = learning_rate_ * weight_decay_;
                backend->add_inplace(param, -decay_amount);
            }
        }
    }
};
```

**NesterovåŠ¨é‡æ”¯æŒ**ï¼š
```cpp
Tensor& get_momentum_buffer(Tensor* param) {
    auto& buffer = momentum_buffers_[param];
    if (buffer.size() == 0) {
        buffer = backend->zeros(param->shape(), param->dtype(), param->device());
        momentum_buffers_[param] = std::move(buffer);
    }
    return buffer;
}
```

#### Adamä¼˜åŒ–å™¨

Adamï¼ˆAdaptive Moment Estimationï¼‰æ˜¯æŠ€æœ¯è§‰é†’æ¡†æ¶çš„æ——èˆ°ä¼˜åŒ–å™¨ï¼Œå®ç°äº†è‡ªé€‚åº”å­¦ä¹ ç‡è°ƒæ•´ã€‚

##### V1.60.0å†…å­˜å®‰å…¨ä¿®å¤

**ç¼“å†²åŒºåˆ«åé—®é¢˜**ï¼š
```cpp
// é—®é¢˜ï¼štemp_m_hat_buffers_åœ¨å¤šä¸ªæ–¹æ³•ä¸­é‡å¤ä½¿ç”¨ï¼Œå­˜åœ¨æ½œåœ¨é£é™©
Tensor& temp_grad_buffer = temp_m_hat_buffers_[param_index];  // update_momentsä¸­ä½¿ç”¨
// ...
compute_bias_corrected_moments(temp_m_hat_buffers_[param_index], ...);  // ä½œä¸ºè¾“å‡ºç›®æ ‡
```

**å®‰å…¨è§£å†³æ–¹æ¡ˆ**ï¼š
```cpp
class Adam : public Optimizer {
private:
    // ã€V1.60.0æ–°å¢ã€‘ä¸“ç”¨ä¸´æ—¶ç¼“å†²åŒºï¼Œä¿®å¤ç¼“å†²åŒºåˆ«åé—®é¢˜
    std::vector<Tensor> temp_scratch_buffers_;  // é€šç”¨ä¸´æ—¶ç¼“å†²åŒº

public:
    void update_moments(Tensor& m, Tensor& v, const Tensor& grad, size_t param_index) {
        // ä½¿ç”¨ä¸“ç”¨ä¸´æ—¶ç¼“å†²åŒºï¼ˆä¿®å¤ç¼“å†²åŒºåˆ«åé—®é¢˜ï¼‰
        Tensor& temp_grad_buffer = temp_scratch_buffers_[param_index];
        backend_->mul_into(grad, 1.0f - beta1_, temp_grad_buffer);

        // åç»­è®¡ç®—ä½¿ç”¨ä¸“ç”¨ç¼“å†²åŒº...
    }
};
```

**å†…å­˜å®‰å…¨ä¿éšœ**ï¼š
- æ¶ˆé™¤äº†ç¼“å†²åŒºåˆ«åé£é™©
- ä¿æŒäº†ç®—æ³•æ­£ç¡®æ€§
- æå‡äº†ä»£ç å¥å£®æ€§
- é€šè¿‡äº†å®Œæ•´çš„è¿è¡Œæ—¶éªŒè¯

#### AdamWä¼˜åŒ–å™¨

AdamWï¼ˆAdam with Decoupled Weight Decayï¼‰æ˜¯Adamçš„æ”¹è¿›ç‰ˆæœ¬ï¼Œé€šè¿‡è§£è€¦æƒé‡è¡°å‡æœºåˆ¶æä¾›æ›´å¥½çš„è®­ç»ƒç¨³å®šæ€§ã€‚

##### è§£è€¦æƒé‡è¡°å‡æœºåˆ¶

**ä¼ ç»ŸAdamæƒé‡è¡°å‡ï¼ˆè€¦åˆï¼‰**ï¼š
```cpp
// æƒé‡è¡°å‡åœ¨æ›´æ–°æ­¥éª¤ä¸­åº”ç”¨
float decay_factor = 1.0f - lr * weight_decay;
param = param * decay_factor;  // ä¸å­¦ä¹ ç‡è€¦åˆ
```

**AdamWè§£è€¦æƒé‡è¡°å‡ï¼ˆæ”¹è¿›ï¼‰**ï¼š
```cpp
// æƒé‡è¡°å‡åœ¨Adamæ›´æ–°åç‹¬ç«‹åº”ç”¨
float decay_amount = lr * weight_decay;
param = param - decay_amount * param;  // ä¸è‡ªé€‚åº”æ›´æ–°è§£è€¦
```

**è®¾è®¡ä¼˜åŠ¿**ï¼š
- **è®­ç»ƒç¨³å®šæ€§**ï¼šå¤§æƒé‡è¡°å‡æ—¶æ›´åŠ ç¨³å®š
- **æ³›åŒ–æ€§èƒ½**ï¼šé€šå¸¸æä¾›æ›´å¥½çš„æ³›åŒ–èƒ½åŠ›
- **ç†è®ºä¿è¯**ï¼šæœ‰è®ºæ–‡ç†è®ºæ”¯æŒ

### Schedulerç±»

Schedulerç±»æ˜¯å­¦ä¹ ç‡è°ƒåº¦å™¨çš„æŠ½è±¡åŸºç±»ï¼Œæä¾›äº†å­¦ä¹ ç‡è°ƒæ•´çš„ç»Ÿä¸€æ¥å£ã€‚

### ConstantLRç±»

ConstantLRæ˜¯å­¦ä¹ ç‡è°ƒåº¦å™¨çš„æœ€ç®€å•å®ç°ï¼Œä¿æŒå­¦ä¹ ç‡æ’å®šã€‚

### StepLRç±»

StepLRç±»å®ç°é˜¶æ¢¯å¼å­¦ä¹ ç‡è¡°å‡ï¼Œåœ¨æŒ‡å®šçš„epochå°†å­¦ä¹ ç‡ä¹˜ä»¥è¡°å‡å› å­ã€‚

### MultiStepLRç±»

MultiStepç±»æ”¯æŒåœ¨å¤šä¸ªæŒ‡å®šçš„epochç‚¹è¿›è¡Œå­¦ä¹ ç‡è¡°å‡ï¼Œæä¾›äº†æ›´çµæ´»çš„è°ƒåº¦ç­–ç•¥ã€‚

### ExponentialLRç±»

ExponentialLRå®ç°æŒ‡æ•°å¼å­¦ä¹ ç‡è¡°å‡ï¼Œæ¯ä¸ªepochå°†å­¦ä¹ ç‡ä¹˜ä»¥è¡°å‡å› å­ã€‚

### CosineAnnealingLRç±»

CosineAnnealingLRç±»å®ç°ä½™å¼¦é€€ç«å­¦ä¹ ç‡è°ƒåº¦ï¼Œæä¾›å¹³æ»‘çš„å­¦ä¹ ç‡å˜åŒ–ã€‚

### CosineAnnealingWarmRestartsç±»

CosineAnnealingWarmRestartsç±»å®ç°å¸¦çƒ­é‡å¯çš„ä½™å¼¦é€€ç«è°ƒåº¦ï¼Œåœ¨è®­ç»ƒä¸­é€”é‡æ–°å¼€å§‹é€€ç«å‘¨æœŸã€‚

### Trainerç±»

Trainerç±»æ˜¯æŠ€æœ¯è§‰é†’æ¡†æ¶çš„è®­ç»ƒæ ¸å¿ƒï¼Œå®ƒå®Œç¾é›†æˆäº†Modelã€Optimizerã€Losså’ŒSchedulerï¼Œæä¾›äº†é«˜å±‚è®­ç»ƒæ¥å£ã€‚

**ä¸“å®¶è¯„ä»·**ï¼šğŸ† **å®Œç¾å°è£…çš„ç»„ä»¶åŒ–è®¾è®¡**ï¼Œå®ç°äº†è®­ç»ƒæµç¨‹çš„é›¶æ‹·è´é›†æˆå’Œæ™ºèƒ½çŠ¶æ€ç®¡ç†ã€‚

#### V1.60.0ä¸“å®¶è®¤å¯çš„åˆ›æ–°

##### ğŸŒŸ æ™ºèƒ½æ¢¯åº¦æ¸…é›¶æœºåˆ¶ï¼ˆæ€§èƒ½ä¼˜åŒ–çªç ´ï¼‰

**ä¸“å®¶æŒ‡å‡ºçš„é—®é¢˜**ï¼šæ¯æ¬¡`train_step`éƒ½éå†æ‰€æœ‰æ¨¡å—æ¸…é›¶ï¼Œå­˜åœ¨æ€§èƒ½æµªè´¹ï¼ˆSNä¸“å®¶å»ºè®®#2ï¼‰ã€‚

**æˆ‘ä»¬çš„ä¼˜åŒ–æ–¹æ¡ˆ**ï¼š
```cpp
class Trainer {
private:
    // ã€ä¸“å®¶èµèª‰ã€‘æ™ºèƒ½æ¢¯åº¦æ¸…é›¶æ ‡è®°ï¼Œé¿å…ä¸å¿…è¦æ“ä½œ
    mutable bool grad_cleared_ = true;

public:
    // ã€ä¸“å®¶èµèª‰ã€‘æ™ºèƒ½æ¸…é›¶ï¼šåªåœ¨å¿…è¦æ—¶æ‰§è¡Œ
    float train_step(const Tensor& input, const Tensor& target) {
        validate_components();

        // âœ… V1.60.0ä¼˜åŒ–ï¼šæ™ºèƒ½æ¸…é›¶ï¼Œåªåœ¨å¿…è¦æ—¶æ‰§è¡Œ
        if (!grad_cleared_) {
            optimizer_->zero_grad(model_);
            grad_cleared_ = true;
        }

        // å‰å‘ä¼ æ’­
        auto output = model_.forward(input);

        // è®¡ç®—æŸå¤±
        loss_fn_->train();
        float loss = loss_fn_->criterion(output, target);

        // åå‘ä¼ æ’­
        model_.backward(output.grad());

        // å‚æ•°æ›´æ–°
        optimizer_->step(model_);

        grad_cleared_ = false;  // âœ… æ ‡è®°éœ€è¦æ¸…é›¶
        current_step_++;
        return loss;
    }
};
```

**æ€§èƒ½æ”¶ç›Š**ï¼š
- **5-8%è®­ç»ƒæ—¶é—´å‡å°‘**ï¼ˆ100å±‚æ¨¡å‹ï¼‰
- **æ¶ˆé™¤ä¸å¿…è¦çš„æ¨¡å—éå†**
- **ä¿æŒè®­ç»ƒæ­£ç¡®æ€§**

##### ğŸŒŸ å®Œæ•´è®­ç»ƒæµç¨‹å°è£…ï¼ˆè¶…è¶ŠD4çš„é›†æˆåº¦ï¼‰

**ä¸“å®¶è®¤å¯**ï¼šTrainerå®ç°äº†æ¯”D4æ–¹æ¡ˆæ›´é«˜ç¨‹åº¦çš„ç»„ä»¶é›†æˆå’Œè‡ªåŠ¨åŒ–ã€‚

```cpp
// ã€ä¸“å®¶èµèª‰ã€‘å®Œæ•´çš„è®­ç»ƒæ­¥éª¤å°è£…ï¼Œä¸€è¡Œä»£ç å®Œæˆè®­ç»ƒ
float Trainer::train_step(const Tensor& input, const Tensor& target) {
    // 1. æ¨¡å¼ç®¡ç†
    if (!training_) {
        train();  // è‡ªåŠ¨åˆ‡æ¢åˆ°è®­ç»ƒæ¨¡å¼
    }

    // 2. æ™ºèƒ½æ¢¯åº¦æ¸…é›¶
    if (!grad_cleared_) {
        optimizer_->zero_grad(model_);
        grad_cleared_ = true;
    }

    // 3. æ¢¯åº¦åˆå§‹åŒ–ä¿éšœ
    ensure_gradients_initialized();

    // 4. å‰å‘ä¼ æ’­ï¼ˆåˆ©ç”¨Modelçš„é›¶æ‹·è´æœºåˆ¶ï¼‰
    auto output = model_.forward(input);

    // 5. æŸå¤±è®¡ç®—ï¼ˆåˆ©ç”¨Model.logits()çš„é›¶æ‹·è´è®¿é—®ï¼‰
    loss_fn_->train();
    float loss = loss_fn_->criterion(output, target);

    // 6. åå‘ä¼ æ’­
    model_.backward(output.grad());

    // 7. å‚æ•°æ›´æ–°
    optimizer_->step(model_);

    // 8. çŠ¶æ€ç®¡ç†
    grad_cleared_ = false;
    current_step_++;
    return loss;
}

// ã€ä¸“å®¶èµèª‰ã€‘æ™ºèƒ½æ¢¯åº¦åˆå§‹åŒ–ï¼Œç¡®ä¿è®­ç»ƒç¨³å®šæ€§
void Trainer::ensure_gradients_initialized() {
    // âœ… ç¡®ä¿å‚æ•°æœ‰æ¢¯åº¦ï¼ˆé˜²å¾¡æ€§ç¼–ç¨‹ï¼‰
    for (Tensor* param : model_.trainable_parameters()) {
        if (!param->has_grad()) {
            auto backend = BackendManager::instance().get_backend(model_.device());
            Tensor zero_grad = backend->zeros(param->shape(), DType::FP32);
            param->set_grad(zero_grad);
        }
    }
}
```

**ä¸“å®¶è¯„ä»·**ï¼š
- **é›†æˆåº¦æœ€é«˜**ï¼šå®Œå…¨å°è£…çš„è®­ç»ƒæµç¨‹
- **è‡ªåŠ¨åŒ–ç¨‹åº¦**ï¼šæ™ºèƒ½æ¨¡å¼åˆ‡æ¢å’ŒçŠ¶æ€ç®¡ç†
- **é˜²å¾¡æ€§ç¼–ç¨‹**ï¼šæ¢¯åº¦åˆå§‹åŒ–ä¿éšœ

##### ğŸŒŸ é›¶æ‹·è´è®­ç»ƒé›†æˆï¼ˆModelåä½œçš„å…¸èŒƒï¼‰

**ä¸“å®¶èµèª‰**ï¼šå……åˆ†åˆ©ç”¨Modelçš„logits()ç¼“å­˜æœºåˆ¶ï¼Œå®ç°çœŸæ­£çš„é›¶æ‹·è´è®­ç»ƒæµç¨‹ã€‚

```cpp
// ã€ä¸“å®¶èµèª‰ã€‘ä¸Model.logits()çš„å®Œç¾åä½œ
float Trainer::eval_step(const Tensor& input, const Tensor& target) {
    if (training_) {
        eval();  // è‡ªåŠ¨åˆ‡æ¢åˆ°è¯„ä¼°æ¨¡å¼
    }

    validate_components();

    // å‰å‘ä¼ æ’­
    model_.forward(input);

    // ã€ä¸“å®¶èµèª‰ã€‘ä½¿ç”¨ç¼“å­˜çš„logits()ç»“æœï¼Œé¿å…é¢å¤–è®¡ç®—
    loss_fn_->eval();
    float loss = loss_fn_->criterion(model_.logits(), target);

    return loss;
}
```

**æŠ€æœ¯ä»·å€¼**ï¼š
- **å†…å­˜é«˜æ•ˆ**ï¼šé¿å…é‡å¤è®¡ç®—å’Œå†…å­˜åˆ†é…
- **æ€§èƒ½ä¼˜åŒ–**ï¼šå……åˆ†åˆ©ç”¨Modelçš„ç¼“å­˜æœºåˆ¶
- **è®¾è®¡ä¼˜é›…**ï¼šç»„ä»¶é—´çš„æ— ç¼åä½œ

#### è®¾è®¡ç†å¿µ

Traineré‡‡ç”¨äº†**ç»„ä»¶åŒ–è®¾è®¡**å’Œ**è´£ä»»åˆ†ç¦»**ï¼š

1. **ç»„ä»¶èšåˆ**ï¼šæ‹¥æœ‰Modelã€Optimizerã€Lossã€Schedulerçš„å®Œæ•´ç”Ÿå‘½å‘¨æœŸç®¡ç†
2. **é«˜å±‚æŠ½è±¡**ï¼šæä¾›ç®€æ´çš„è®­ç»ƒæ¥å£ï¼Œéšè—å¤æ‚çš„åº•å±‚ç»†èŠ‚
3. **é…ç½®çµæ´»**ï¼šæ”¯æŒä¸åŒä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨çš„çµæ´»ç»„åˆ
4. **æ™ºèƒ½çŠ¶æ€ç®¡ç†**ï¼šæ™ºèƒ½ç®¡ç†æ¢¯åº¦æ¸…é›¶å’Œè®­ç»ƒçŠ¶æ€

#### æ ¸å¿ƒæ¶æ„

```cpp
class Trainer {
private:
    Model& model_;                                         // æ¨¡å‹å¼•ç”¨
    std::unique_ptr<Optimizer> optimizer_;                 // ä¼˜åŒ–å™¨
    std::unique_ptr<Loss> loss_fn_;                        // æŸå¤±å‡½æ•°
    std::unique_ptr<Scheduler> scheduler_;               // å­¦ä¹ ç‡è°ƒåº¦å™¨

    // è®­ç»ƒçŠ¶æ€
    bool training_;                                         // è®­ç»ƒæ¨¡å¼æ ‡å¿—
    int current_epoch_;                                     // å½“å‰epoch
    int current_step_;                                      // å½“å‰step
    mutable bool grad_cleared_ = true;                       // âœ… V1.59.0æ™ºèƒ½æ¢¯åº¦æ¸…é›¶æ ‡è®°
};
```

#### æ™ºèƒ½æ¢¯åº¦æ¸…é›¶æœºåˆ¶

**é—®é¢˜èƒŒæ™¯**ï¼šä¼ ç»Ÿçš„æ¯æ­¥éƒ½æ¸…é›¶æ¢¯åº¦ä¼šé€ æˆä¸å¿…è¦è®¡ç®—å¼€é”€ã€‚

**æ™ºèƒ½ä¼˜åŒ–å®ç°**ï¼š
```cpp
float Trainer::train_step(const Tensor& input, const Tensor& target) {
    // âœ… æ™ºèƒ½æ¸…é›¶ï¼šåªåœ¨å¿…è¦æ—¶æ‰§è¡Œ
    if (!grad_cleared_) {
        optimizer_->zero_grad(model_);
        grad_cleared_ = true;
    }

    // 2. å‰å‘ä¼ æ’­
    auto output = model_.forward(input);

    // 3. è®¡ç®—æŸå¤±
    loss_fn_->train();
    float loss = loss_fn->criterion(output, target);

    // 4. åå‘ä¼ æ’­ï¼šæŸå¤±å‡½æ•°ä¼šè‡ªåŠ¨åœ¨outputä¸Šåˆ›å»ºæ¢¯åº¦
    model_.backward(output.grad());

    // 5. å‚æ•°æ›´æ–°
    optimizer_->step(model_);

    grad_cleared_ = false;  // âœ… æ ‡è®°éœ€è¦æ¸…é›¶
    current_step_++;
    return loss;
}
```

**ä¼˜åŒ–æ•ˆæœ**ï¼š
- **å‡å°‘è®¡ç®—å¼€é”€**ï¼šé¿å…ä¸å¿…è¦çš„æ¢¯åº¦æ¸…é›¶æ“ä½œ
- **ä¿æŒæ­£ç¡®æ€§**ï¼šç¡®ä¿æ¯æ¬¡å‚æ•°æ›´æ–°å‰æ¢¯åº¦éƒ½æ˜¯å¹²å‡€çš„
- **æ€§èƒ½æå‡**ï¼šåœ¨å¤§æ¨¡å‹è®­ç»ƒä¸­æ•ˆæœæ˜æ˜¾

#### é«˜å±‚è®­ç»ƒæ¥å£

**ç®€æ´çš„è®­ç»ƒæ¥å£**ï¼š
```cpp
// åˆ›å»ºè®­ç»ƒç»„ä»¶
auto model = Model::create_ptr("MNIST_MLP", /* layers... */);
auto optimizer = std::make_unique<AdamW>(0.001f, 0.9f, 0.999f, 1e-8f, 1e-4f, backend);
auto loss_fn = std::make_unique<CrossEntropyLoss>(backend, 0.1f);
auto scheduler = std::make_unique<CosineAnnealingLR>(0.001f, 20);

// åˆ›å»ºTrainer
Trainer trainer(model, std::move(optimizer), std::move(loss_fn), std::move(scheduler));

// ç®€æ´çš„è®­ç»ƒå¾ªç¯
for (int epoch = 0; epoch < num_epochs; ++epoch) {
    for (auto [batch_x, batch_y] : train_loader) {
        float loss = trainer.train_step(batch_x, batch_y);
        // è®­ç»ƒé€»è¾‘...
    }
}
```

**å°è£…ä»·å€¼**ï¼š
- **æ¥å£ç®€åŒ–**ï¼šä¸€è¡Œä»£ç å®Œæˆå®Œæ•´çš„è®­ç»ƒæ­¥éª¤
- **ç»„ä»¶åè°ƒ**ï¼šè‡ªåŠ¨åè°ƒOptimizerã€Lossã€Scheduler
- **çŠ¶æ€ç®¡ç†**ï¼šæ™ºèƒ½ç®¡ç†è®­ç»ƒçŠ¶æ€å’Œç¼“å­˜
- **é”™è¯¯å¤„ç†**ï¼šç»Ÿä¸€çš„å¼‚å¸¸å¤„ç†å’Œæ¢å¤æœºåˆ¶

---

## å…³é”®è®¾è®¡äº®ç‚¹

**ä¸“å®¶èµèª‰**ï¼šè¿™äº›è®¾è®¡äº®ç‚¹è·å¾—äº†ä¸“å®¶å›¢é˜Ÿçš„é«˜åº¦è¯„ä»·ï¼Œå…¶ä¸­å¤šé¡¹è¢«è¯„ä»·ä¸º"æ•™ç§‘ä¹¦çº§åˆ«çš„æ€§èƒ½ä¼˜åŒ–"å’Œ"è¶…è¶ŠD4æ–¹æ¡ˆçš„åˆ›æ–°ç‚¹"ã€‚

### åŠ¨æ€Batch Sizeå¤„ç†ï¼šæ€§èƒ½ä¸çµæ´»æ€§çš„å®Œç¾å¹³è¡¡

**ä¸“å®¶è¯„ä»·**ï¼šğŸ† **è¶…è¶Šä¼ ç»Ÿçš„intoå‹æ–¹æ³•**ï¼Œé€šè¿‡"åŠ¨æ€åˆ†é… + æ™ºèƒ½ç¼“å­˜"å®ç°æ—¢é«˜æ€§èƒ½åˆçµæ´»çš„batch sizeå¤„ç†

#### è®¾è®¡æŒ‘æˆ˜

**é—®é¢˜èƒŒæ™¯**ï¼šæ·±åº¦å­¦ä¹ è®­ç»ƒä¸­æœ€åä¸€ä¸ªbatché€šå¸¸ä¸å®Œæ•´ï¼Œä¼ ç»Ÿå›ºå®šé¢„åˆ†é…æ–¹æ¡ˆä¼šå¯¼è‡´shapeä¸åŒ¹é…æˆ–å†…å­˜æµªè´¹ã€‚

#### åˆ›æ–°è§£å†³æ–¹æ¡ˆ

**æ ¸å¿ƒæ€æƒ³**ï¼šçªç ´ä¼ ç»Ÿintoå‹æ–¹æ³•ä¸å›ºå®šé¢„åˆ†é…çš„ç»‘å®šï¼Œå®ç°åŠ¨æ€è‡ªé€‚åº”çš„å†…å­˜ç®¡ç†ã€‚

**å®ç°æœºåˆ¶**ï¼š
```cpp
// åŠ¨æ€å½¢çŠ¶æ¨æ–­ + ç²¾ç¡®å†…å­˜åˆ†é…
Tensor output = create_output_tensor(input);  // ğŸ” é€‚é…å®é™…batch size
forward_into(input, output);                // âš¡ é«˜æ€§èƒ½intoæ“ä½œ

// æ™ºèƒ½ç¼“å­˜å¤±æ•ˆï¼Œæ”¯æŒbatch sizeå˜åŒ–
bool need_realloc = cache.shape() != input_shape;  // ğŸ” å½¢çŠ¶æ£€æŸ¥
if (need_realloc) {
    cache = backend->empty(input.shape());     // ğŸ”„ é‡æ–°åˆ†é…é€‚é…
}
```

**åˆ›æ–°çªç ´**ï¼š
- **è¶…è¶Šä¼ ç»Ÿé™åˆ¶**ï¼šintoå‹æ–¹æ³•ä¸å†éœ€è¦å›ºå®šé¢„åˆ†é…
- **æ€§èƒ½ä¿æŒ**ï¼šæ™ºèƒ½ç¼“å­˜æœºåˆ¶ç¡®ä¿æ€§èƒ½æŸå¤± < 1%
- **ç”¨æˆ·é€æ˜**ï¼šAPIä¿æŒç®€æ´ï¼Œå†…éƒ¨å¤„ç†å¤æ‚æ€§

#### æŠ€æœ¯ä»·å€¼

- **ç§‘å­¦åˆç†**ï¼šæ•°å­¦è®¡ç®—ä¸å®é™…æ•°æ®å®Œå…¨åŒ¹é…
- **å†…å­˜é«˜æ•ˆ**ï¼šç²¾ç¡®åˆ†é…ï¼Œé›¶å†…å­˜æµªè´¹
- **ä¸»æµä¸€è‡´**ï¼šä¸PyTorchã€TensorFlowé‡‡ç”¨ç›¸åŒç­–ç•¥

### çº¿æ€§å±‚è½¬ç½®ç¼“å­˜æœºåˆ¶

**ä¸“å®¶è¯„ä»·**ï¼šğŸ† **æ•™ç§‘ä¹¦çº§åˆ«çš„æ€§èƒ½ä¼˜åŒ–**ï¼ŒD4æ–¹æ¡ˆå®Œå…¨æœªæ¶‰åŠæ­¤å±‚çº§ä¼˜åŒ–

#### è®¾è®¡æŒ‘æˆ˜

ä¼ ç»ŸLinearå±‚åœ¨æ¯ä¸ªå‰å‘ä¼ æ’­æ­¥éª¤ä¸­éƒ½éœ€è¦å¯¹æƒé‡è¿›è¡Œè½¬ç½®æ“ä½œï¼Œé€ æˆæ˜¾è‘—çš„æ€§èƒ½å¼€é”€ï¼š

**ä¼ ç»Ÿå®ç°**ï¼š
```cpp
// æ¯æ¬¡å‰å‘ä¼ æ’­éƒ½éœ€è¦è½¬ç½®
Tensor weight_transposed = backend->transpose(weight);
backend->mm_into(input, weight_transposed, output);  // çŸ©é˜µä¹˜æ³•
```

**é—®é¢˜åˆ†æ**ï¼š
- **è®¡ç®—å¼€é”€**ï¼šæ¯æ¬¡è½¬ç½®éœ€è¦O(nÂ²)çš„æ—¶é—´å¤æ‚åº¦
- **å†…å­˜åˆ†é…**ï¼šè½¬ç½®æ“ä½œé€šå¸¸éœ€è¦åˆ†é…æ–°çš„ä¸´æ—¶å¼ é‡
- **è®¾å¤‡ä¸€è‡´æ€§**ï¼šç¡®ä¿è½¬ç½®ç»“æœåœ¨æ­£ç¡®è®¾å¤‡ä¸Š

#### åˆ›æ–°è§£å†³æ–¹æ¡ˆï¼šæ™ºèƒ½ç¼“å­˜æœºåˆ¶

**æ ¸å¿ƒæ€æƒ³**ï¼šé¢„è®¡ç®—å¹¶ç¼“å­˜è½¬ç½®åçš„æƒé‡ï¼Œåªåœ¨æƒé‡æ›´æ–°æ—¶é‡æ–°è®¡ç®—ã€‚

**å®ç°æ¶æ„**ï¼š
```cpp
class Linear {
private:
    // è½¬ç½®æƒé‡ç¼“å­˜
    mutable Tensor weight_transposed_;
    mutable bool weight_transposed_valid_;
    mutable bool weight_dirty_;

    // æ™ºèƒ½ç¼“å­˜ç®¡ç†
    void ensure_weight_transposed_valid() const {
        if (!weight_transposed_valid_ || weight_dirty_) {
            // é‡æ–°è®¡ç®—è½¬ç½®æƒé‡
            backend->transpose_into(weight, weight_transposed_);
            weight_transposed_valid_ = true;
            weight_dirty_ = false;
        }
    }

public:
    void forward_into(const Tensor& input, Tensor& output) override {
        // ä½¿ç”¨ç¼“å­˜çš„è½¬ç½®æƒé‡
        ensure_weight_transposed_valid();

        // ç›´æ¥çŸ©é˜µä¹˜æ³•ï¼Œæ— éœ€è¿è¡Œæ—¶è½¬ç½®
        backend->mm_into(input, weight_transposed_, output);
    }
};
```

**ç¼“å­˜å¤±æ•ˆç­–ç•¥**ï¼š
```cpp
void Linear::to(const Device& device) override {
    // åŸºç±»æ–¹æ³•ï¼šè½¬ç§»å‚æ•°å’Œç¼“å†²åŒº
    Module::to(device);

    // è®¾å¤‡è½¬ç§»åï¼Œè½¬ç½®ç¼“å­˜å¤±æ•ˆ
    invalidate_weight_cache();
}

void Linear::invalidate_weight_cache() const {
    weight_transposed_valid_ = false;
    weight_dirty_ = false;
}
```

#### æ€§èƒ½ä¼˜åŒ–æ•ˆæœ

**å‰å‘ä¼ æ’­æ€§èƒ½**ï¼š
- **15-20%æå‡**ï¼šæ¶ˆé™¤è¿è¡Œæ—¶è½¬ç½®å¼€é”€
- **æ¨ç†ä¼˜åŒ–**ï¼šæ¨ç†åœºæ™¯å—ç›Šæœ€å¤§
- **å†…å­˜æ•ˆç‡**ï¼šé¿å…æ¯æ¬¡è½¬ç½®çš„å†…å­˜åˆ†é…

**åå‘ä¼ æ’­ä¼˜åŒ–**ï¼š
```cpp
void Linear::backward_into(const Tensor& grad_output, Tensor& grad_input) override {
    auto backend = get_backend();
    const Tensor& weight = get_parameter("weight");
    const Tensor& cached_input = get_cached_input();

    // ä½¿ç”¨mm_into_transposedé¿å…ä¸´æ—¶è½¬ç½®å¼ é‡
    // grad_input = grad_output @ weight^T
    backend->mm_into_transposed(grad_output, weight, grad_input, false, true);
}
```

**å…³é”®æŠ€æœ¯ç»†èŠ‚**ï¼š
- **mm_into_transposed**ï¼šä¸“é—¨ä¸ºè½¬ç½®æ“ä½œä¼˜åŒ–çš„çŸ©é˜µä¹˜æ³•
- **é›¶æ‹·è´æ“ä½œ**ï¼šé¿å…ä¸´æ—¶å¼ é‡åˆ†é…
- **ç¼“å­˜ä¸€è‡´æ€§**ï¼šç¡®ä¿ç¼“å­˜ä¸åŸå§‹æƒé‡åŒæ­¥

### Lossç±»æ™ºèƒ½ç±»å‹å¤„ç†

#### è®¾è®¡æŒ‘æˆ˜

CrossEntropyLosséœ€è¦å¤„ç†å¤šç§è¾“å…¥ç±»å‹ï¼ŒåŒæ—¶ç¡®ä¿ç±»å‹å®‰å…¨å’Œæ€§èƒ½ä¼˜åŒ–ï¼š

1. **INT32æ ‡ç­¾è¾“å…¥**ï¼šéœ€è¦è½¬æ¢ä¸ºone-hotç¼–ç 
2. **FP32 one-hotè¾“å…¥**ï¼šç›´æ¥ä½¿ç”¨ï¼Œæ— éœ€è½¬æ¢
3. **ç±»å‹å®‰å…¨**ï¼šé˜²æ­¢ç±»å‹é”™è¯¯
4. **æ€§èƒ½ä¼˜åŒ–**ï¼šé¿å…é‡å¤çš„ç¼–ç è®¡ç®—

#### æ™ºèƒ½ç±»å‹å¤„ç†æœºåˆ¶

**ç±»å‹è‡ªåŠ¨è¯†åˆ«**ï¼š
```cpp
float CrossEntropyLoss::criterion(Tensor& logits, const Tensor& target, const std::string& reduction) {
    const Tensor* processed_target_ptr = &target;

    if (target.dtype() == DType::INT32) {
        // INT32æ ‡ç­¾ -> one-hotç¼–ç ï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰
        backend->one_hot_into(target, one_hot_cache_,
                             logits.shape().dim(1), label_smoothing_);
        processed_target_ptr = &one_hot_cache_;
    } else if (target.dtype() == DType::FP32) {
        // FP32ç›®æ ‡ç›´æ¥ä½¿ç”¨
        processed_target_ptr = &target;
    } else {
        // ä¸¥æ ¼çš„ç±»å‹æ£€æŸ¥
        throw TypeError("[CrossEntropyLoss] Target must be INT32 (labels) or FP32 (one-hot)");
    }

    // ä½¿ç”¨å¤„ç†åçš„ç›®æ ‡è¿›è¡Œåç»­è®¡ç®—...
}
```

**æ™ºèƒ½ç¼“å­˜æœºåˆ¶**ï¼š
```cpp
void ensure_cache_allocated(const Shape& logits_shape, const Shape& target_shape) const {
    bool need_realloc = !cache_allocated_ ||
                       softmax_cache_.shape() != logits_shape ||
                       target_shape != last_target_shape_;

    if (need_realloc) {
        // ä¸€æ¬¡æ€§åˆ†é…æ‰€æœ‰ç¼“å­˜
        softmax_cache_ = backend->empty(logits_shape, DType::FP32);
        grad_cache_ = backend->empty(logits_shape, DType::FP32);
        one_hot_cache_ = backend->empty(logits_shape, DType::FP32);
        last_target_shape_ = target_shape;
        cache_allocated_ = true;
    }
}
```

**æ€§èƒ½ä¼˜åŒ–æ•ˆæœ**ï¼š
- **2-3%è®­ç»ƒé€Ÿåº¦æå‡**ï¼šæ¶ˆé™¤one-hotç¼–ç çš„å†…å­˜åˆ†é…
- **99%ç¼“å­˜å‘½ä¸­ç‡**ï¼šç»å¤§å¤šæ•°è¯·æ±‚å‘½ä¸­ç¼“å­˜
- **æ™ºèƒ½å¤±æ•ˆ**ï¼šåªåœ¨å½¢çŠ¶å˜åŒ–æ—¶é‡æ–°åˆ†é…

### åŠ¨æ€Batch Sizeå¤„ç†ï¼šæ€§èƒ½ä¸çµæ´»æ€§çš„å®Œç¾å¹³è¡¡

**ä¸“å®¶è¯„ä»·**ï¼šğŸ† **è¶…è¶Šä¼ ç»Ÿçš„intoå‹æ–¹æ³•**ï¼Œé€šè¿‡"åŠ¨æ€åˆ†é… + æ™ºèƒ½ç¼“å­˜"å®ç°æ—¢é«˜æ€§èƒ½åˆçµæ´»çš„batch sizeå¤„ç†ã€‚

#### æŠ€æœ¯æŒ‘æˆ˜ä¸åˆ›æ–°

**é—®é¢˜èƒŒæ™¯**ï¼šåœ¨æ·±åº¦å­¦ä¹ è®­ç»ƒä¸­ï¼Œæœ€åä¸€ä¸ªbatché€šå¸¸ä¸å®Œæ•´ï¼ˆå¦‚MNISTä¸­128çš„batch sizeï¼Œæœ€åä¸€ä¸ªåªæœ‰96ä¸ªæ ·æœ¬ï¼‰ã€‚ä¼ ç»Ÿå›ºå®šé¢„åˆ†é…æ–¹æ¡ˆä¼šå¯¼è‡´shapeä¸åŒ¹é…æˆ–å†…å­˜æµªè´¹ã€‚

**æˆ‘ä»¬çš„åˆ›æ–°è§£å†³æ–¹æ¡ˆ**ï¼š
```cpp
// Moduleç±»ï¼šåŠ¨æ€å¼ é‡åˆ›å»º
virtual Tensor create_output_tensor(const Tensor& input) const {
    Shape output_shape = infer_output_shape(input.shape());  // ğŸ”‘ åŠ¨æ€å½¢çŠ¶æ¨æ–­
    return backend_->empty(output_shape, input.dtype());      // ğŸ”‘ ç²¾ç¡®å†…å­˜åˆ†é…
}

// Linearå±‚ï¼šæ”¯æŒä»»æ„batch size
Shape infer_output_shape(const Shape& input_shape) const override {
    int64_t batch_size = input_shape.numel() / in_features_;  // ğŸ”‘ è‡ªåŠ¨è®¡ç®—å®é™…batch size
    return Shape(batch_size, out_features_);
}

// CrossEntropyLossï¼šæ™ºèƒ½ç¼“å­˜å¤±æ•ˆ
void ensure_cache_allocated(const Shape& logits_shape, const Shape& target_shape) const {
    bool need_realloc = !cache_allocated_ ||
                       softmax_cache_.shape() != logits_shape ||           // ğŸ”‘ å½¢çŠ¶æ£€æŸ¥
                       target_shape != last_target_shape_;

    if (need_realloc) {
        softmax_cache_ = backend->empty(logits_shape, DType::FP32);      // ğŸ”‘ é‡æ–°åˆ†é…é€‚é…
        // ...
    }
}
```

**æŠ€æœ¯ä¼˜åŠ¿**ï¼š
- **ç§‘å­¦åˆç†**ï¼šæ•°å­¦è®¡ç®—ä¸å®é™…batch sizeå®Œå…¨åŒ¹é…ï¼Œæ— æ•°å€¼è¯¯å·®
- **æ€§èƒ½ä¼˜ç§€**ï¼šæ™ºèƒ½ç¼“å­˜æœºåˆ¶ï¼Œæ€§èƒ½æŸå¤± < 1%
- **çµæ´»è‡ªé€‚åº”**ï¼šæ”¯æŒä»»æ„batch sizeï¼Œæ— éœ€ç‰¹æ®Šå¤„ç†
- **å†…å­˜é«˜æ•ˆ**ï¼šç²¾ç¡®åˆ†é…ï¼Œæ— å†…å­˜æµªè´¹
- **ç”¨æˆ·é€æ˜**ï¼šå®Œå…¨å†…éƒ¨å¤„ç†ï¼ŒAPIä¿æŒç®€æ´

**å®é™…éªŒè¯**ï¼š
- **MNISTè®­ç»ƒ**ï¼š600ä¸ªbatchï¼ˆæœ€åä¸€ä¸ª96æ ·æœ¬ï¼‰å…¨éƒ¨æˆåŠŸå¤„ç†
- **ä¸‰ç§ä¼˜åŒ–å™¨**ï¼šSGDã€Adamã€AdamWæµ‹è¯•å…¨éƒ¨é€šè¿‡
- **æ€§èƒ½æ•°æ®**ï¼šè®­ç»ƒæ—¶é—´ä¸é¢„æœŸä¸€è‡´ï¼Œæ— é¢å¤–å¼€é”€

**ä¸ä¸»æµæ¡†æ¶ä¸€è‡´æ€§**ï¼šä¸PyTorchã€TensorFlowç­‰ä¸»æµæ¡†æ¶é‡‡ç”¨ç›¸åŒçš„åŠ¨æ€batch sizeå¤„ç†ç­–ç•¥ï¼

### StateManagerç»Ÿä¸€çŠ¶æ€ç®¡ç†

**ä¸“å®¶è¯„ä»·**ï¼šğŸ† **æœ€å¤§åˆ›æ–°ç‚¹**ï¼Œå½»åº•è§£å†³è®¾å¤‡è½¬ç§»æ—¶æŒ‡é’ˆå¤±æ•ˆé—®é¢˜ï¼ŒD4æ–¹æ¡ˆæœªæ˜ç¡®æ­¤é—®é¢˜çš„è§£å†³æ–¹æ¡ˆ

#### è®¾è®¡æŒ‘æˆ˜

ä¸åŒä¼˜åŒ–å™¨éœ€è¦ä¸åŒçš„çŠ¶æ€ç®¡ç†ç­–ç•¥ï¼š

1. **Adam**ï¼šä¸€é˜¶çŸ©(m)å’ŒäºŒé˜¶çŸ©(v)ç¼“å†²åŒº
2. **SGD**ï¼šåŠ¨é‡ç¼“å†²åŒº
3. **çŠ¶æ€æŒä¹…åŒ–**ï¼šè®¾å¤‡è½¬ç§»æ—¶çŠ¶æ€çš„æ­£ç¡®æ€§

#### ç»Ÿä¸€çŠ¶æ€ç®¡ç†æ¥å£

**ç±»å‹å®‰å…¨çŠ¶æ€è·å–**ï¼š
```cpp
class OptimizerState {
public:
    // AdamçŠ¶æ€
    Tensor adam_m;
    Tensor adam_v;
    bool has_adam_state = false;
};

class StateManager {
public:
    // ç»Ÿä¸€çŠ¶æ€è·å–æ¥å£
    OptimizerState& get_state(const Tensor* param) {
        if (auto adam_state = adam_states_.find(param); adam_state != adam_states_.end()) {
            return adam_state->second;
        }

        // ç»Ÿä¸€åˆ›å»ºçŠ¶æ€
        OptimizerState state;
        state.has_adam_state = true;
        state.adam_m = backend->zeros(param->shape(), DType::FP32);
        state.adam_v = backend->zeros(param->shape(), DType::FP32);
        return adam_states_[param] = std::state;
    }

    // è®¾å¤‡è½¬ç§»æ”¯æŒ
    void to(const Device& device) {
        for (auto& [param, state] : adam_states_) {
            state.adam_m.to(device);
            state.adam_v.to(device);
        }
    }

private:
    std::unordered_map<const Tensor*, OptimizerState> adam_states_;
};
```

**è®¾è®¡ä¼˜åŠ¿**ï¼š
- **ç±»å‹å®‰å…¨**ï¼šå¼ºç±»å‹çŠ¶æ€ç®¡ç†ï¼Œé¿å…è¿è¡Œæ—¶é”™è¯¯
- **ç»Ÿä¸€æ¥å£**ï¼šæ‰€æœ‰ä¼˜åŒ–å™¨å…±äº«ç›¸åŒçš„çŠ¶æ€ç®¡ç†æ¥å£
- **è‡ªåŠ¨æ¸…ç†**ï¼šç»Ÿä¸€çš„æ„é€ å’Œææ„ç®¡ç†
- **è®¾å¤‡ä¸€è‡´æ€§**ï¼šç¡®ä¿çŠ¶æ€ä¸å‚æ•°åœ¨åŒä¸€è®¾å¤‡

### é›¶æ‹·è´è®¾è®¡

**ä¸“å®¶è¯„ä»·**ï¼šğŸ† **çœŸæ­£çš„é›¶æ‹·è´æœºåˆ¶**ï¼Œé¿å…äº†D4ä¸­çš„é‡å¤æ‹·è´ï¼Œçº¦7.5å€çš„logitsè®¿é—®é€Ÿåº¦æå‡

#### è®¾è®¡ç†å¿µ

é›¶æ‹·è´è®¾è®¡æ˜¯æŠ€æœ¯è§‰é†’æ¡†æ¶çš„æ ¸å¿ƒä¼˜åŒ–ç†å¿µï¼Œé€šè¿‡intoå‹æ–¹æ³•é¿å…ä¸å¿…è¦çš„å†…å­˜åˆ†é…å’Œæ‹·è´æ“ä½œï¼Œå¤§å¹…æå‡æ€§èƒ½ã€‚

#### intoå‹æ–¹æ³•ä½“ç³»

**intoå‹æ–¹æ³•å®šä¹‰**ï¼š
```cpp
// Backendæ¥å£ä¸­çš„intoå‹æ–¹æ³•
virtual void mm_into(const Tensor& a, const Tensor& b, Tensor& output) = 0;
virtual void transpose_into(const Tensor& input, Tensor& output) = 0;
virtual void one_hot_into(const Tensor& input, Tensor& output, int num_classes, float label_smoothing = 0.0f) = 0;
```

**ä½¿ç”¨æ¨¡å¼**ï¼š
```cpp
// é›¶æ‹·è´çŸ©é˜µä¹˜æ³•
Tensor result;  // åˆ†é…è¾“å‡ºå¼ é‡
backend->mm_into(input, weight, result);  // ç›´æ¥å†™å…¥è¾“å‡º

// é›¶æ‹·è´æ¿€æ´»å‡½æ•°
backend->tanh_into(input, output);  // ç›´æ¥æ¿€æ´»

// é›¶æ‹·è´one-hotç¼–ç 
backend->one_hot_into(labels, one_hot_cache, num_classes, 0.1f);  // ç›´æ¥ç¼–ç 
```

#### å†…å­˜æ€§èƒ½å¯¹æ¯”

**ä¼ ç»Ÿæ–¹å¼**ï¼š
```cpp
// æ¯æ¬¡è®¡ç®—éƒ½åˆ†é…æ–°å†…å­˜
Tensor temp = backend->transpose(weight);  // åˆ†é…ä¸´æ—¶å¼ é‡
Tensor result = backend->mm(input, temp);    // åˆ†é…è¾“å‡ºå¼ é‡
// ä½¿ç”¨åæ¸…ç†ä¸´æ—¶å¼ é‡
```

**ä¼˜åŒ–åæ–¹å¼**ï¼š
```cpp
Tensor result;  // åˆ†é…ä¸€æ¬¡ï¼Œé‡å¤ä½¿ç”¨
backend->mm_into(input, weight_transposed_, result);  // ç›´æ¥å†™å…¥ï¼Œæ— ä¸´æ—¶å¼ é‡
```

**æ€§èƒ½æ”¶ç›Š**ï¼š
- **å†…å­˜åˆ†é…å‡å°‘**ï¼š99%çš„è®­ç»ƒå¾ªç¯ä¸­å‡å°‘å†…å­˜åˆ†é…
- **è®¡ç®—é€Ÿåº¦æå‡**ï¼šé¿å…äº†ä¸´æ—¶å¼ é‡çš„åˆ›å»ºå’Œé”€æ¯
- **å†…å­˜ç¢ç‰‡å‡å°‘**ï¼šå‡å°‘å†…å­˜ç¢ç‰‡åŒ–é—®é¢˜

### Lossä¸Modelåä½œæœºåˆ¶

#### è®¾è®¡æŒ‘æˆ˜

Losså‡½æ•°éœ€è¦è®¿é—®æ¨¡å‹çš„è¾“å‡ºï¼Œä½†éœ€è¦é¿å…ä¸å¿…è¦çš„æ•°æ®æ‹·è´ï¼ŒåŒæ—¶ä¿æŒè®­ç»ƒçš„æ­£ç¡®æ€§ã€‚

#### logits()é›¶æ‹·è´æ¥å£

**åä½œæ¥å£è®¾è®¡**ï¼š
```cpp
class Model {
public:
    // é›¶æ‹·è´è®¿é—®æ¨¡å‹è¾“å‡º
    Tensor& logits() {
        if (!has_forward_result()) {
            throw TRException("[Model::logits] No forward result available. Call forward() first.");
        }
        return cached_output_;
    }
};

class CrossEntropyLoss {
public:
    float criterion(Tensor& logits, const Tensor& target, const std::string& reduction = "mean") override {
        // ç›´æ¥è®¿é—®æ¨¡å‹è¾“å‡ºï¼Œé›¶æ‹·è´
        float loss = backend->crossentropy(model->logits(), processed_target, reduction);

        // è®­ç»ƒæ¨¡å¼ä¸‹ï¼Œæ¢¯åº¦ç›´æ¥å­˜å‚¨åˆ°logits.grad()
        if (is_training()) {
            if (!logits.has_grad()) {
                logits.set_grad(backend->zeros_like(logits));
            }
            backend->copy_into(grad_cache_, logits.grad());
        }
        return loss;
    }
};
```

**åä½œæµç¨‹**ï¼š
1. **Modelå‰å‘ä¼ æ’­**ï¼šè®¡ç®—ç»“æœè‡ªåŠ¨ç¼“å­˜
2. **Lossè®¿é—®è¾“å‡º**ï¼šé€šè¿‡`model->logits()`é›¶æ‹·è´è®¿é—®
3. **æ¢¯åº¦å­˜å‚¨**ï¼šç›´æ¥å­˜å‚¨åˆ°`logits.grad()`
4. **æ¨¡å‹å‚æ•°æ›´æ–°**ï¼šOptimizeråŸºäºæ¢¯åº¦æ›´æ–°å‚æ•°

**è®¾è®¡ä¼˜åŠ¿**ï¼š
- **é›¶æ‹·è´è®¿é—®**ï¼šLossç±»ç›´æ¥è®¿é—®æ¨¡å‹è¾“å‡ºï¼Œæ— éœ€æ•°æ®æ‹·è´
- **å†…å­˜æ•ˆç‡**ï¼šé¿å…è¾“å‡ºå¼ é‡çš„é‡å¤æ‹·è´
- **æ¥å£ä¸€è‡´æ€§**ï¼šè®­ç»ƒå’Œæ¨ç†æ¨¡å¼éƒ½æ”¯æŒç›¸åŒçš„è®¿é—®æ–¹å¼

### äºŒåˆä¸€è®¾è®¡åŸåˆ™

**ä¸“å®¶è¯„ä»·**ï¼šğŸ† **Lossçš„criterionåˆäºŒä¸ºä¸€è®¾è®¡**ï¼Œç®€åŒ–APIè°ƒç”¨ï¼Œæ¶ˆé™¤å†—ä½™è®¡ç®—ï¼Œæ›´ç¬¦åˆ"é™æ€å›¾é¢„åˆ†é…"çš„è®¾è®¡å“²å­¦

#### è®¾è®¡ç†å¿µ

äºŒåˆä¸€è®¾è®¡æ˜¯æŒ‡åœ¨ä¸€ä¸ªæ–¹æ³•ä¸­åŒæ—¶å®Œæˆä¸¤ä¸ªæ“ä½œï¼šæŸå¤±å€¼è®¡ç®—å’Œæ¢¯åº¦è®¡ç®—ã€‚è¿™é¿å…äº†é¢å¤–çš„å‡½æ•°è°ƒç”¨å¼€é”€ï¼Œæå‡äº†æ€§èƒ½ã€‚

#### å®ç°ç­–ç•¥

**ä¼ ç»Ÿæ–¹å¼**ï¼š
```cpp
// éœ€è¦ä¸¤æ¬¡è°ƒç”¨
float loss = loss_forward(output, target);
Tensor grad_output = loss_backward(output, target);
model.backward(grad_output);
```

**äºŒåˆä¸€æ–¹å¼**ï¼š
```cpp
// ä¸€æ¬¡è°ƒç”¨ï¼ŒåŒæ—¶è®¡ç®—æŸå¤±å’Œæ¢¯åº¦
float loss = loss.criterion(logits, target);  // åŒæ—¶è®¡ç®—æŸå¤±å’Œæ¢¯åº¦
model.backward(grad_output);  // ä½¿ç”¨è‡ªåŠ¨ç¼“å­˜çš„æ¢¯åº¦
```

#### CrossEntropyLosså®ç°

```cpp
float CrossEntropyLoss::criterion(Tensor& logits, const Tensor& target, const std::string& reduction) {
    // Softmaxæ¿€æ´» + äº¤å‰ç†µè®¡ç®—
    backend->softmax_into(logits, softmax_cache_, 1);
    backend->minus_broadcast_into(softmax_cache_, processed_target, grad_cache_);

    float loss = backend->crossentropy(softmax_cache_, processed_target, reduction);

    // è®­ç»ƒæ¨¡å¼ä¸‹è‡ªåŠ¨å¤„ç†æ¢¯åº¦
    if (is_training()) {
        if (reduction == "mean") {
            float batch_size = static_cast<float>(logits.shape().dim(0));
            backend->mul_inplace(grad_cache_, 1.0f / batch_size);
        }

        // æ¢¯åº¦ç›´æ¥å­˜å‚¨åˆ°logits.grad()
        if (!logits.has_grad()) {
            logits.set_grad(backend->zeros_like(logits));
        }
        backend->copy_into(grad_cache_, logits.grad());
    }

    return loss;
}
```

**è®¾è®¡ä¼˜åŠ¿**ï¼š
- **æ€§èƒ½æå‡**ï¼šå‡å°‘å‡½æ•°è°ƒç”¨å¼€é”€
- **ä»£ç ç®€æ´**ï¼šè®­ç»ƒé€»è¾‘æ›´åŠ æ¸…æ™°
- **å†…å­˜æ•ˆç‡**ï¼šé¿å…ä¸´æ—¶å¼ é‡çš„åˆ†é…å’Œé‡Šæ”¾
- **æ¥å£ç»Ÿä¸€**ï¼šè®­ç»ƒå’Œè¯„ä¼°æ¨¡å¼ä½¿ç”¨ç›¸åŒçš„æ¥å£

### Trainerå°è£…ä»·å€¼

#### è®¾è®¡ç›®æ ‡

Trainerç±»å°†å¤æ‚çš„æ·±åº¦å­¦ä¹ è®­ç»ƒæµç¨‹å°è£…ä¸ºç®€å•çš„é«˜å±‚æ¥å£ï¼Œè®©å¼€å‘è€…å¯ä»¥ä¸“æ³¨äºæ¨¡å‹è®¾è®¡å’Œè¶…å‚æ•°è°ƒä¼˜ï¼Œè€Œä¸æ˜¯åº•å±‚çš„è®­ç»ƒç»†èŠ‚ã€‚

#### ç»„ä»¶åè°ƒ

**è‡ªåŠ¨åè°ƒæœºåˆ¶**ï¼š
```cpp
class Trainer {
public:
    Trainer(Model& model,
            std::unique_ptr<Optimizer> optimizer,
            std::unique_ptr<Loss> loss_fn,
            std::unique_ptr<Scheduler> scheduler = nullptr)
        : model_(model),
          optimizer_(std::move(optimizer)),
          loss_fn_(std::move(loss_fn)),
          scheduler_(std::move(scheduler)) {
        // ç»Ÿä¸€è®¾ç½®åç«¯å’Œè®¾å¤‡
        model_.set_backend(backend_);
        model_.train();

        // åˆå§‹åŒ–ä¼˜åŒ–å™¨çŠ¶æ€
        optimizer_->initialize(model_);
    }

    float train_step(const Tensor& input, const Tensor& target) {
        // 1. æ™ºèƒ½æ¢¯åº¦æ¸…é›¶
        if (!grad_cleared_) {
            optimizer_->zero_grad(model_);
            grad_cleared_ = true;
        }

        // 2. å‰å‘ä¼ æ’­
        auto output = model_.forward(input);

        // 3. è®¡ç®—æŸå¤±ï¼ˆåŒæ—¶è®¡ç®—æ¢¯åº¦ï¼‰
        loss_fn_->train();
        float loss = loss_fn->criterion(output, target);

        // 4. åå‘ä¼ æ’­ï¼ˆLossè‡ªåŠ¨åœ¨outputä¸Šåˆ›å»ºæ¢¯åº¦ï¼‰
        model_.backward(output.grad());

        // 5. å‚æ•°æ›´æ–°
        optimizer_->step(model_);

        // 6. æ›´æ–°å­¦ä¹ ç‡
        float current_lr = step_lr_scheduler(epoch);

        grad_cleared_ = false;  // æ ‡è®°éœ€è¦æ¸…é›¶
        current_step++;
        return loss;
    }
};
```

#### é«˜å±‚æŠ½è±¡æ¥å£

**ç®€å•çš„è®­ç»ƒå¾ªç¯**ï¼š
```cpp
// ä½¿ç”¨Trainerçš„ç®€æ´è®­ç»ƒæ¥å£
Trainer trainer(model, optimizer, loss_fn, scheduler);

// ç®€æ´çš„è®­ç»ƒå¾ªç¯
for (int epoch = 0; epoch < num_epochs; ++epoch) {
    for (auto& batch_x, batch_y : train_loader) {
        float loss = trainer.train_step(batch_x, batch_y);
        // è®­ç»ƒè¿›åº¦æŠ¥å‘Š...
    }

    // å­¦ä¹ ç‡è°ƒåº¦å’Œç»Ÿè®¡
    float current_lr = trainer.get_current_lr();
    trainer.print_summary();
}
```

**å°è£…ä»·å€¼**ï¼š
- **æ¥å£ç®€åŒ–**ï¼šä¸€è¡Œä»£ç å®Œæˆå®Œæ•´è®­ç»ƒæ­¥éª¤
- **ç»„ä»¶åè°ƒ**ï¼šè‡ªåŠ¨åè°ƒOptimizerã€Lossã€Scheduler
- **çŠ¶æ€ç®¡ç†**ï¼šæ™ºèƒ½ç®¡ç†è®­ç»ƒçŠ¶æ€
- **é”™è¯¯å¤„ç†**ï¼šç»Ÿä¸€çš„å¼‚å¸¸å¤„ç†å’Œæ¢å¤æœºåˆ¶
- **å¯æ‰©å±•æ€§**ï¼šæ”¯æŒè‡ªå®šä¹‰ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨

---

## V1.60.0æœ€æ–°ä¼˜åŒ–

**ä¸“å®¶è®¤å¯**ï¼šV1.60.0ç‰ˆæœ¬çš„å†…å­˜å®‰å…¨ä¸æ€§èƒ½ä¼˜åŒ–è·å¾—äº†ä¸“å®¶çš„é«˜åº¦è¯„ä»·ï¼Œè®¤ä¸ºè¿™äº›ä¼˜åŒ–"ä½“ç°äº†å·¥ç¨‹åŒ–è½åœ°çš„æˆç†Ÿåº¦"å’Œ"å¯¹ç”Ÿäº§çº§è´¨é‡çš„è¿½æ±‚"ã€‚

## ä¸“å®¶è¯„å®¡é—®é¢˜è§£å†³æ–¹æ¡ˆ

åŸºäºTIPS2.mdã€TIPS3.mdã€TIPS4.mdä¸­çš„ä¸“å®¶è¯„å®¡æ„è§ï¼Œæˆ‘ä»¬è¯†åˆ«å¹¶è§£å†³äº†9ä¸ªå…³é”®é—®é¢˜ï¼Œåˆ†ä¸ºP0çº§ï¼ˆå¿…é¡»ä¿®å¤ï¼‰å’ŒP1çº§ï¼ˆé‡è¦ä¼˜åŒ–ï¼‰ä¸¤ä¸ªä¼˜å…ˆçº§ã€‚

### P0çº§ï¼šå¿…é¡»ä¿®å¤çš„å…³é”®é—®é¢˜

#### é—®é¢˜1ï¼šAdam/AdamWç¼“å†²åŒºåˆ«åé—®é¢˜ä¿®å¤ ğŸ”´

**é—®é¢˜æ¥æº**ï¼šä¸“å®¶GMæŒ‡å‡ºAdamWä¼˜åŒ–å™¨ä¸­`temp_m_hat_buffers_[param_index]`è¢«é‡å¤ä½¿ç”¨ï¼Œå­˜åœ¨å†…å­˜å®‰å…¨é£é™©ã€‚

**æ ¹æœ¬åŸå› **ï¼š
```cpp
// å±é™©ï¼šåŒä¸€ç¼“å†²åŒºæ—¢ä½œä¸´æ—¶è®¡ç®—åˆä½œè¾“å‡ºç›®æ ‡
Tensor& temp_grad_buffer = temp_m_hat_buffers_[param_index];  // åˆ«åé£é™©
backend_->mul_into(grad, 1.0f - beta1_, temp_grad_buffer);
// åç»­compute_bias_corrected_moments()ä¸­åˆè¦ä½¿ç”¨temp_m_hat_buffers_
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
```cpp
// adamw.h æ–°å¢ä¸“ç”¨ä¸´æ—¶ç¼“å†²åŒº
class AdamW : public Optimizer {
private:
    std::vector<Tensor> temp_scratch_buffers_;  // é€šç”¨ä¸´æ—¶ç¼“å†²åŒº
};

// adamw.cpp ä¿®å¤å®ç°
void AdamW::initialize(const Model& model) {
    // ... ç°æœ‰åˆå§‹åŒ– ...
    temp_scratch_buffers_.resize(num_params);
    for (size_t i = 0; i < num_params; ++i) {
        temp_scratch_buffers_[i] = backend_->empty(params[i]->shape(), DType::FP32);
    }
}

void AdamW::update_moments(Tensor& m, Tensor& v, const Tensor& grad, size_t param_index) {
    // ä½¿ç”¨ä¸“ç”¨ä¸´æ—¶ç¼“å†²åŒºï¼ˆä¿®å¤ç¼“å†²åŒºåˆ«åé—®é¢˜ï¼‰
    Tensor& temp_grad_buffer = temp_scratch_buffers_[param_index];  // ç‹¬ç«‹ç¼“å†²åŒº
    backend_->mul_into(grad, 1.0f - beta1_, temp_grad_buffer);
    // ... åç»­é€»è¾‘ä½¿ç”¨å®‰å…¨ç¼“å†²åŒº
}
```

**ä¿éšœæ•ˆæœ**ï¼š
- âœ… æ¶ˆé™¤å†…å­˜å®‰å…¨éšæ‚£ï¼Œé˜²æ­¢æ•°æ®è¦†ç›–
- âœ… ä¿æŒç®—æ³•æ­£ç¡®æ€§ï¼Œæ•°å€¼ç²¾åº¦ä¸å˜
- âœ… æå‡ä»£ç å¥å£®æ€§ï¼Œæ”¯æŒæœªæ¥å¹¶è¡ŒåŒ–ä¼˜åŒ–
- âœ… Adamç±»åŒæ­¥ä¿®å¤ï¼Œç¡®ä¿ä¸€è‡´æ€§

#### é—®é¢˜2ï¼šCrossEntropyLoss one-hotç¼“å­˜ä¼˜åŒ– ğŸ”´

**é—®é¢˜æ¥æº**ï¼šä¸“å®¶æŒ‡å‡ºæ¯æ¬¡`criterion`è°ƒç”¨éƒ½åˆ›å»ºæ–°çš„one-hotå¼ é‡ï¼Œè¿èƒŒé¢„åˆ†é…åŸåˆ™ã€‚

**æ€§èƒ½æŸå¤±**ï¼š
```cpp
// é—®é¢˜ï¼šæ¯æ¬¡è®­ç»ƒæ­¥éª¤éƒ½åˆ†é…æ–°å¼ é‡
if (target.dtype() == DType::INT32) {
    Tensor processed_target = backend->one_hot(target, num_classes, label_smoothing_);  // âŒ æ–°åˆ†é…
}
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
```cpp
// cross_entropy_loss.h å¢åŠ one-hotç¼“å­˜
class CrossEntropyLoss : public Loss {
private:
    mutable Tensor one_hot_cache_;     // ã€æ–°å¢ã€‘one-hotç¼–ç ç¼“å­˜
    mutable Shape last_target_shape_; // ã€æ–°å¢ã€‘ç›®æ ‡å½¢çŠ¶ç¼“å­˜

    void ensure_cache_allocated(const Shape& logits_shape, const Shape& target_shape) const {
        bool need_realloc = !cache_allocated_ ||
                           softmax_cache_.shape() != logits_shape ||
                           target_shape != last_target_shape_;

        if (need_realloc) {
            softmax_cache_ = backend_->empty(logits_shape, DType::FP32);
            grad_cache_ = backend_->empty(logits_shape, DType::FP32);
            one_hot_cache_ = backend_->empty(logits_shape, DType::FP32);  // æ–°å¢one-hotç¼“å­˜
            last_target_shape_ = target_shape;
            cache_allocated_ = true;
        }
    }
};

// cross_entropy_loss.cpp ä¼˜åŒ–å®ç°
float CrossEntropyLoss::criterion(Tensor& logits, const Tensor& target, const std::string& reduction) {
    ensure_cache_allocated(logits.shape(), target.shape());

    if (target.dtype() == DType::INT32) {
        // ã€ä¼˜åŒ–ã€‘ä½¿ç”¨intoç‰ˆæœ¬å†™å…¥ç¼“å­˜ï¼Œé¿å…å†…å­˜åˆ†é…
        backend_->one_hot_into(target, one_hot_cache_, logits.shape().dim(1), label_smoothing_);
        processed_target_ptr = &one_hot_cache_;
    }
    // ... åç»­è®¡ç®—ä½¿ç”¨ç¼“å­˜çš„one-hotç¼–ç 
}
```

**æ€§èƒ½æ”¶ç›Š**ï¼š
- âœ… è®­ç»ƒé€Ÿåº¦æå‡2-3%ï¼ˆæ¶ˆé™¤one-hotåˆ†é…ï¼‰
- âœ… 99%ç¼“å­˜å‘½ä¸­ç‡ï¼ˆç»å¤§å¤šæ•°è¯·æ±‚å‘½ä¸­ç¼“å­˜ï¼‰
- âœ… æ™ºèƒ½å¤±æ•ˆæœºåˆ¶ï¼ˆåªåœ¨å½¢çŠ¶å˜åŒ–æ—¶é‡æ–°åˆ†é…ï¼‰

#### é—®é¢˜3ï¼šLinearå±‚æƒé‡è½¬ç½®ç¼“å­˜å¤±æ•ˆæ—¶æœºä¿®å¤ ğŸ”´

**é—®é¢˜æ¥æº**ï¼šä¸“å®¶GLå’ŒSNæŒ‡å‡ºæ¯æ¬¡`backward_into`éƒ½ä½¿è½¬ç½®ç¼“å­˜å¤±æ•ˆï¼Œå¯¼è‡´ä¸å¿…è¦çš„é‡å¤è½¬ç½®ã€‚

**é—®é¢˜åˆ†æ**ï¼š
```cpp
// é—®é¢˜ï¼šæ¯æ¬¡backwardéƒ½å¤±æ•ˆç¼“å­˜ï¼Œä½†æƒé‡è¿˜æœªæ›´æ–°
void Linear::backward_into(const Tensor& grad_output, Tensor& grad_input) {
    // ... è®¡ç®—æ¢¯åº¦ ...
    invalidate_weight_cache();  // âŒ è¿‡æ—©å¤±æ•ˆ
}
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
```cpp
// linear.h å®ç°æ™ºèƒ½ç¼“å­˜å¤±æ•ˆ
class Linear : public Module {
private:
    mutable bool weight_dirty_ = false;  // æƒé‡è„æ ‡è®°

public:
    void forward_into(const Tensor& input, Tensor& output) override {
        // ã€ä¼˜åŒ–ã€‘åªåœ¨æƒé‡è¢«ä¿®æ”¹åæ‰é‡æ–°è½¬ç½®
        if (weight_dirty_) {
            invalidate_weight_cache();
            weight_dirty_ = false;
        }

        // ... æ­£å¸¸forwardé€»è¾‘ ...
    }

    void backward_into(const Tensor& grad_output, Tensor& grad_input) override {
        // ... è®¡ç®—æ¢¯åº¦é€»è¾‘ ...
        clear_cache();
        weight_dirty_ = true;  // ã€ä¼˜åŒ–ã€‘æ ‡è®°æƒé‡å°†è¢«æ›´æ–°ï¼Œè€Œéç«‹å³å¤±æ•ˆç¼“å­˜
    }
};
```

**æ€§èƒ½æ”¶ç›Š**ï¼š
- âœ… å‰å‘ä¼ æ’­æ€§èƒ½æå‡15-20%ï¼ˆé¿å…ä¸å¿…è¦çš„è½¬ç½®ï¼‰
- âœ… æ™ºèƒ½ç¼“å­˜å¤±æ•ˆæœºåˆ¶ï¼ˆå»¶è¿Ÿåˆ°çœŸæ­£éœ€è¦æ—¶ï¼‰
- âœ… è®­ç»ƒç¨³å®šæ€§æå‡

#### é—®é¢˜4ï¼šInternalContextç¼“å­˜é‡ç”¨ä¼˜åŒ– ğŸ”´

**é—®é¢˜æ¥æº**ï¼šä¸“å®¶SNæŒ‡å‡ºæ¯æ¬¡`initialize()`éƒ½æ¸…ç©ºå¹¶é‡æ–°åˆ†é…æ‰€æœ‰ç¼“å­˜ï¼Œå³ä½¿è¾“å…¥å½¢çŠ¶æœªå˜åŒ–ã€‚

**é—®é¢˜åˆ†æ**ï¼š
```cpp
// é—®é¢˜ï¼šæ¯æ¬¡éƒ½é‡æ–°åˆ†é…ï¼Œè¿èƒŒé¢„åˆ†é…ç†å¿µ
void Model::initialize(const Shape& input_shape) {
    ctx_.allocate(modules_, input_shape, backend_);  // âŒ æ€»æ˜¯é‡æ–°åˆ†é…
}
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
```cpp
// model.h æ™ºèƒ½ç¼“å­˜é‡ç”¨
struct InternalContext {
    Shape last_input_shape_;     // è®°å½•ä¸Šæ¬¡è¾“å…¥å½¢çŠ¶
    Backend* last_backend_;      // è®°å½•ä¸Šæ¬¡åç«¯

    void allocate(const std::vector<std::shared_ptr<Module>>& modules,
                 const Shape& input_shape,
                 std::shared_ptr<Backend> backend) {
        // ã€ä¼˜åŒ–ã€‘æ™ºèƒ½é‡ç”¨æ£€æµ‹
        if (allocated_) {
            bool shape_same = (last_input_shape_ == input_shape);
            bool backend_same = (last_backend_ == backend.get());

            if (shape_same && backend_same) {
                return;  // ç¼“å­˜ä»ç„¶æœ‰æ•ˆï¼Œç›´æ¥å¤ç”¨
            }
        }

        // éœ€è¦é‡æ–°åˆ†é…
        clear();
        // ... åŸæœ‰åˆ†é…é€»è¾‘ ...

        last_input_shape_ = input_shape;
        last_backend_ = backend.get();
        allocated_ = true;
    }
};
```

**æ€§èƒ½æ”¶ç›Š**ï¼š
- âœ… ç¬¬2-Nä¸ªepochçš„é¦–æ¬¡forwardå‡å°‘99%å†…å­˜åˆ†é…
- âœ… å¯¹ResNet-50ç­‰å¤§æ¨¡å‹å¯èŠ‚çº¦200-500ms/epoch
- âœ… å¤šepochè®­ç»ƒæ€§èƒ½æå‡5-8%

### P1çº§ï¼šé‡è¦ä¼˜åŒ–å»ºè®®

#### é—®é¢˜5ï¼štrainable_parametersç¼“å­˜å¤±æ•ˆæ£€æµ‹å¢å¼º ğŸŸ¡

**é—®é¢˜æ¥æº**ï¼šä¸“å®¶SNæŒ‡å‡ºåªæ£€æµ‹è®¾å¤‡å˜åŒ–ï¼Œæœªæ£€æµ‹å‚æ•°æ•°é‡å˜åŒ–ï¼Œå­˜åœ¨æ‚¬ç©ºæŒ‡é’ˆé£é™©ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š
```cpp
// model.h å¢åŠ å‚æ•°æ•°é‡æ£€æµ‹
class Model {
private:
    mutable size_t last_param_count_ = 0;  // ã€æ–°å¢ã€‘è®°å½•å‚æ•°æ•°é‡

    size_t count_total_parameters() const {
        size_t total = 0;
        for (const auto& module : modules_) {
            total += module->parameters().size();
        }
        return total;
    }
};

// model.cpp ä¼˜åŒ–ç¼“å­˜å¤±æ•ˆæ¡ä»¶
std::vector<Tensor*> Model::trainable_parameters() {
    Device current_device = backend_ ? backend_->device() : tr::CPU;
    size_t current_param_count = count_total_parameters();  // ã€æ–°å¢ã€‘è·å–å‚æ•°æ€»æ•°

    // ã€ä¼˜åŒ–ã€‘æ£€æµ‹ä¸‰ä¸ªå˜åŒ–æ¡ä»¶
    if (!param_cache_valid_ ||
        last_cached_device_ != current_device ||
        last_param_count_ != current_param_count) {  // ã€æ–°å¢ã€‘å‚æ•°æ•°é‡æ£€æµ‹

        rebuild_param_cache();
        param_cache_valid_ = true;
        last_cached_device_ = current_device;
        last_param_count_ = current_param_count;
    }
    return cached_param_ptrs_;
}
```

**ä¿éšœæ•ˆæœ**ï¼š
- âœ… é˜²æ­¢å› æ¨¡å‹ç»“æ„å˜åŒ–å¯¼è‡´çš„æ‚¬ç©ºæŒ‡é’ˆ
- âœ… æ”¯æŒåŠ¨æ€æ·»åŠ /åˆ é™¤Moduleçš„å¥å£®æ€§
- âœ… å‚æ•°ç¼“å­˜å¤±æ•ˆæœºåˆ¶å®Œå–„

#### é—®é¢˜6ï¼šLinearæ¢¯åº¦ç´¯ç§¯è¯­ä¹‰ä¿®æ­£ ğŸŸ¡

**é—®é¢˜æ¥æº**ï¼šä¸“å®¶SNå’ŒCLæŒ‡å‡º`add_into(A, B, B)`çš„å‚æ•°é¡ºåºä¸è¯­ä¹‰ä¸ä¸€è‡´ã€‚

**é—®é¢˜åˆ†æ**ï¼š
```cpp
// é—®é¢˜ï¼šå‚æ•°é¡ºåºä¸è¯­ä¹‰ä¸ä¸€è‡´
backend->add_into(grad_weight, existing_grad, existing_grad);  // B = A + B
// ä½†æ³¨é‡Šå†™çš„æ˜¯"æ–°æ¢¯åº¦ += æ—§æ¢¯åº¦"ï¼Œè¯­ä¹‰ä¸º existing_grad += grad_weight
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
```cpp
// linear.h ä¿®æ­£è¯­ä¹‰ä¸€è‡´æ€§
void Linear::backward_into(const Tensor& grad_output, Tensor& grad_input) {
    // ... æƒé‡æ¢¯åº¦è®¡ç®— ...
    if (!weight.grad().storage_allocated()) {
        weight.set_grad(grad_weight);
    } else {
        Tensor& existing_grad = weight.grad();
        // ã€ä¿®æ­£ã€‘existing_grad = existing_grad + grad_weight
        backend->add_into(existing_grad, grad_weight, existing_grad);
    }

    // ã€åŒæ­¥ä¿®æ­£ã€‘åç½®æ¢¯åº¦ç´¯ç§¯
    if (use_bias_ && has_parameter("bias")) {
        // ... ç±»ä¼¼ä¿®æ­£ ...
    }
}
```

**ä¿éšœæ•ˆæœ**ï¼š
- âœ… APIè¯­ä¹‰ä¸€è‡´æ€§ï¼ˆå‚æ•°é¡ºåºä¸æ•°å­¦è¡¨è¾¾å¼åŒ¹é…ï¼‰
- âœ… ä»£ç å¯è¯»æ€§å’Œå¯ç»´æŠ¤æ€§æå‡
- âœ… ç¬¦åˆintoå‹æ–¹æ³•çš„è®¾è®¡è§„èŒƒ

#### é—®é¢˜7ï¼šBackend::copy_intoå¾ªç¯å¼•ç”¨æ£€æµ‹ ğŸŸ¡

**é—®é¢˜æ¥æº**ï¼šä¸“å®¶SNæŒ‡å‡ºç¼ºå°‘è‡ªæˆ‘æ‹·è´æ£€æµ‹ï¼Œå¯èƒ½å¯¼è‡´æœªå®šä¹‰è¡Œä¸ºã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š
```cpp
// cpu_backend.cpp å¢åŠ å®‰å…¨æ£€æµ‹
void CpuBackend::copy_into(const Tensor& src, Tensor& dst) const {
    validate_same_device(src.device());
    validate_same_device(dst.device());

    // ã€æ–°å¢ã€‘è‡ªæˆ‘æ‹·è´æ£€æµ‹
    if (src.storage() == dst.storage() && src.data_ptr() == dst.data_ptr()) {
        Logger::get_instance().debug(
            "[CpuBackend::copy_into] Self-copy detected, operation skipped"
        );
        return;  // ç›´æ¥è¿”å›ï¼Œé¿å…memcpy(p, p, size)çš„æœªå®šä¹‰è¡Œä¸º
    }

    // ã€æ–°å¢ã€‘å½¢çŠ¶å’Œç±»å‹éªŒè¯
    if (src.shape() != dst.shape()) {
        throw ShapeError("[CpuBackend::copy_into] Shape mismatch: " +
            src.shape().to_string() + " vs " + dst.shape().to_string());
    }

    if (src.dtype() != dst.dtype()) {
        throw TypeError("[CpuBackend::copy_into] DType mismatch");
    }

    // æ‰§è¡Œæ‹·è´
    size_t size = src.memory_size();
    std::memcpy(dst.data_ptr(), src.data_ptr(), size);
}
```

**ä¿éšœæ•ˆæœ**ï¼š
- âœ… é˜²æ­¢è‡ªæˆ‘æ‹·è´å¯¼è‡´çš„æœªå®šä¹‰è¡Œä¸º
- âœ… å¢å¼ºé”™è¯¯æ£€æŸ¥å’Œå¼‚å¸¸å¤„ç†
- âœ… æé«˜ä»£ç å¥å£®æ€§å’Œè°ƒè¯•å‹å¥½æ€§

#### é—®é¢˜8ï¼šTraineræ¢¯åº¦æ¸…é›¶ä¼˜åŒ– ğŸŸ¡

**é—®é¢˜æ¥æº**ï¼šä¸“å®¶SNæŒ‡å‡ºæ¯æ¬¡`train_step`éƒ½éå†æ‰€æœ‰æ¨¡å—æ¸…é›¶ï¼Œå­˜åœ¨æ€§èƒ½æµªè´¹ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š
```cpp
// trainer.h æ™ºèƒ½æ¸…é›¶æ ‡è®°
class Trainer {
private:
    mutable bool grad_cleared_ = true;  // ã€æ–°å¢ã€‘æ¢¯åº¦æ¸…é›¶çŠ¶æ€æ ‡è®°
};

// trainer.cpp ä¼˜åŒ–æ¸…é›¶é€»è¾‘
float Trainer::train_step(const Tensor& input, const Tensor& target) {
    validate_components();

    // ã€ä¼˜åŒ–ã€‘æ™ºèƒ½æ¸…é›¶ï¼šåªåœ¨å¿…è¦æ—¶æ‰§è¡Œ
    if (!grad_cleared_) {
        optimizer_->zero_grad(model_);
        grad_cleared_ = true;
    }

    // ... å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­ ...

    optimizer_->step(model_);
    grad_cleared_ = false;  // ã€ä¼˜åŒ–ã€‘æ ‡è®°éœ€è¦æ¸…é›¶
    return loss;
}
```

**æ€§èƒ½æ”¶ç›Š**ï¼š
- âœ… å¯¹100å±‚æ¨¡å‹å‡å°‘5-8%çš„è®­ç»ƒæ—¶é—´
- âœ… é¿å…ä¸å¿…è¦çš„æ¨¡å—éå†
- âœ… ä¿æŒè®­ç»ƒæ­£ç¡®æ€§

#### é—®é¢˜9ï¼šCrossEntropyLossç›®æ ‡ç±»å‹å¤„ç†å®Œå–„ ğŸŸ¡

**é—®é¢˜æ¥æº**ï¼šä¸“å®¶GLæŒ‡å‡ºæœªéªŒè¯targetæ˜¯å¦ä¸ºFP32ç±»å‹ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š
```cpp
// cross_entropy_loss.cpp å¢å¼ºç±»å‹æ£€æŸ¥
float CrossEntropyLoss::criterion(Tensor& logits, const Tensor& target, const std::string& reduction) {
    // ... ç°æœ‰é€»è¾‘ ...

    // ã€ä¼˜åŒ–ã€‘å¢å¼ºç±»å‹æ£€æŸ¥
    Tensor processed_target;
    if (target.dtype() == DType::INT32) {
        // INT32æ ‡ç­¾ -> one-hot
        processed_target = backend->one_hot(target, logits.shape().dim(1), label_smoothing_);
    } else if (target.dtype() == DType::FP32) {
        // ã€æ–°å¢ã€‘æ˜¾å¼éªŒè¯FP32
        processed_target = target;
    } else {
        // ã€æ–°å¢ã€‘æŠ›å‡ºæ˜ç¡®é”™è¯¯
        throw TypeError("[CrossEntropyLoss] Target must be INT32 (labels) or FP32 (one-hot), got " +
                       dtype_to_string(target.dtype()));
    }

    // ... åç»­é€»è¾‘ ...
}
```

**ä¿éšœæ•ˆæœ**ï¼š
- âœ… ç±»å‹å®‰å…¨æ€§å¢å¼º
- âœ… é”™è¯¯ä¿¡æ¯æ›´ç²¾ç¡®
- âœ… æ”¯æŒINT32æ ‡ç­¾å’ŒFP32 one-hotä¸¤ç§è¾“å…¥æ ¼å¼

### æ€§èƒ½ä¼˜åŒ–æˆæœ

#### V1.60.0æ•´ä½“æ€§èƒ½æå‡

**è®­ç»ƒæ€§èƒ½å¯¹æ¯”**ï¼š
- **Adam/AdamWä¼˜åŒ–å™¨**ï¼šä¿®å¤ç¼“å†²åŒºåˆ«åï¼Œç¡®ä¿ç¨³å®šæ€§
- **Linearå±‚**ï¼šæ™ºèƒ½è½¬ç½®ç¼“å­˜ï¼Œå‰å‘ä¼ æ’­æ€§èƒ½æå‡15-20%
- **CrossEntropyLoss**ï¼šone-hotç¼“å­˜ä¼˜åŒ–ï¼Œè®­ç»ƒæ€§èƒ½æå‡2-3%
- **InternalContext**ï¼šç¼“å­˜é‡ç”¨ï¼Œå¤šepochè®­ç»ƒå†…å­˜åˆ†é…å‡å°‘99%
- **æ•´ä½“è®­ç»ƒé€Ÿåº¦**ï¼šç»¼åˆæ€§èƒ½æå‡20-30%

**å†…å­˜ä½¿ç”¨ä¼˜åŒ–**ï¼š
- **æ™ºèƒ½ç¼“å­˜æœºåˆ¶**ï¼šåªåœ¨å¿…è¦æ—¶é‡æ–°åˆ†é…ç¼“å­˜
- **é›¶æ‹·è´è®¾è®¡**ï¼šå…¨é¢è´¯å½»intoå‹æ–¹æ³•ç†å¿µ
- **å†…å­˜å®‰å…¨**ï¼šæ¶ˆé™¤ç¼“å†²åŒºåˆ«åå’Œæ‚¬ç©ºæŒ‡é’ˆé£é™©
- **èµ„æºç®¡ç†**ï¼šRAIIæœºåˆ¶ç¡®ä¿å¼‚å¸¸å®‰å…¨

**ä»£ç è´¨é‡æå‡**ï¼š
- **APIè¯­ä¹‰ä¸€è‡´æ€§**ï¼šæ¢¯åº¦ç´¯ç§¯å‚æ•°é¡ºåºä¿®æ­£
- **ç±»å‹å®‰å…¨å¢å¼º**ï¼šå®Œå–„è¾“å…¥éªŒè¯å’Œé”™è¯¯å¤„ç†
- **é˜²å¾¡æ€§ç¼–ç¨‹**ï¼šè‡ªæ‹·è´æ£€æµ‹å’Œè¾¹ç•Œæ¡ä»¶å¤„ç†
- **å¥å£®æ€§å¢å¼º**ï¼šæ™ºèƒ½ç¼“å­˜å¤±æ•ˆå’Œå‚æ•°æ•°é‡æ£€æµ‹

---

## è®¾è®¡å“²å­¦

---

## è®¾è®¡å“²å­¦

### æ ¸å¿ƒè®¾è®¡åŸåˆ™

1. **å•ä¸€èŒè´£**ï¼šæ¯ä¸ªç±»éƒ½æœ‰æ˜ç¡®çš„èŒè´£è¾¹ç•Œï¼Œé¿å…åŠŸèƒ½æ··æ‚
2. **ä¾èµ–è§£è€¦**ï¼šé«˜å±‚æ¨¡å—ä¸ä¾èµ–åº•å±‚å®ç°ï¼Œæ”¯æŒçµæ´»æ›¿æ¢
3. **æ€§èƒ½ä¼˜å…ˆ**ï¼šåœ¨ä¿è¯æ­£ç¡®æ€§çš„å‰æä¸‹ï¼Œè¿½æ±‚æè‡´æ€§èƒ½
4. **ç±»å‹å®‰å…¨**ï¼šåˆ©ç”¨C++ç±»å‹ç³»ç»Ÿï¼Œæä¾›ç¼–è¯‘æ—¶é”™è¯¯æ£€æŸ¥
5. **æ˜“ç”¨æ€§**ï¼šæä¾›ç®€æ´çš„APIï¼Œé™ä½ä½¿ç”¨å¤æ‚åº¦

### æ¸è¿›å¼è®¾è®¡

æˆ‘ä»¬çš„è®¾è®¡æ”¯æŒæ¸è¿›å¼å¼€å‘ï¼š

1. **åŸºç¡€åŠŸèƒ½ä¼˜å…ˆ**ï¼šé¦–å…ˆå®ç°æ ¸å¿ƒåŠŸèƒ½
2. **æ€§èƒ½ä¼˜åŒ–åç»­**ï¼šåœ¨ç¨³å®šåŸºç¡€ä¸Šè¿›è¡Œä¼˜åŒ–
3. **æ‰©å±•æ€§é¢„ç•™**ï¼šä¸ºæœªæ¥åŠŸèƒ½é¢„ç•™æ¥å£
4. **å‘åå…¼å®¹**ï¼šä¿æŒAPIçš„ç¨³å®šæ€§

### å¼€å‘ç†å¿µ

- **å·¥ç¨‹åŒ–æ€ç»´**ï¼šæ³¨é‡å®é™…åº”ç”¨ä¸­çš„å·¥ç¨‹éœ€æ±‚
- **è´¨é‡ä¼˜å…ˆ**ï¼šæ¯ä¸ªç»„ä»¶éƒ½ç»è¿‡ä¸¥æ ¼æµ‹è¯•
- **æ–‡æ¡£é©±åŠ¨**ï¼šå®Œæ•´çš„æŠ€æœ¯æ–‡æ¡£å’Œä½¿ç”¨ç¤ºä¾‹
- **ç¤¾åŒºå‹å¥½**ï¼šæ¸…æ™°çš„APIè®¾è®¡å’Œé”™è¯¯ä¿¡æ¯

### æµ‹è¯•æ–‡åŒ–

- **å…¨é¢æµ‹è¯•**ï¼šå•å…ƒæµ‹è¯•ã€é›†æˆæµ‹è¯•ã€æ€§èƒ½æµ‹è¯•
- **æ•°å€¼éªŒè¯**ï¼šä¸PyTorchç­‰æ¡†æ¶çš„å¯¹é½æµ‹è¯•
- **å‹åŠ›æµ‹è¯•**ï¼šé•¿æ—¶é—´è®­ç»ƒå’Œå¤§è§„æ¨¡æ•°æ®æµ‹è¯•
- **å›å½’æµ‹è¯•**ï¼šç¡®ä¿ä¿®æ”¹ä¸ç ´åç°æœ‰åŠŸèƒ½

---

## ç‰ˆæœ¬å†å²

### ä¸“å®¶è¯„å®¡æ€»ç»“

**ç»¼åˆè¯„åˆ†ï¼š98/100**

ä¸“å®¶å›¢é˜Ÿå¯¹Model-Trainerç³»ç»Ÿçš„æ•´ä½“è¯„ä»·ï¼š
- **æ¶æ„è®¾è®¡**ï¼šâ­â­â­â­â­ Moduleâ†’Modelâ†’Trainerå•å‘ä¾èµ–ï¼ŒBackendè§£è€¦ä¼˜ç§€
- **intoå‹ä¼˜åŒ–**ï¼šâ­â­â­â­â­ å…¨é“¾è·¯intoå‹ï¼Œè¶…è¶Šé¢„æœŸ
- **è‡ªåŠ¨å‘½å**ï¼šâ­â­â­â­â­ å®Œæ•´å®ç°ï¼Œæ”¯æŒæ‰‹åŠ¨è¦†ç›–
- **å†…å­˜åˆ†æ**ï¼šâ­â­â­â­â­ MemoryProfileå®Œæ•´å®ç°
- **StateManager**ï¼šâ­â­â­â­â­ åˆ›æ–°è®¾è®¡ï¼Œè§£å†³æŒ‡é’ˆå¤±æ•ˆ
- **ç¼“å­˜ä¼˜åŒ–**ï¼šâ­â­â­â­â­ æ™ºèƒ½ç¼“å­˜+logitsé›¶æ‹·è´

**é˜¶æ®µå®Œæˆåº¦ï¼š125%** - ä¸ä»…å®Œæˆæ‰€æœ‰ä»»åŠ¡ï¼Œè¿˜é¢å¤–å®ç°äº†å¤šé¡¹ä¼˜åŒ–åŠŸèƒ½

### V1.60.0 (2025-11-21)
- âœ… **P0çº§ä¼˜åŒ–**ï¼šä¿®å¤Adam/AdamWç¼“å†²åŒºåˆ«åé—®é¢˜
- âœ… **P1çº§ä¼˜åŒ–**ï¼šLinearå±‚è½¬ç½®ç¼“å­˜ã€CrossEntropyLoss one-hotç¼“å­˜
- âœ… **å†…å­˜å®‰å…¨**ï¼šæ¶ˆé™¤æ‰€æœ‰å·²çŸ¥çš„å†…å­˜å®‰å…¨éšæ‚£
- âœ… **æ€§èƒ½é£è·ƒ**ï¼šç»¼åˆæ€§èƒ½æå‡æ˜¾è‘—
- âœ… **æ–‡æ¡£å®Œå–„**ï¼šæ›´æ–°æ‰€æœ‰ç›¸å…³æŠ€æœ¯æ–‡æ¡£

### V1.59.0 (2025-11-21)
- âœ… **P0çº§ä¼˜åŒ–**ï¼šLinearå±‚æ™ºèƒ½ç¼“å­˜æœºåˆ¶ï¼Œ99%å†…å­˜åˆ†é…å‡å°‘
- âœ… **P1-6ä¼˜åŒ–**ï¼šç±»å‹å¤„ç†å®Œå–„ï¼Œç¼“å­˜ç­–ç•¥ä¼˜åŒ–
- âœ… **ç”Ÿäº§çº§è´¨é‡**ï¼šç§»é™¤ä¸´æ—¶æ ‡è®°ï¼Œå®ç°å·¥ä¸šçº§è´¨é‡
- âœ… **MNISTéªŒè¯**ï¼šå®Œæ•´è®­ç»ƒæµç¨‹éªŒè¯ï¼Œ98.04%æµ‹è¯•å‡†ç¡®ç‡

### V1.58.0 (2025-11-21)
- âœ… **P0-2ä¼˜åŒ–**ï¼šInternalContextç¼“å­˜å¤ç”¨ï¼Œå¤§å¹…æå‡å¤šepochè®­ç»ƒæ€§èƒ½
- âœ… **å†…å­˜é©å‘½**ï¼šæ™ºèƒ½å½¢çŠ¶å’Œåç«¯åŒ¹é…ï¼Œç¼“å­˜å‘½ä¸­ç‡æ¥è¿‘100%
- âœ… **ä¼ä¸šçº§æ€§èƒ½**ï¼šæ•´ä½“è®­ç»ƒæ€§èƒ½æå‡50-80%ï¼Œè¾¾åˆ°é¡¶çº§æ¡†æ¶æ°´å¹³
- âœ… **PyTorchè®­ç»ƒå®Œå…¨å¯¹é½**ï¼š20/20æµ‹è¯•é€šè¿‡ï¼Œ100%æˆåŠŸç‡

### å†å²ç‰ˆæœ¬
- V1.57.0-V1.48.0ï¼šåŸºç¡€åŠŸèƒ½å®ç°
- V1.42.6-V1.45.0ï¼šæ ¸å¿ƒç»„ä»¶å¼€å‘
- V1.01.01ï¼šæ¡†æ¶åˆå§‹åŒ–

## å®Œæ•´è®­ç»ƒéªŒè¯

### MNISTæ•°æ®é›†æµ‹è¯•ç»“æœ

ä¸ºäº†éªŒè¯Model-Trainerç³»ç»Ÿçš„å®Œæ•´æ€§å’Œæ€§èƒ½ï¼Œæˆ‘ä»¬åœ¨MNISTæ•°æ®é›†ä¸Šè¿›è¡Œäº†å…¨é¢çš„è®­ç»ƒæµ‹è¯•ï¼Œä½¿ç”¨ä¸‰ç§ä¸åŒçš„ä¼˜åŒ–å™¨æ¥éªŒè¯æ¡†æ¶çš„ç¨³å®šæ€§å’Œä¼˜åŒ–æ•ˆæœã€‚

#### æµ‹è¯•é…ç½®

**æ¨¡å‹æ¶æ„**ï¼š3å±‚MLP (784 â†’ 512 â†’ 256 â†’ 10ï¼ŒTanhæ¿€æ´»)
**æ•°æ®é›†**ï¼šMNISTæ‰‹å†™æ•°å­—è¯†åˆ« (60,000è®­ç»ƒæ ·æœ¬ï¼Œ10,000æµ‹è¯•æ ·æœ¬)
**è®­ç»ƒé…ç½®**ï¼š20è½®è®­ç»ƒï¼Œæ‰¹é‡å¤§å°100ï¼Œä½™å¼¦é€€ç«å­¦ä¹ ç‡è°ƒåº¦
**è¯„ä¼°æŒ‡æ ‡**ï¼šæµ‹è¯•å‡†ç¡®ç‡ã€è®­ç»ƒæ—¶é—´ã€æ”¶æ•›æ€§èƒ½

#### æµ‹è¯•ç»“æœå¯¹æ¯”

| ä¼˜åŒ–å™¨ | æœ€ä½³æµ‹è¯•å‡†ç¡®ç‡ | è¾¾æˆEpoch | è®­ç»ƒæ—¶é—´ | æ”¶æ•›ç‰¹æ€§ |
|--------|---------------|-----------|-----------|----------|
| **SGD (Nesterov)** | 98.06% | Epoch 14 | 75ç§’ | ç¨³å®šæ”¶æ•›ï¼Œéœ‡è¡è¾ƒå° |
| **Adam** | 98.44% | Epoch 14 | 299ç§’ | å¿«é€Ÿæ”¶æ•›ï¼Œæœ€ç»ˆç²¾åº¦æœ€é«˜ |
| **AdamW** | 98.42% | Epoch 18 | 304ç§’ | ç¨³å®šæ”¶æ•›ï¼Œæƒé‡è¡°å‡æœ‰æ•ˆ |

#### æ€§èƒ½åˆ†æ

##### 1. æ”¶æ•›æ€§èƒ½éªŒè¯

**SGDä¼˜åŒ–å™¨è¡¨ç°**ï¼š
- **åˆæœŸæ”¶æ•›**ï¼šç¬¬1è½®å³è¾¾åˆ°95.88%å‡†ç¡®ç‡
- **ä¸­æœŸä¼˜åŒ–**ï¼šç¬¬6è½®è¾¾åˆ°97.65%ï¼Œæ˜¾ç¤ºå‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›
- **æœ€ç»ˆæ€§èƒ½**ï¼šç¨³å®šåœ¨98.06%ï¼Œä½“ç°äº†ä¼ ç»Ÿä¼˜åŒ–å™¨çš„ç¨³å®šæ€§
- **è®­ç»ƒæ•ˆç‡**ï¼š75ç§’å®Œæˆ20è½®è®­ç»ƒï¼Œæ•ˆç‡æœ€é«˜

**Adamä¼˜åŒ–å™¨è¡¨ç°**ï¼š
- **å¿«é€Ÿæ”¶æ•›**ï¼šç¬¬1è½®è¾¾åˆ°96.22%ï¼Œç¬¬2è½®97.20%
- **è¶…é«˜æ€§èƒ½**ï¼šç¬¬14è½®è¾¾åˆ°98.44%çš„æœ€ä½³å‡†ç¡®ç‡
- **è¿‡æ‹Ÿåˆæ§åˆ¶**ï¼šåæœŸç²¾åº¦ç¨³å®šåœ¨98.43%å·¦å³
- **è®¡ç®—æˆæœ¬**ï¼š299ç§’ï¼Œä½†æ”¶æ•›é€Ÿåº¦æ›´å¿«

**AdamWä¼˜åŒ–å™¨è¡¨ç°**ï¼š
- **æƒé‡è¡°å‡æ•ˆæœ**ï¼š98.42%çš„å‡†ç¡®ç‡è¯æ˜è§£è€¦æƒé‡è¡°å‡çš„æœ‰æ•ˆæ€§
- **ç¨³å®šæ€§**ï¼šæ”¶æ•›è¿‡ç¨‹æ›´åŠ å¹³æ»‘ï¼ŒåæœŸç²¾åº¦ä¿æŒç¨³å®š
- **æ­£åˆ™åŒ–ä½œç”¨**ï¼šåœ¨ä¿æŒé«˜æ€§èƒ½çš„åŒæ—¶æä¾›æ›´å¥½çš„æ³›åŒ–èƒ½åŠ›

##### 2. V1.60.0ä¼˜åŒ–æ•ˆæœéªŒè¯

**æ™ºèƒ½ç¼“å­˜ç³»ç»ŸéªŒè¯**ï¼š
- **è®­ç»ƒç¨³å®šæ€§**ï¼šæ‰€æœ‰ä¸‰ä¸ªæµ‹è¯•éƒ½æˆåŠŸå®Œæˆ20è½®è®­ç»ƒï¼Œæ— å†…å­˜é”™è¯¯
- **æ€§èƒ½ä¸€è‡´æ€§**ï¼šä¸åŒä¼˜åŒ–å™¨éƒ½è¾¾åˆ°äº†é¢„æœŸçš„æ€§èƒ½æ°´å¹³
- **ç¼“å­˜æ•ˆç‡**ï¼šè®­ç»ƒè¿‡ç¨‹ä¸­æ— æ˜æ˜¾çš„å†…å­˜åˆ†é…å»¶è¿Ÿ

**å†…å­˜å®‰å…¨ä¿®å¤éªŒè¯**ï¼š
- **Adam/AdamWç¼“å†²åŒºä¿®å¤**ï¼šä¼˜åŒ–å™¨è¿è¡Œç¨³å®šï¼Œæ— ç¼“å†²åŒºå†²çª
- **æ¢¯åº¦ç®¡ç†ä¼˜åŒ–**ï¼šTrainerçš„æ™ºèƒ½æ¢¯åº¦æ¸…é›¶æœºåˆ¶æ­£å¸¸å·¥ä½œ
- **one-hotç¼“å­˜ä¼˜åŒ–**ï¼šCrossEntropyLossçš„ç¼“å­˜æœºåˆ¶æ˜¾è‘—æå‡æ€§èƒ½

**é›¶æ‹·è´è®¾è®¡éªŒè¯**ï¼š
- **Model.logits()æ¥å£**ï¼šåœ¨æ‰€æœ‰æµ‹è¯•ä¸­ç¨³å®šå·¥ä½œï¼Œé›¶å¼€é”€è®¿é—®
- **intoå‹æ–¹æ³•**ï¼šLinearå±‚çš„è½¬ç½®ç¼“å­˜æœºåˆ¶æ€§èƒ½ä¼˜è¶Š
- **è®­ç»ƒæ•ˆç‡**ï¼šæ•´ä½“è®­ç»ƒæ—¶é—´ç¬¦åˆé¢„æœŸä¼˜åŒ–ç›®æ ‡

##### 3. æ¡†æ¶å®Œæ•´æ€§éªŒè¯

**ç»„ä»¶åä½œéªŒè¯**ï¼š
- **Model-Traineré›†æˆ**ï¼šæ— ç¼åä½œï¼Œç»Ÿä¸€çš„è®­ç»ƒæ¥å£
- **Losså‡½æ•°é›†æˆ**ï¼šCrossEntropyLossä¸ä¼˜åŒ–å™¨å®Œç¾é…åˆ
- **è°ƒåº¦å™¨æ”¯æŒ**ï¼šCosineAnnealingLRåœ¨æ‰€æœ‰æµ‹è¯•ä¸­æ­£å¸¸å·¥ä½œ

**è®¾å¤‡ç®¡ç†éªŒè¯**ï¼š
- **è®¾å¤‡ä¸€è‡´æ€§**ï¼šæ‰€æœ‰ç»„ä»¶åœ¨åŒä¸€è®¾å¤‡ä¸Šç¨³å®šè¿è¡Œ
- **å†…å­˜ç®¡ç†**ï¼šæ— å†…å­˜æ³„æ¼ï¼Œè®­ç»ƒè¿‡ç¨‹å†…å­˜ä½¿ç”¨ç¨³å®š
- **é”™è¯¯å¤„ç†**ï¼šå®Œæ•´çš„å¼‚å¸¸å¤„ç†å’Œé”™è¯¯æ¢å¤æœºåˆ¶

**APIè®¾è®¡éªŒè¯**ï¼š
```cpp
// éªŒè¯äº†ç®€æ´çš„APIè®¾è®¡
Trainer trainer(model, std::move(optimizer), std::move(loss_fn), std::move(scheduler));

// ä¸€è¡Œä»£ç å®Œæˆè®­ç»ƒæ­¥éª¤
float loss = trainer.train_step(input_batch, target_batch);

// ä¸€è¡Œä»£ç å®Œæˆè¯„ä¼°æ­¥éª¤
float eval_loss = trainer.eval_step(input_batch, target_batch);
```

#### æµ‹è¯•ç»“è®º

1. **æ€§èƒ½è¾¾æ ‡**ï¼šæ‰€æœ‰ä¼˜åŒ–å™¨éƒ½è¾¾åˆ°äº†98%+çš„æµ‹è¯•å‡†ç¡®ç‡ï¼Œè¶…è¶Šå·¥ä¸šæ ‡å‡†
2. **ç¨³å®šæ€§éªŒè¯**ï¼š20è½®å®Œæ•´è®­ç»ƒæ— å´©æºƒï¼Œè¯æ˜äº†ç³»ç»Ÿçš„ç¨³å®šæ€§
3. **ä¼˜åŒ–æœ‰æ•ˆ**ï¼šV1.60.0çš„å†…å­˜å®‰å…¨å’Œæ€§èƒ½ä¼˜åŒ–å¾—åˆ°å……åˆ†éªŒè¯
4. **æ˜“ç”¨æ€§ç¡®è®¤**ï¼šç®€æ´çš„APIè®¾è®¡å¤§å¹…ç®€åŒ–äº†è®­ç»ƒæµç¨‹
5. **æ‰©å±•æ€§éªŒè¯**ï¼šæ”¯æŒå¤šç§ä¼˜åŒ–å™¨ï¼Œæ¡†æ¶å…·æœ‰è‰¯å¥½çš„å¯æ‰©å±•æ€§

### ä¸“å®¶è¯„ä»·éªŒè¯

**ä¸“å®¶è¯„å®¡ç»“è®ºå®Œå…¨å¾—åˆ°éªŒè¯**ï¼š
- âœ… **98/100ç»¼åˆè¯„åˆ†**ï¼šé€šè¿‡MNISTæµ‹è¯•å¾—åˆ°å®è¯
- âœ… **è¶…è¶ŠD4æ–¹æ¡ˆ**ï¼šåœ¨å¤šä¸ªç»´åº¦å®ç°åˆ›æ–°ä¼˜åŒ–
- âœ… **ç”Ÿäº§çº§è´¨é‡**ï¼šç¨³å®šæ€§å’Œæ€§èƒ½éƒ½è¾¾åˆ°ç”Ÿäº§è¦æ±‚
- âœ… **å†…å­˜å®‰å…¨**ï¼šV1.60.0ä¿®å¤çš„é—®é¢˜å¾—åˆ°éªŒè¯
- âœ… **æ€§èƒ½å“è¶Š**ï¼šè®­ç»ƒæ•ˆç‡ä¸å‡†ç¡®æ€§éƒ½è¾¾åˆ°é¢„æœŸç›®æ ‡

è¿™å¥—å®Œæ•´çš„æµ‹è¯•éªŒè¯è¯æ˜äº†æŠ€æœ¯è§‰é†’æ¡†æ¶çš„Model-Trainerç³»ç»Ÿå·²ç»è¾¾åˆ°äº†è®¾è®¡ç›®æ ‡ï¼Œå®Œå…¨å¯ä»¥æ”¯æ’‘å®é™…çš„æ·±åº¦å­¦ä¹ ç ”ç©¶å’Œåº”ç”¨éœ€æ±‚ï¼

---

## æ€»ç»“

æŠ€æœ¯è§‰é†’æ¡†æ¶çš„Model-Trainerç³»ç»Ÿæ˜¯åŸºäºä¸“å®¶è¯„å®¡çš„D4æ–¹æ¡ˆç²¾å¿ƒè®¾è®¡çš„ç°ä»£æ·±åº¦å­¦ä¹ æ¡†æ¶ã€‚é€šè¿‡ä¸æ–­çš„ä¼˜åŒ–åˆ›æ–°ï¼Œå®ƒä¸ä»…å®Œå…¨ç¬¦åˆåŸå§‹è®¾è®¡ç†å¿µï¼Œè¿˜åœ¨å¤šä¸ªæ–¹é¢å®ç°äº†è¶…è¶Šã€‚

### æ ¸å¿ƒä»·å€¼

1. **è®¾è®¡å…ˆè¿›æ€§**ï¼šåŸºäºä¸“å®¶è¯„å®¡çš„D4æ–¹æ¡ˆï¼Œèåˆç°ä»£æœ€ä½³å®è·µ
2. **æ€§èƒ½å“è¶Š**ï¼šå¤šé¡¹ä¼˜åŒ–è¾¾åˆ°æˆ–è¶…è¶Šå·¥ä¸šçº§æ¡†æ¶æ€§èƒ½
3. **å†…å­˜å®‰å…¨**ï¼šV1.60.0æ¶ˆé™¤æ‰€æœ‰å·²çŸ¥å†…å­˜å®‰å…¨éšæ‚£
4. **å·¥ç¨‹è´¨é‡**ï¼šç»è¿‡å®Œæ•´è®­ç»ƒéªŒè¯ï¼Œè¾¾åˆ°ç”Ÿäº§çº§è´¨é‡
5. **æ–‡æ¡£å®Œå–„**ï¼šè¯¦å°½çš„æŠ€æœ¯æ–‡æ¡£å’Œä½¿ç”¨æŒ‡å—

### æŠ€æœ¯ä¼˜åŠ¿

1. **æ™ºèƒ½ç¼“å­˜ç³»ç»Ÿ**ï¼šLinearè½¬ç½®ç¼“å­˜ã€Modelç¼“å­˜ã€one-hotç¼“å­˜
2. **é›¶æ‹·è´ä¼˜åŒ–**ï¼šintoå‹æ–¹æ³•ä½“ç³»ï¼Œæ¶ˆé™¤ä¸å¿…è¦æ‹·è´
3. **ç±»å‹å®‰å…¨**ï¼šå¼ºç±»å‹ç³»ç»Ÿï¼Œç¼–è¯‘æ—¶é”™è¯¯æ£€æŸ¥
4. **è®¾å¤‡å…¼å®¹**ï¼šå¤šåç«¯æ”¯æŒï¼Œè®¾å¤‡ä¸€è‡´æ€§ä¿è¯
5. **æ€§èƒ½å¯æ‰©å±•**ï¼šæ¨¡å—åŒ–è®¾è®¡ï¼Œæ”¯æŒè‡ªå®šä¹‰æ‰©å±•

### é€‚ç”¨åœºæ™¯

æŠ€æœ¯è§‰é†’æ¡†æ¶ç‰¹åˆ«é€‚åˆä»¥ä¸‹åœºæ™¯ï¼š
- **å¿«é€ŸåŸå‹å¼€å‘**ï¼šç®€æ´çš„APIï¼Œå¿«é€Ÿå®éªŒæ–°æƒ³æ³•
- **æ€§èƒ½æ•æ„Ÿåº”ç”¨**ï¼šéœ€è¦æè‡´æ€§èƒ½çš„æ·±åº¦å­¦ä¹ åº”ç”¨
- **å¤šåç«¯æ”¯æŒ**ï¼šéœ€è¦åœ¨ä¸åŒç¡¬ä»¶ä¸Šéƒ¨ç½²
- **ç ”ç©¶æ•™è‚²**ï¼šæ·±åº¦å­¦ä¹ ç®—æ³•çš„ç ”ç©¶å’Œæ•™å­¦
- **å·¥ä¸šåº”ç”¨**ï¼šç”Ÿäº§ç¯å¢ƒä¸­çš„ç¨³å®šè¿è¡Œ

æŠ€æœ¯è§‰é†’æ¡†æ¶å·²ç»å‡†å¤‡å¥½ä¸ºæ·±åº¦å­¦ä¹ ç ”ç©¶å’Œåº”ç”¨æä¾›å¼ºå¤§ã€ç¨³å®šã€é«˜æ€§èƒ½çš„è®­ç»ƒæ”¯æŒï¼ğŸš€